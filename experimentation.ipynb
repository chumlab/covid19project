{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "Loading the datasets and cleaning. The following datasets are expected:\n",
    "* `locations_clean_user_location.tsv`: The original provided list of raw locations with corresponding number of occurances\n",
    "* In `/data`:\n",
    "  * `cities1000.tsv`, cities with > 1000 pop. (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/cities1000.zip\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `countryInfo.tsv`, countries (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/countryInfo.txt\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `admin1CodesASCII.txt`, states and provinces (admin1) (GeoNames)\n",
    "    * https://download.geonames.org/export/dump/admin1CodesASCII.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_user_location  tweet_id\n",
       "0                None   4994911\n",
       "1       United States    190257\n",
       "2               India     97652"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets user locations list\n",
    "# Loading using pandas' read_csv (tab-deleted) to set 'tweet_id' dtype to int\n",
    "\n",
    "tweets_user_locations = os.path.join(current_dir, \"locations_clean_user_location.tsv\")\n",
    "df = pd.read_csv(tweets_user_locations, sep='\\t', dtype={'tweet_id': int})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pndurette/.pyenv/versions/3.8.3/envs/chumblab/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039154</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>Ehl Tarter,Эл Тартер</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1721</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2012-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>San Julia,San Julià,Sant Julia de Loria,Sant J...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2013-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3039604</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Kasa,Пас де ла Каса</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2363</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-06-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid                 name            asciiname  \\\n",
       "0    3039154            El Tarter            El Tarter   \n",
       "1    3039163  Sant Julià de Lòria  Sant Julia de Loria   \n",
       "2    3039604       Pas de la Casa       Pas de la Casa   \n",
       "\n",
       "                                            altnames  latitude  longitude  \\\n",
       "0                               Ehl Tarter,Эл Тартер  42.57952    1.65362   \n",
       "1  San Julia,San Julià,Sant Julia de Loria,Sant J...  42.46372    1.49129   \n",
       "2                      Pas de la Kasa,Пас де ла Каса  42.54277    1.73361   \n",
       "\n",
       "  featclass featcode country  cc2 admin1 admin2 admin3 admin4  population  \\\n",
       "0         P      PPL      AD  NaN     02    NaN    NaN    NaN        1052   \n",
       "1         P     PPLA      AD  NaN     06    NaN    NaN    NaN        8022   \n",
       "2         P      PPL      AD  NaN     03    NaN    NaN    NaN        2363   \n",
       "\n",
       "   elevation  gtopo30        timezone     moddate  \n",
       "0        NaN     1721  Europe/Andorra  2012-11-03  \n",
       "1        NaN      921  Europe/Andorra  2013-11-23  \n",
       "2     2050.0     2106  Europe/Andorra  2008-06-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Cities with > 1000 inabitants)\n",
    "# https://download.geonames.org/export/dump/cities1000.zip\n",
    "# Loading using geopandas for geometry (usefulness tbd)\n",
    "# NB: We can ignore 'DtypeWarning' as we don't need column 13\n",
    "\n",
    "cities = os.path.join(current_dir, data_dir, \"cities1000.tsv\")\n",
    "# cities_df = gpd.read_file(cities)\n",
    "cities_df = pd.read_csv(cities, sep='\\t',\n",
    "            names=['geonameid', 'name', 'asciiname', 'altnames', 'latitude', 'longitude',\n",
    "                   'featclass', 'featcode', 'country', 'cc2', 'admin1', 'admin2', 'admin3', 'admin4',\n",
    "                   'population', 'elevation', 'gtopo30', 'timezone', 'moddate'],\n",
    "            dtype={'admin3': str}) # can't set column 13\n",
    "cities_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "      <th>altname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627577</th>\n",
       "      <td>5128581</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Aebura,Bandar Raya New York,Big Apple,Cathair ...</td>\n",
       "      <td>40.71427</td>\n",
       "      <td>-74.00597</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8175133</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid           name      asciiname  \\\n",
       "627577    5128581  New York City  New York City   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "627577  Aebura,Bandar Raya New York,Big Apple,Cathair ...  40.71427   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "627577  -74.00597         P      PPL      US  NaN     NY    NaN    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30          timezone     moddate altname  \n",
       "627577     8175133       10.0       57  America/New_York  2019-09-23     NYC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate City names\n",
    "# The cities_df dataframe has an 'altnames' column that are CSVs\n",
    "# We transform it to a list then explode it to make searching easier\n",
    "# (and reset the index). The new column 'altname' can be used to search.\n",
    "\n",
    "cities_alt_df = cities_df.assign(\n",
    "    altname=cities_df['altnames'].str.split(',')\n",
    "    ).explode('altname').reset_index(drop=True)\n",
    "\n",
    "cities_alt_df.head(3)\n",
    "\n",
    "cities_alt_df[cities_alt_df['altname'] == 'NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>6058560</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landona,London,Londonas,Londono,YXU,leondeon,l...</td>\n",
       "      <td>42.98339</td>\n",
       "      <td>-81.23304</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>America/Toronto</td>\n",
       "      <td>2012-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48817</th>\n",
       "      <td>2643743</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENG</td>\n",
       "      <td>GLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7556900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>2019-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118957</th>\n",
       "      <td>4119617</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Haddoxburg,London</td>\n",
       "      <td>35.32897</td>\n",
       "      <td>-93.25296</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>115</td>\n",
       "      <td>90813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1046</td>\n",
       "      <td>116.0</td>\n",
       "      <td>121</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120898</th>\n",
       "      <td>4298960</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...</td>\n",
       "      <td>37.12898</td>\n",
       "      <td>-84.08326</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KY</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8126</td>\n",
       "      <td>378.0</td>\n",
       "      <td>379</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122937</th>\n",
       "      <td>4517009</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landon,Limerick,London,New London,lndn,lndn  a...</td>\n",
       "      <td>39.88645</td>\n",
       "      <td>-83.44825</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>097</td>\n",
       "      <td>44674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10060</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132245</th>\n",
       "      <td>5367815</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>London,Londres,New London</td>\n",
       "      <td>36.47606</td>\n",
       "      <td>-119.44318</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1869</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>2011-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid    name asciiname  \\\n",
       "13904     6058560  London    London   \n",
       "48817     2643743  London    London   \n",
       "118957    4119617  London    London   \n",
       "120898    4298960  London    London   \n",
       "122937    4517009  London    London   \n",
       "132245    5367815  London    London   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "13904   Landona,London,Londonas,Londono,YXU,leondeon,l...  42.98339   \n",
       "48817   ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...  51.50853   \n",
       "118957                                  Haddoxburg,London  35.32897   \n",
       "120898  LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...  37.12898   \n",
       "122937  Landon,Limerick,London,New London,lndn,lndn  a...  39.88645   \n",
       "132245                          London,Londres,New London  36.47606   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "13904   -81.23304         P      PPL      CA  NaN     08    NaN    NaN    NaN   \n",
       "48817    -0.12574         P     PPLC      GB  NaN    ENG    GLA    NaN    NaN   \n",
       "118957  -93.25296         P      PPL      US  NaN     AR    115  90813    NaN   \n",
       "120898  -84.08326         P    PPLA2      US  NaN     KY    125    NaN    NaN   \n",
       "122937  -83.44825         P    PPLA2      US  NaN     OH    097  44674    NaN   \n",
       "132245 -119.44318         P      PPL      US  NaN     CA    107    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30             timezone     moddate  \n",
       "13904       346765        NaN      252      America/Toronto  2012-08-19  \n",
       "48817      7556900        NaN       25        Europe/London  2019-09-18  \n",
       "118957        1046      116.0      121      America/Chicago  2017-05-23  \n",
       "120898        8126      378.0      379     America/New_York  2017-03-09  \n",
       "122937       10060      321.0      321     America/New_York  2017-05-23  \n",
       "132245        1869       91.0       93  America/Los_Angeles  2011-05-14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cities finding\n",
    "# City\n",
    "city_test = cities_df[(cities_df['name'] == 'London')]\n",
    "city_test\n",
    "\n",
    "# City & admin1\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG')]\n",
    "city_test\n",
    "\n",
    "# City & admin1 & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City (with the largest population)\n",
    "cities_df[(cities_df['name'] == 'London')].nlargest(1, ['population']) \n",
    "city_test\n",
    "\n",
    "# City with alternative names\n",
    "\n",
    "city_test = cities_df[(cities_df['name'] == 'London')].copy()\n",
    "city_test\n",
    "\n",
    "# city_test.apply(lambda x: x.astype('str').str.split(',')).explode('altnames')\n",
    "# city_test.apply(lambda x: x.astype(str).str.split(',').explode()).reset_index(\n",
    "\n",
    "# city_test = cities_df[(cities_df['name'] == 'LON') | ('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test = cities_df[('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test\n",
    "\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #ISO ISO3  ISO-Numeric fips               Country           Capital  \\\n",
       "0   AD  AND           20   AN               Andorra  Andorra la Vella   \n",
       "1   AE  ARE          784   AE  United Arab Emirates         Abu Dhabi   \n",
       "2   AF  AFG            4   AF           Afghanistan             Kabul   \n",
       "\n",
       "   Area(in sq km)  Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "0           468.0       77006        EU  .ad          EUR         Euro   376   \n",
       "1         82880.0     9630959        AS  .ae          AED       Dirham   971   \n",
       "2        647500.0    37172386        AS  .af          AFN      Afghani    93   \n",
       "\n",
       "  Postal Code Format Postal Code Regex          Languages  geonameid  \\\n",
       "0              AD###  ^(?:AD)*(\\d{3})$                 ca    3041565   \n",
       "1                NaN               NaN  ar-AE,fa,en,hi,ur     290557   \n",
       "2                NaN               NaN  fa-AF,ps,uz-AF,tk    1149361   \n",
       "\n",
       "          neighbours EquivalentFipsCode  \n",
       "0              ES,FR                NaN  \n",
       "1              SA,OM                NaN  \n",
       "2  TM,CN,IR,TJ,PK,UZ                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Countries info)\n",
    "# https://download.geonames.org/export/dump/countryInfo.txt\n",
    "# Loading using pandas' read_csv (tab-deleted), ignore lines 1-48\n",
    "\n",
    "countries = os.path.join(current_dir, data_dir, \"countryInfo.tsv\")\n",
    "countries_df = pd.read_csv(countries, sep='\\t', header=49)\n",
    "countries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 name           name ascii  geonameid\n",
       "0  AD.06  Sant Julià de Loria  Sant Julia de Loria    3039162\n",
       "1  AD.05               Ordino               Ordino    3039676\n",
       "2  AD.04           La Massana           La Massana    3040131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (states and provinces, admin1)\n",
    "# https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
    "# Loading using pandas' read_csv (tab-deleted),\n",
    "# Column names from https://download.geonames.org/export/dump/readme.txt\n",
    "# 'code' is '<country>.<admin1 for country>'\n",
    "\n",
    "admin1 = os.path.join(current_dir, data_dir, \"admin1CodesASCII.txt\")\n",
    "admin1_df = pd.read_csv(admin1, sep='\\t', names=['code', 'name', 'name ascii', 'geonameid'])\n",
    "admin1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code, name, name ascii, geonameid]\n",
       "Index: []"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin1_df[admin1_df['name'] == 'Ontario']\n",
    "admin1_df[admin1_df['name ascii'].str.match('orange country')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678465</th>\n",
       "      <td>5882600</td>\n",
       "      <td>Agincourt North</td>\n",
       "      <td>Agincourt North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.80418</td>\n",
       "      <td>-79.27528</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678466</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678467</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678468</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678469</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679962</th>\n",
       "      <td>12156903</td>\n",
       "      <td>Downsview-Roding-CFB</td>\n",
       "      <td>Downsview-Roding-CFB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.73329</td>\n",
       "      <td>-79.49049</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679963</th>\n",
       "      <td>12156904</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.74564</td>\n",
       "      <td>-79.51347</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679964</th>\n",
       "      <td>12156905</td>\n",
       "      <td>High Park-Swansea</td>\n",
       "      <td>High Park-Swansea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.64506</td>\n",
       "      <td>-79.46787</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679965</th>\n",
       "      <td>12156906</td>\n",
       "      <td>Kingsview Village-The Westway</td>\n",
       "      <td>Kingsview Village-The Westway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.69899</td>\n",
       "      <td>-79.54786</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679966</th>\n",
       "      <td>12156907</td>\n",
       "      <td>Kingsway South</td>\n",
       "      <td>Kingsway South</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.65352</td>\n",
       "      <td>-79.51058</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1502 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geonameid                           name  \\\n",
       "678465   5882600                Agincourt North   \n",
       "678466   5882873                           Ajax   \n",
       "678467   5882873                           Ajax   \n",
       "678468   5882873                           Ajax   \n",
       "678469   5882873                           Ajax   \n",
       "...          ...                            ...   \n",
       "679962  12156903           Downsview-Roding-CFB   \n",
       "679963  12156904         Glenfield-Jane Heights   \n",
       "679964  12156905              High Park-Swansea   \n",
       "679965  12156906  Kingsview Village-The Westway   \n",
       "679966  12156907                 Kingsway South   \n",
       "\n",
       "                            asciiname  \\\n",
       "678465                Agincourt North   \n",
       "678466                           Ajax   \n",
       "678467                           Ajax   \n",
       "678468                           Ajax   \n",
       "678469                           Ajax   \n",
       "...                               ...   \n",
       "679962           Downsview-Roding-CFB   \n",
       "679963         Glenfield-Jane Heights   \n",
       "679964              High Park-Swansea   \n",
       "679965  Kingsview Village-The Westway   \n",
       "679966                 Kingsway South   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "678465                                                NaN  43.80418   \n",
       "678466  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678467  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678468  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678469  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "...                                                   ...       ...   \n",
       "679962                                                NaN  43.73329   \n",
       "679963                                                NaN  43.74564   \n",
       "679964                                                NaN  43.64506   \n",
       "679965                                                NaN  43.69899   \n",
       "679966                                                NaN  43.65352   \n",
       "\n",
       "        longitude featclass featcode country  cc2  ... Continent  tld  \\\n",
       "678465  -79.27528         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "678466  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678467  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678468  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678469  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "...           ...       ...      ...     ...  ...  ...       ...  ...   \n",
       "679962  -79.49049         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679963  -79.51347         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679964  -79.46787         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679965  -79.54786         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679966  -79.51058         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "\n",
       "       CurrencyCode CurrencyName  Phone  Postal Code Format  \\\n",
       "678465          NaN          NaN    NaN                 NaN   \n",
       "678466          NaN          NaN    NaN                 NaN   \n",
       "678467          NaN          NaN    NaN                 NaN   \n",
       "678468          NaN          NaN    NaN                 NaN   \n",
       "678469          NaN          NaN    NaN                 NaN   \n",
       "...             ...          ...    ...                 ...   \n",
       "679962          NaN          NaN    NaN                 NaN   \n",
       "679963          NaN          NaN    NaN                 NaN   \n",
       "679964          NaN          NaN    NaN                 NaN   \n",
       "679965          NaN          NaN    NaN                 NaN   \n",
       "679966          NaN          NaN    NaN                 NaN   \n",
       "\n",
       "        Postal Code Regex Languages neighbours EquivalentFipsCode  \n",
       "678465                NaN       NaN        NaN                NaN  \n",
       "678466                NaN       NaN        NaN                NaN  \n",
       "678467                NaN       NaN        NaN                NaN  \n",
       "678468                NaN       NaN        NaN                NaN  \n",
       "678469                NaN       NaN        NaN                NaN  \n",
       "...                   ...       ...        ...                ...  \n",
       "679962                NaN       NaN        NaN                NaN  \n",
       "679963                NaN       NaN        NaN                NaN  \n",
       "679964                NaN       NaN        NaN                NaN  \n",
       "679965                NaN       NaN        NaN                NaN  \n",
       "679966                NaN       NaN        NaN                NaN  \n",
       "\n",
       "[1502 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames 'admin1' (admin1_df) for Canadian provinces uses a 2-digit code\n",
    "# Use postal abbreviation which people use\n",
    "\n",
    "# CA.01\tAlberta\tAlberta\t5883102\n",
    "# CA.02\tBritish Columbia\tBritish Columbia\t5909050\n",
    "# CA.03\tManitoba\tManitoba\t6065171\n",
    "# CA.04\tNew Brunswick\tNew Brunswick\t6087430\n",
    "# CA.13\tNorthwest Territories\tNorthwest Territories\t6091069\n",
    "# CA.07\tNova Scotia\tNova Scotia\t6091530\n",
    "# CA.14\tNunavut\tNunavut\t6091732\n",
    "# CA.08\tOntario\tOntario\t6093943\n",
    "# CA.09\tPrince Edward Island\tPrince Edward Island\t6113358\n",
    "# CA.10\tQuebec\tQuebec\t6115047\n",
    "# CA.11\tSaskatchewan\tSaskatchewan\t6141242\n",
    "# CA.12\tYukon\tYukon\t6185811\n",
    "# CA.05\tNewfoundland and Labrador\tNewfoundland and Labrador\t6354959\n",
    "\n",
    "province_abbr = {\n",
    "    'CA.01': 'CA.AB', # Alberta\n",
    "    'CA.02': 'CA.BC', # British Columbia\n",
    "    'CA.03': 'CA.MB', # Manitoba\n",
    "    'CA.04': 'CA.NB', # New Brunswick\n",
    "    'CA.05': 'CA.NL', # Newfoundland and Labrador\n",
    "    'CA.07': 'CA.NS', # Nova Scotia\n",
    "    'CA.08': 'CA.ON', # Ontario\n",
    "    'CA.09': 'CA.PE', # Prince Edward Island\n",
    "    'CA.10': 'CA.QC', # Quebec\n",
    "    'CA.11': 'CA.SK', # Saskatchewan\n",
    "    'CA.12': 'CA.YK', # Yukon\n",
    "    'CA.13': 'CA.NT', # Northwest Territories\n",
    "    'CA.14': 'CA.NU'  # Nunavut\n",
    "}\n",
    "\n",
    "for num, alpha in province_abbr.items():\n",
    "    admin1_df.loc[(admin1_df['code'] == num),'code'] = alpha\n",
    "\n",
    "# Add to cities too\n",
    "# Query the cities with country CA and num code, copy,\n",
    "# replace num code by letter code, then concat back\n",
    "new_cities = pd.DataFrame([], columns=countries_df.columns)\n",
    "for num_code, letter_code in province_abbr.items():\n",
    "    country, num = tuple(num_code.split('.'))\n",
    "    country, letter = tuple(letter_code.split('.'))\n",
    " \n",
    "    alt_cities = cities_alt_df[(cities_alt_df['country'] == country) & \\\n",
    "                               (cities_alt_df['admin1'] == num)].copy()\n",
    "    alt_cities['admin1'] = letter\n",
    "    new_cities = pd.concat([new_cities, alt_cities], ignore_index=True)\n",
    "\n",
    "cities_alt_df = pd.concat([cities_alt_df, new_cities], ignore_index=True)\n",
    "cities_alt_df[cities_alt_df['admin1'] == 'ON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>BO.04</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>HN.12</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>SV.06</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code    name name ascii  geonameid\n",
       "351   BO.04  La Paz     La Paz         99\n",
       "1190  HN.12  La Paz     La Paz         99\n",
       "3288  SV.06  La Paz     La Paz         99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test when there's more than 1 admin1\n",
    "\n",
    "# admin1_df[admin1_df['code'].str.contains('^US.')]\n",
    "# admin1_df[admin1_df['name'] == 'La Paz']\n",
    "country_code = 'HN'\n",
    "element = 'La Paz'\n",
    "test1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "test1.loc[:, 'geonameid'] = 99\n",
    "test11 = test1.head(1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>US.FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4155751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code     name name ascii  geonameid\n",
       "3660  US.FL  Florida    Florida    4155751"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With both country-code and admin1-code\n",
    "country_code = 'CA'\n",
    "admin1_code = 'ON'\n",
    "admin1_df[(admin1_df['code'].str.contains(f'^{country_code}.{admin1_code}'))]\n",
    "\n",
    "# With only an admin1-code\n",
    "admin1_code = 'FL'\n",
    "admin1_df[(admin1_df['code'].str.contains(f'.{admin1_code}$'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative names (huge DB)\n",
    "\n",
    "# alts = os.path.join(current_dir, data_dir, \"alternateNamesV2.txt\")\n",
    "# alts_df = pd.read_csv(alts, sep='\\t',\n",
    "#             names=['alternateNameId', 'geonameid', 'isolanguage', 'alternate name',\n",
    "#                    'isPreferredName', 'isShortName', 'isColloquial', 'isHistoric', 'from', 'to'])\n",
    "# alts_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alts_df[(alts_df['isPreferredName'] == 1) & (alts_df['alternate name'] == 'République Démocratique Du Congo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>ES.29</td>\n",
       "      <td>Comunidad de Madrid</td>\n",
       "      <td>Comunidad de Madrid</td>\n",
       "      <td>3117732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                 name           name ascii geonameid\n",
       "3933  ES.29  Comunidad de Madrid  Comunidad de Madrid   3117732"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add alternative country names (e.g. USA, UK, etc.)\n",
    "# (we can't easily get alternative country names)\n",
    "alternative_country_names = {\n",
    "    6252001: ['USA', 'US','United States of America','America', 'Estados Unidos', '🇺🇸'], # United States\n",
    "    2510769: ['España', 'Espanya', '🇪🇸'], # [Kingdom of] Spain\n",
    "    2635167: ['UK', '🇬🇧'], # United Kingdom\n",
    "    1861060: ['日本', '🇯🇵'],    # Japan\n",
    "    298795: ['Türkiye', '🇹🇷'], # Turkey\n",
    "    3469034: ['Brasil', '🇧🇷'], # Brazil\n",
    "    3175395: ['Italia', '🇮🇹'], # Italy\n",
    "    1694008: ['Republic of the Philippines', '🇵🇭'], # Philipines\n",
    "    2921044: ['Deutschland', '🇩🇪'], # Germany\n",
    "    2750405: ['The Netherlands'], # Netherlands\n",
    "    3508796: ['República Dominicana', 'Republica Dominicana'], # Dominiucal Republic\n",
    "    3932488: ['Perú', '🇵🇪'], # Peru\n",
    "    1269750: ['भारत', '🇮🇳'], # India\n",
    "    2802361: ['Belgique', 'België', '🇧🇪'], # Belgium \n",
    "    2260494: ['République Démocratique Du Con'], # Congo\n",
    "    3996063: ['méxico', '🇲🇽'], # Mexico\n",
    "    1567903: ['việt nam'], # Vietnam\n",
    "    6251999: ['🇨🇦'], # Canada\n",
    "    2328926: ['Nig', '🇳🇬'], # Nigeria\n",
    "    3865483: ['🇦🇷'], # Argentina\n",
    "    953987: ['🇿🇦'], # South Africa\n",
    "    3017382: ['🇫🇷'], # France\n",
    "    2300660: ['🇬🇭'], # Ghana\n",
    "    1819730: ['🇭🇰'], # Hong Kong\n",
    "    3895114: ['🇨🇱'], # Chile\n",
    "    3686110: ['🇨🇴'], # Colombia\n",
    "    1643084: ['Indone', '🇮🇩'], # Indonesia\n",
    "    3625428: ['🇻🇪'], # Venezuela\n",
    "    3489940: ['🇯🇲'], # Jamaica\n",
    "    2077456: ['🇦🇺'], # Australia\n",
    "    192950: ['🇰🇪'], # Kenya\n",
    "    2658434: ['Suisse', 'Schweiz', '🇨🇭'], # Switzerland\n",
    "    4566966: ['🇵🇷'], # Puerto Rico\n",
    "    1168579: ['🇵🇰'], # Pakistan\n",
    "    1880251: ['🇸🇬'], # Singapore\n",
    "    1605651: ['ประเทศไทย'], # Thailand\n",
    "    2782113: ['Österreich'], # Austria\n",
    "    798544: ['Polska'], # Poland\n",
    "    2287781: [\"Côte d'Ivoire\"], # Ivory Coast\n",
    "    2287781: ['Kingdom of Saudi Arabia', 'ٱلْمَمْلَكَة ٱلْعَرَبِيَّة ٱلسَّعُوْدِيَّة'], # Saudi Arabia\n",
    "    2017370: ['Россия'], # Russia\n",
    "    1835841: ['Republic of Korea'], # South Korea\n",
    "    2661886: ['Sverige'], # Sweden\n",
    "    1814991: [\"People's Republic of China\"], # China\n",
    "    6290252: ['Republic of Serbia'], # Serbia\n",
    "    130758: ['Islamic Republic of Iran'], # Iran\n",
    "    2589581: ['Algérie'], # Algeria\n",
    "    3077311: ['Czech Republic'], # Czech Republic\n",
    "    2464461: ['Tunisie'], # Tunisia\n",
    "    290557: ['UAE'], # United Arab Emirates\n",
    "    690791: ['Украина'], # Ukraine\n",
    "}\n",
    "\n",
    "new_countries = pd.DataFrame([], columns=countries_df.columns)\n",
    "for geo, alt_names in alternative_country_names.items():\n",
    "    for name in alt_names:\n",
    "        alt_country = countries_df[countries_df['geonameid'] == geo].copy()\n",
    "        alt_country['Country'] = name\n",
    "        new_countries = pd.concat([new_countries, alt_country], ignore_index=True)\n",
    "\n",
    "countries_df = pd.concat([countries_df, new_countries], ignore_index=True)\n",
    "\n",
    "# Admin1 alternatives\n",
    "alternative_admin1_names = {\n",
    "    3117732: ['Comunidad de Madrid'],\n",
    "    3336901: ['Catalunya', 'Cataluña'], # Catalonia, Spain\n",
    "    5332921: ['Southern California', 'SoCal'], # California, USA\n",
    "    4155751: ['South Florida'], # Florida, USA\n",
    "    3170831: ['Piemonte'], # Italy\n",
    "    3174976: ['Lazio'],\n",
    "    3174618: ['Lombardia'],\n",
    "    3177401: ['Emilia Romagna'],\n",
    "    3165361: ['Toscana'],\n",
    "    1642672: ['Jawa Barat'], # West Java\n",
    "    1642668: ['Jawa Timur'], # East Java\n",
    "    2951839: ['Bayern'], # Bavaria, Germany\n",
    "}\n",
    "\n",
    "new_admin1s = pd.DataFrame([], columns=admin1_df.columns)\n",
    "for geo, alt_names in alternative_admin1_names.items():\n",
    "    for name in alt_names:\n",
    "        alt_admin1 = admin1_df[admin1_df['geonameid'] == geo].copy()\n",
    "        alt_admin1['name'] = name\n",
    "        alt_admin1['name ascii'] = name\n",
    "        new_admin1s = pd.concat([new_admin1s, alt_admin1], ignore_index=True)\n",
    "\n",
    "admin1_df = pd.concat([admin1_df, new_admin1s], ignore_index=True)\n",
    "\n",
    "admin1_df[admin1_df['name'] == 'Comunidad de Madrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard specific 'tweet_user_location' strings\n",
    "LOCATION_DISCARD = ['', 'none', '\\\\n', 'global', 'earth',\n",
    "                    'planet earth', 'worldwide', 'everywhere',\n",
    "                    'internet', 'en todas partes',\n",
    "                    'europe', 'africa',\n",
    "                    'world', 'mars', 'text resist to 50409', 'she/her',\n",
    "                    'JDSupra.com', 'Here', 'The World', 'Rock Planet', 'Somewhere',\n",
    "                    'Hell', 'World Wide', 'Hogwarts', 'Neverland', 'International',\n",
    "                    '127.0.0.1', 'Wakanda', 'Planeta Tierra', 'Universe', 'Heaven',\n",
    "                    'Online', 'World Wide Web', 'Somewhere over the rainbow', 'Parts Unknown',\n",
    "                    'Mundo', 'Narnia', 'Twitter', 'some place', 'Gotham City', 'Mother Earth',\n",
    "                    'nowhere', 'nationwide', 'they/them', 'space', '#DV #CSA #Daniel_Morgan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the percentage of tweets that have a 'geonameid'\n",
    "# Skipping the ones we know aren't valid (discards)\n",
    "def print_geonameid_completeness(df):\n",
    "    all_tweets = df[~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)]['tweet_id'].sum()\n",
    "    geonameid_tweets = df[df.geonameid.notnull()]['tweet_id'].sum()\n",
    "    print(f'{geonameid_tweets/all_tweets*100:.3f}%')\n",
    "\n",
    "# Show dataframe df where 'geonameid' is NaN and location\n",
    "# is not known to be invalid (discards)\n",
    "def show_nan(df):\n",
    "    nan_df = df[(~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)) & df['geonameid'].isnull()]\n",
    "    print(f'Number of NaNs: {len(nan_df.index)}')\n",
    "    return nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ✈</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338215 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "0                                 None   4994911   \n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "...                                ...       ...   \n",
       "338210      N 52°27' 0'' / W 1°49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ✈          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "0                                 None  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "...                                ...  \n",
       "338210      N 52°27' 0'' / W 1°49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338215 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of 'tweet_user_location' so we leave the original intact\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location']\n",
    "\n",
    "# Discard specific 'tweet_user_location' strings\n",
    "# tweet_user_location_discard = ['None', '\\\\N']\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]\n",
    "\n",
    "# Discard locations that don't exist more than 2 times\n",
    "df = df[df['tweet_id'] > 2]\n",
    "\n",
    "# Renaming admin1 or city locations\n",
    "# \"<original>\": \"<new>\"\n",
    "# rename_locations = {\n",
    "#     \"Southern California\": \"California\",\n",
    "#     \"SoCal\": \"California\",\n",
    "#     \"South Florida\": \"Florida\",\n",
    "#     \"Comunidad de Madrid\": \"Madrid\",\n",
    "#     \"Catalunya\": \"Catalonia\",\n",
    "#     \"Cataluña\": \"Catalonia\",\n",
    "#     \"Piemonte\": \"Piedmont\",\n",
    "#     \"Lombardia\": \"Lombardy\",\n",
    "#     \"Emilia Romagna\": \"Emilia-Romagna\",\n",
    "#     \"Toscana\": \"Tuscany\",\n",
    "#     \"Jawa Barat\": \"West Java\", \n",
    "#     \"Jawa Timur\": \"East Java\",\n",
    "#     \"Bayern\": \"Bavaria\"\n",
    "# }\n",
    "\n",
    "# for loc_src, loc_dst in rename_locations.items():\n",
    "#     df.loc[(df['tweet_user_location_copy'] == loc_src),'tweet_user_location_copy'] = loc_dst\n",
    "\n",
    "# Filter out emojis and other symbols\n",
    "# * https://stackoverflow.com/a/49986645\n",
    "# * https://www.ling.upenn.edu/courses/Spring_2003/ling538/UnicodeRanges.html (Unicode symbol ranges)\n",
    "import re\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emojis: emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # emojis: symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # emojis: transport & map symbols\n",
    "        u\"\\U00002700-\\U000027BF\"  # 'Dingbats' http://www.unicode.org/charts/PDF/U2700.pdf\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deEmojify(x))\n",
    "\n",
    "# Truncate leading and trailing spaces\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.strip())\n",
    "\n",
    "# Filter out emoji flags, except if there's only one\n",
    "# n.b. 1 emoji = 2 characters (i.e. '{2}')\n",
    "def deFlag(text):\n",
    "    regrex_oneflag = re.compile(pattern = u\"^[\\U0001F1E0-\\U0001F1FF]{2}$\", flags = re.UNICODE)\n",
    "    regrex_allflags = re.compile(pattern = u\"[\\U0001F1E0-\\U0001F1FF]+\", flags = re.UNICODE)\n",
    "    if regrex_oneflag.search(text) is not None:\n",
    "        return text\n",
    "    else:\n",
    "        return regrex_allflags.sub(r'',text)\n",
    "        \n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deFlag(x))\n",
    "    \n",
    "# Truncate trailing \",\" and \".\" characters\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip('.'))\n",
    "\n",
    "df\n",
    "\n",
    "# pd.set_option('display.max_rows', 20000)\n",
    "# df[df['tweet_user_location_copy'].str.match(r'[\\U0001F1E0-\\U0001F1FF]') == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean: Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything used for comparison lowercase for simplicity\n",
    "\n",
    "# Locations\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].str.lower()\n",
    "\n",
    "# Cities\n",
    "cities_alt_df['name'] = cities_alt_df['name'].str.lower()\n",
    "cities_alt_df['asciiname'] = cities_alt_df['asciiname'].str.lower()\n",
    "cities_alt_df['altname'] = cities_alt_df['altname'].str.lower()\n",
    "cities_alt_df['admin1'] = cities_alt_df['admin1'].str.lower()\n",
    "\n",
    "# Admin1\n",
    "admin1_df['code'] = admin1_df['code'].str.lower()\n",
    "admin1_df['name'] = admin1_df['name'].str.lower()\n",
    "admin1_df['name ascii'] = admin1_df['name ascii'].str.lower()\n",
    "\n",
    "# Countries\n",
    "countries_df['Country'] = countries_df['Country'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Canada</td>\n",
       "      <td>723</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>712</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>canada</td>\n",
       "      <td>674</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>199</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Canada</td>\n",
       "      <td>177</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>Canada🇨🇦</td>\n",
       "      <td>52</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32494</th>\n",
       "      <td>canada</td>\n",
       "      <td>28</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>🇨🇦Canada🇨🇦</td>\n",
       "      <td>17</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78821</th>\n",
       "      <td>🍁 Canada 🍁</td>\n",
       "      <td>12</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83440</th>\n",
       "      <td>Canada</td>\n",
       "      <td>11</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97153</th>\n",
       "      <td>Canada🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97288</th>\n",
       "      <td>CANADA 🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106456</th>\n",
       "      <td>canada🇨🇦🇲🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143617</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143790</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148946</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155483</th>\n",
       "      <td>🍁Canada🍁</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192221</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244818</th>\n",
       "      <td>CANADA🇨🇦🇨🇦🇨🇦</td>\n",
       "      <td>4</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294426</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294536</th>\n",
       "      <td>Canada 🍁</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_user_location  tweet_id tweet_user_location_copy\n",
       "18                  Canada     40858                   canada\n",
       "1497               Canada        723                   canada\n",
       "1520                CANADA       712                   canada\n",
       "1594                canada       674                   canada\n",
       "4756               Canada.       199                   canada\n",
       "5333                Canada       177                   canada\n",
       "17363             Canada🇨🇦        52                   canada\n",
       "32494              canada         28                   canada\n",
       "52402           🇨🇦Canada🇨🇦        17                   canada\n",
       "78821           🍁 Canada 🍁        12                   canada\n",
       "83440              Canada         11                   canada\n",
       "97153              Canada🍁         9                   canada\n",
       "97288             CANADA 🍁         9                   canada\n",
       "100681            Canada           9                   canada\n",
       "106456          canada🇨🇦🇲🇦         9                   canada\n",
       "143617             CANADA          6                   canada\n",
       "143790              CANADA         6                   canada\n",
       "148946             CANADA          6                   canada\n",
       "155483            🍁Canada🍁         6                   canada\n",
       "192221              Canada         5                   canada\n",
       "244818        CANADA🇨🇦🇨🇦🇨🇦         4                   canada\n",
       "294426            Canada.          3                   canada\n",
       "294536            Canada 🍁         3                   canada"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations are verbatim the name of a country, e.g.:\n",
    "df[df['tweet_user_location_copy'] == 'canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[df['tweet_user_location'].isin(simple_countries_df['Country'])]\n",
    "# # simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]#.set_index('Country')\n",
    "\n",
    "# # Merge in country info (with goenameid) when there's an exact country match\n",
    "\n",
    "# # Keep the columns of countries_df we need.\n",
    "# simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]\n",
    "# #df = pd.merge(df, simple_countries_df, how='left', left_on='tweet_user_location_copy', right_on='Country')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_geonameid_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_cities_df = cities_df[['geonameid', 'name', 'asciiname', 'altnames']]\n",
    "# df = pd.merge(df, simple_cities_df, how='left', left_on='tweet_user_location', right_on='name')\n",
    "#df_copy = df[df['geonameid'].isnull()]\n",
    "#pd.merge(df_copy, simple_cities_df, how='left', left_on='tweet_user_location_copy', right_on='name')\n",
    "\n",
    "# NB: this can't work b/c cities name (unlike countries) aren't unique, e.g. there's a lot of \"London\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['tweet_user_location_copy'].str.count(',') > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"Toronto, Ontario, Canada, World\"\n",
    "# test = \"Toronto, Canada\"\n",
    "# test.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toronto']\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def split_fixed_parts(num_parts, location):\n",
    "#     parts = location.split(',')\n",
    "#     if num_parts > len(parts):\n",
    "#         for i in range(num_parts - len(parts)):\n",
    "#             parts.insert(0, None)\n",
    "#     else:\n",
    "#         for i in range(len(parts) - num_parts):\n",
    "#             parts.pop(0)\n",
    "#     return parts\n",
    "\n",
    "# def parts_dict(num_parts, location):\n",
    "#     parts = split_fixed_parts(num_parts, location)\n",
    "#     return {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "\n",
    "def split_parts(location):\n",
    "    return location.split(',')\n",
    "\n",
    "# print(split_fixed_parts(3, 'Toronto'))\n",
    "print(split_parts('Toronto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>035</td>\n",
       "      <td>45</td>\n",
       "      <td>035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Eisha</td>\n",
       "      <td>45</td>\n",
       "      <td>eisha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>45</td>\n",
       "      <td>兵庫県神戸市</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Cloud Nine</td>\n",
       "      <td>45</td>\n",
       "      <td>cloud nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Denver, Colo.</td>\n",
       "      <td>45</td>\n",
       "      <td>denver, colo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_user_location  tweet_id tweet_user_location_copy\n",
       "0                    None   4994911                     none\n",
       "1           United States    190257            united states\n",
       "2                   India     97652                    india\n",
       "3         London, England     77542          london, england\n",
       "4                     USA     67336                      usa\n",
       "...                   ...       ...                      ...\n",
       "19995                 035        45                      035\n",
       "19996               Eisha        45                    eisha\n",
       "19997              兵庫県神戸市        45                   兵庫県神戸市\n",
       "19998          Cloud Nine        45               cloud nine\n",
       "19999       Denver, Colo.        45             denver, colo\n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mini test dataset\n",
    "# test_df = df[df['tweet_user_location_copy'].str.count(',') == 2].head(50)\n",
    "# test_df = df[df['tweet_user_location'].str.match('Florida')].copy()\n",
    "test_df = df.head(20000).copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>none</td>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>united states</td>\n",
       "      <td>[united states]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>india</td>\n",
       "      <td>[india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>usa</td>\n",
       "      <td>[usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>035</td>\n",
       "      <td>45</td>\n",
       "      <td>035</td>\n",
       "      <td>[035]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Eisha</td>\n",
       "      <td>45</td>\n",
       "      <td>eisha</td>\n",
       "      <td>[eisha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>45</td>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>[兵庫県神戸市]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Cloud Nine</td>\n",
       "      <td>45</td>\n",
       "      <td>cloud nine</td>\n",
       "      <td>[cloud nine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Denver, Colo.</td>\n",
       "      <td>45</td>\n",
       "      <td>denver, colo</td>\n",
       "      <td>[denver,  colo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_user_location  tweet_id tweet_user_location_copy  \\\n",
       "0                    None   4994911                     none   \n",
       "1           United States    190257            united states   \n",
       "2                   India     97652                    india   \n",
       "3         London, England     77542          london, england   \n",
       "4                     USA     67336                      usa   \n",
       "...                   ...       ...                      ...   \n",
       "19995                 035        45                      035   \n",
       "19996               Eisha        45                    eisha   \n",
       "19997              兵庫県神戸市        45                   兵庫県神戸市   \n",
       "19998          Cloud Nine        45               cloud nine   \n",
       "19999       Denver, Colo.        45             denver, colo   \n",
       "\n",
       "                 elements  \n",
       "0                  [none]  \n",
       "1         [united states]  \n",
       "2                 [india]  \n",
       "3      [london,  england]  \n",
       "4                   [usa]  \n",
       "...                   ...  \n",
       "19995               [035]  \n",
       "19996             [eisha]  \n",
       "19997            [兵庫県神戸市]  \n",
       "19998        [cloud nine]  \n",
       "19999     [denver,  colo]  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parts = 3\n",
    "\n",
    "# https://stackoverflow.com/a/16242202\n",
    "#test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))\n",
    "#test_df = pd.concat([test_df, test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))], axis=1)\n",
    "\n",
    "test_df['elements'] = test_df['tweet_user_location_copy'].map(lambda location: location.split(','))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(countries_df, element):\n",
    "    # Filter 'Country' field with 'element'\n",
    "    country = countries_df[countries_df['Country'] == element]\n",
    "    \n",
    "    # No results\n",
    "    if len(country) == 0:\n",
    "        return None\n",
    "    \n",
    "    # There can be only one result\n",
    "    return country\n",
    "\n",
    "\n",
    "def get_admin1(admin1_df, element, country_code=None):\n",
    "    if country_code is None:\n",
    "        # admin1 matching name (or ascii name), or admin1 code w/o country\n",
    "        admin1 = admin1_df[(admin1_df['name'] == element) | \\\n",
    "                           (admin1_df['name ascii'] == element) | \\\n",
    "                           (admin1_df['code'].str.contains(rf'.{element}$'))]\n",
    "        \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            return None\n",
    "    \n",
    "        if len(admin1) > 1:\n",
    "            # If it's an admin1 code\n",
    "            if len(element) == 2:\n",
    "                # If there's more than 1 admin1 codes and it's a 2 letter code,\n",
    "                # take the one that is either USA or Canada\n",
    "                admin1_ = admin1.copy()\n",
    "                admin1 = admin1_[(admin1_['code'].str.contains(rf'us.{element}$')) | \\\n",
    "                                 (admin1_['code'].str.contains(rf'ca.{element}$'))]\n",
    "                \n",
    "                if len(admin1) == 1:\n",
    "                    return admin1\n",
    "                \n",
    "                else:\n",
    "                    # #ERROR:99\n",
    "                    # This error happens when for an admin1 code,\n",
    "                    # w/o a country, there is more than 1 admin1 row that is not USA or Canada\n",
    "                    admin1 = admin1_df[admin1_df['code'].str.contains(rf'.{element}$')].copy()\n",
    "                    admin1.loc[:, 'geonameid'] = 99\n",
    "                    return admin1.head(1)\n",
    "            \n",
    "            # If there's more than 1 admin1 name/ascii name\n",
    "            # take the one that is either USA or Canada\n",
    "            # (Americans tend to write only their state\n",
    "            # name and e.g. there's many Floridas)\n",
    "            admin1_ = admin1.copy()\n",
    "            admin1 = admin1_[(admin1_['code'].str.contains(rf'^us.')) | \\\n",
    "                            (admin1_['code'].str.contains(rf'^ca.'))]\n",
    "            \n",
    "            if len(admin1) == 1:\n",
    "                return admin1\n",
    "                \n",
    "            else:\n",
    "                # #ERROR:98\n",
    "                # This error happens when, w/o a country, there is\n",
    "                # more than 1 admin1 by that name/ascii name.\n",
    "                # There is not enough data to infer which one.\n",
    "                # (and it's not in the US or Canada)\n",
    "                # e.g. \"La Paz\" district (Bolivia, Honduras, El Savador)\n",
    "                admin1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "                admin1.loc[:, 'geonameid'] = 98\n",
    "                return admin1.head(1)\n",
    "    \n",
    "    else:\n",
    "        country_code = country_code.lower()\n",
    "        # admin1 code matching <country_code>.<abbreviation>\n",
    "        # or (admin1 code starts with <country_code> and (match name (or ascii name)))\n",
    "        admin1 = admin1_df[\n",
    "            (admin1_df['code'] == f'{country_code}.{element}') | \\\n",
    "                ((admin1_df['code'].str.contains(rf'^{country_code}.')) & \\\n",
    "                 ((admin1_df['name'] == element) | (admin1_df['name ascii'] == element)))]\n",
    "        \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            return None\n",
    "        \n",
    "        if len(admin1) > 1:\n",
    "            # #ERROR:97\n",
    "            # This error happens when, with a country, there is\n",
    "            # more than 1 admin1 by that name/ascii name.\n",
    "            admin1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "            admin1.loc[:, 'geonameid'] = 97\n",
    "            return admin1.head(1)\n",
    "    \n",
    "    return admin1\n",
    "\n",
    "\n",
    "def get_city(cities_df, element, admin1_code=None, country_code=None):\n",
    "    # print(f'admin1_code: {admin1_code}, country_code: {country_code}')\n",
    "    if admin1_code is None and country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element)]\n",
    "    \n",
    "    elif admin1_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                         (cities_df['country'] == country_code)]\n",
    "    \n",
    "    elif country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code)]\n",
    "    \n",
    "    else:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code) & \\\n",
    "                           (cities_df['country'] == country_code)]\n",
    "    \n",
    "    if len(cities) == 0:\n",
    "        # No results\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # More than one result,\n",
    "        # take the city with the largest population.\n",
    "        return cities.nlargest(1, ['population']) \n",
    "\n",
    "\"\"\"\n",
    "Cases:\n",
    "\n",
    "country\n",
    "\n",
    "city, state/prov, country\n",
    "city, state/prov\n",
    "city, country\n",
    "city\n",
    "\n",
    "neighboorhood, city, country\n",
    "neighboorhood, city\n",
    "\n",
    "state/prov, country\n",
    "state/prov\n",
    "\"\"\"\n",
    "\n",
    "# Filter out Regex 'metacharacters' (compile regex for performance)\n",
    "# https://docs.python.org/3/howto/regex.html#matching-characters\n",
    "meta_chars = \".^$*+?{}[]\\|()\"\n",
    "meta_chars = [re.escape(i) for i in list(meta_chars)]\n",
    "regrex_pattern = re.compile(\"|\".join(meta_chars))\n",
    "\n",
    "def infer_geonameid(elements):\n",
    "    try:\n",
    "        return compute_geonameid(elements)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def compute_geonameid(elements):\n",
    "    # Datasets\n",
    "    # * countries_df\n",
    "    # * admin1_df\n",
    "    # * cities_df\n",
    "\n",
    "    # Remove leading/trailing spaces, lowercase\n",
    "    elements = [e.strip().lower() for e in elements]\n",
    "    \n",
    "    # Don't try to infer if element should be ignored\n",
    "    if elements[0] in LOCATION_DISCARD:\n",
    "        return np.nan\n",
    "    \n",
    "    # Filter out Regex 'metacharacters'\n",
    "    elements = [regrex_pattern.sub(r'', e) for e in elements]\n",
    "    \n",
    "    # One item\n",
    "    # TODO: Invert? Check city first, then state, then country?\n",
    "    # e.g. New York is always the city, not the state.\n",
    "    if len(elements) == 1:\n",
    "        country = get_country(countries_df, elements[0])\n",
    "        \n",
    "        # \"<country>\" as-is\n",
    "        if country is not None:\n",
    "            return str(country['geonameid'].item())\n",
    "    \n",
    "        admin1 = get_admin1(admin1_df, elements[0])\n",
    "    \n",
    "        # \"<state/province>\" as-is\n",
    "        if admin1 is not None:\n",
    "            return str(admin1['geonameid'].item())\n",
    "\n",
    "        city = get_city(cities_alt_df, elements[0])\n",
    "        \n",
    "        # \"<city>\" as-is\n",
    "        if city is not None:\n",
    "            return str(city['geonameid'].item())\n",
    "\n",
    "    \n",
    "    # Two items (0, 1)\n",
    "    elif len(elements) == 2:\n",
    "        country = get_country(countries_df, elements[1])\n",
    "        \n",
    "        # if element[1] is country:\n",
    "        if country is not None:\n",
    "            country_code = str(country['#ISO'].item())\n",
    "            \n",
    "            # Get admin1 (restrict to <country>)\n",
    "            admin1 = get_admin1(admin1_df, elements[0], country_code=country_code)\n",
    "    \n",
    "            # if element[0] is <state/province> within <country>:\n",
    "            if admin1 is not None:\n",
    "                return str(admin1['geonameid'].item())\n",
    "            \n",
    "            # Get city (restrict to <country>)\n",
    "            city = get_city(cities_alt_df, elements[0], country_code=country_code)\n",
    "        \n",
    "            # if element[0] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return country\n",
    "            return str(country['geonameid'].item())\n",
    "        \n",
    "        \n",
    "        admin1 = get_admin1(admin1_df, elements[1])\n",
    "        \n",
    "        # if element[1] is <state/province>:\n",
    "        if admin1 is not None:\n",
    "            \n",
    "            # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "            # Split it, then make it into a tuple\n",
    "            country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "            \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[0], admin1_code=admin1_code)\n",
    "            \n",
    "            # if element[0] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return <state/province>\n",
    "            return str(admin1['geonameid'].item())\n",
    "         \n",
    "        city = get_city(cities_alt_df, elements[1])\n",
    "        \n",
    "        # if element[1] is <city>:\n",
    "        if city is not None:\n",
    "            return str(city['geonameid'].item())\n",
    "    \n",
    "    # Three items\n",
    "    elif len(elements) == 3:\n",
    "        \n",
    "        country = get_country(countries_df, elements[2])\n",
    "        \n",
    "        # if element[2] is country:\n",
    "        if country is not None:\n",
    "            country_code = str(country['#ISO'].item())\n",
    "\n",
    "            # Get admin1 (restrict to <country>)\n",
    "            admin1 = get_admin1(admin1_df, elements[1], country_code=country_code)\n",
    "            \n",
    "            # if element[1] is <state/province> within <country>:\n",
    "            if admin1 is not None:\n",
    "                \n",
    "                # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "                # Split it, then make it into a tuple\n",
    "                country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "                \n",
    "                # Get city (restrict to <state/province>)\n",
    "                city = get_city(cities_alt_df, elements[0], admin1_code=admin1_code)\n",
    "                \n",
    "                # if element[0] if <city> within <state/province>\n",
    "                if city is not None:\n",
    "                    # return <city>\n",
    "                    return str(city['geonameid'].item())\n",
    "                   \n",
    "                # return <state/province>\n",
    "                return str(admin1['geonameid'].item())\n",
    "                \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[1], country_code=country_code)\n",
    "                \n",
    "            # if element[1] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                # return <city>\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return country\n",
    "            return str(country['geonameid'].item())\n",
    "            \n",
    "        admin1 = get_admin1(admin1_df, elements[2])\n",
    "        \n",
    "        # if element[2] is <state/province>:\n",
    "        if admin1 is not None:\n",
    "            \n",
    "            # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "            # Split it, then make it into a tuple\n",
    "            country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "            \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[1], admin1_code=admin1_code)\n",
    "            \n",
    "            # if element[1] if <city> within <state/province>\n",
    "            if city is not None:\n",
    "                # return <city>\n",
    "                return str(city['geonameid'].item())\n",
    "            \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>lu.ca</td>\n",
       "      <td>capellen</td>\n",
       "      <td>capellen</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code      name name ascii  geonameid\n",
       "1781  lu.ca  capellen   capellen         99"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infer_geonameid(['ca'])\n",
    "get_admin1(admin1_df, 'ca')\n",
    "# element = \"CA\"\n",
    "# admin1_df[(admin1_df['name'] == element) | \\\n",
    "#                            (admin1_df['name ascii'] == element) | \\\n",
    "#                            (admin1_df['code'].str.contains(f'.{element}$'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_df['geonameid'] = np.nan\n",
    "test_df['geonameid'] = test_df['elements'].map(lambda elements: infer_geonameid(elements))\n",
    "#test_df\n",
    "\n",
    "# Testing one by one\n",
    "# for e in test_df['elements']:\n",
    "#     print(e)\n",
    "#     infer_geonameid(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"As-is\" input\n",
    "# Set the geonameid manually of certain entries of 'tweet_user_location'\n",
    "as_is_locations = {\n",
    "    \"Caracas - Venezuela\": 3640847,\n",
    "    \"日本 東京\": 1850144, # Tokyo\n",
    "    \"México, D.F.\": 3527646,\n",
    "    \"México, DF\": 3527646,\n",
    "    \"México DF\": 3527646,\n",
    "    \"Caracas, Distrito Capital\": 3640847,\n",
    "    \"London UK\": 2643741,\n",
    "    \"Kuala Lumpur Federal Territory\": 1733046,\n",
    "    \"CDMX\": 3527646,\n",
    "    \"Ciudad Autónoma de Buenos Aire\": 690791,\n",
    "    \"Jakarta Capital Region\": 1642911,\n",
    "    \"San Francisco Bay Area\": 5391959,\n",
    "    \"Bay Area\": 5391959,\n",
    "    \"Côte d'Ivoire\": 2287781,\n",
    "    \"Madrid, Comunidad de Madrid\": 3117732, \n",
    "}\n",
    "\n",
    "for location, geonameid in as_is_locations.items():\n",
    "    test_df.loc[(test_df['tweet_user_location'] == location),'geonameid'] = geonameid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.908%\n"
     ]
    }
   ],
   "source": [
    "print_geonameid_completeness(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs: 7158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>JDSupra.com</td>\n",
       "      <td>3520</td>\n",
       "      <td>jdsupra.com</td>\n",
       "      <td>[jdsupra.com]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>3068</td>\n",
       "      <td>national capital region</td>\n",
       "      <td>[national capital region]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Here</td>\n",
       "      <td>2367</td>\n",
       "      <td>here</td>\n",
       "      <td>[here]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>Hell</td>\n",
       "      <td>2289</td>\n",
       "      <td>hell</td>\n",
       "      <td>[hell]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>The World</td>\n",
       "      <td>2204</td>\n",
       "      <td>the world</td>\n",
       "      <td>[the world]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>Porto Velho RO</td>\n",
       "      <td>45</td>\n",
       "      <td>porto velho ro</td>\n",
       "      <td>[porto velho ro]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Eisha</td>\n",
       "      <td>45</td>\n",
       "      <td>eisha</td>\n",
       "      <td>[eisha]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>45</td>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>[兵庫県神戸市]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Cloud Nine</td>\n",
       "      <td>45</td>\n",
       "      <td>cloud nine</td>\n",
       "      <td>[cloud nine]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Denver, Colo.</td>\n",
       "      <td>45</td>\n",
       "      <td>denver, colo</td>\n",
       "      <td>[denver,  colo]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7158 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_user_location  tweet_id tweet_user_location_copy  \\\n",
       "343                JDSupra.com      3520              jdsupra.com   \n",
       "392    National Capital Region      3068  national capital region   \n",
       "504                       Here      2367                     here   \n",
       "521                       Hell      2289                     hell   \n",
       "537                  The World      2204                the world   \n",
       "...                        ...       ...                      ...   \n",
       "19992           Porto Velho RO        45           porto velho ro   \n",
       "19996                    Eisha        45                    eisha   \n",
       "19997                   兵庫県神戸市        45                   兵庫県神戸市   \n",
       "19998               Cloud Nine        45               cloud nine   \n",
       "19999            Denver, Colo.        45             denver, colo   \n",
       "\n",
       "                        elements geonameid  \n",
       "343                [jdsupra.com]       NaN  \n",
       "392    [national capital region]       NaN  \n",
       "504                       [here]       NaN  \n",
       "521                       [hell]       NaN  \n",
       "537                  [the world]       NaN  \n",
       "...                          ...       ...  \n",
       "19992           [porto velho ro]       NaN  \n",
       "19996                    [eisha]       NaN  \n",
       "19997                   [兵庫県神戸市]       NaN  \n",
       "19998               [cloud nine]       NaN  \n",
       "19999            [denver,  colo]       NaN  \n",
       "\n",
       "[7158 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_rows', 200000)\n",
    "show_nan(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6077243'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_geonameid(['columbus', 'ohio', 'usa'])\n",
    "infer_geonameid(['usa'])\n",
    "#get_admin1(admin1_df, 'florida', country_code='US')\n",
    "infer_geonameid(['montreal', 'quebec', 'canada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code, name, name ascii, geonameid]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = 'toronto'\n",
    "admin1_code = 'on'\n",
    "# cities_alt_df[(cities_alt_df['altname'] == element) & \\\n",
    "#               (cities_alt_df['admin1'] == admin1_code)]\n",
    "\n",
    "element = 'england'\n",
    "country_code = 'GB'\n",
    "admin1_df[(admin1_df['code'] == f'{country_code}.{element}') & \\\n",
    "         ((admin1_df['name'] == element) | \\\n",
    "          (admin1_df['name ascii'] == element))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6252001'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countries_df[countries_df['Country'] == 'united states']\n",
    "infer_geonameid(['united states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>US</td>\n",
       "      <td>united states</td>\n",
       "      <td>Washington</td>\n",
       "      <td>9629091.0</td>\n",
       "      <td>327167434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.us</td>\n",
       "      <td>USD</td>\n",
       "      <td>Dollar</td>\n",
       "      <td>1</td>\n",
       "      <td>#####-####</td>\n",
       "      <td>^\\d{5}(-\\d{4})?$</td>\n",
       "      <td>en-US,es-US,haw,fr</td>\n",
       "      <td>6252001</td>\n",
       "      <td>CA,MX,CU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #ISO ISO3 ISO-Numeric fips        Country     Capital  Area(in sq km)  \\\n",
       "233   US  USA         840   US  united states  Washington       9629091.0   \n",
       "\n",
       "    Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "233  327167434       NaN  .us          USD       Dollar     1   \n",
       "\n",
       "    Postal Code Format Postal Code Regex           Languages geonameid  \\\n",
       "233         #####-####  ^\\d{5}(-\\d{4})?$  en-US,es-US,haw,fr   6252001   \n",
       "\n",
       "    neighbours EquivalentFipsCode  \n",
       "233   CA,MX,CU                NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = ['united states']\n",
    "get_country(countries_df, elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-c9ad4ec91786>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_df['url'] = output_df['geonameid'].map(lambda x: get_geoname_url(x))\n"
     ]
    }
   ],
   "source": [
    "# Only keep columns we need\n",
    "output_df = test_df[['tweet_user_location', 'tweet_id', 'geonameid']]\n",
    "output_path = os.path.join(current_dir, \"locations_clean_user_location_geonameid.tsv\")\n",
    "output_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "def get_geoname_url(x):\n",
    "    if not x:\n",
    "        return \"\"\n",
    "    return f\"https://www.geonames.org/{x}\"\n",
    "\n",
    "# Special 'with URL' for fast-checking\n",
    "output_df['url'] = output_df['geonameid'].map(lambda x: get_geoname_url(x))\n",
    "output_path = os.path.join(current_dir, \"locations_clean_user_location_geonameid_url.tsv\")\n",
    "output_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.geonames.org/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>6252001</td>\n",
       "      <td>https://www.geonames.org/6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>1269750</td>\n",
       "      <td>https://www.geonames.org/1269750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>2643743</td>\n",
       "      <td>https://www.geonames.org/2643743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>6252001</td>\n",
       "      <td>https://www.geonames.org/6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>035</td>\n",
       "      <td>45</td>\n",
       "      <td>4563309</td>\n",
       "      <td>https://www.geonames.org/4563309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Eisha</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.geonames.org/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>兵庫県神戸市</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.geonames.org/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Cloud Nine</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.geonames.org/nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>Denver, Colo.</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.geonames.org/nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_user_location  tweet_id geonameid  \\\n",
       "0                    None   4994911       NaN   \n",
       "1           United States    190257   6252001   \n",
       "2                   India     97652   1269750   \n",
       "3         London, England     77542   2643743   \n",
       "4                     USA     67336   6252001   \n",
       "...                   ...       ...       ...   \n",
       "19995                 035        45   4563309   \n",
       "19996               Eisha        45       NaN   \n",
       "19997              兵庫県神戸市        45       NaN   \n",
       "19998          Cloud Nine        45       NaN   \n",
       "19999       Denver, Colo.        45       NaN   \n",
       "\n",
       "                                    url  \n",
       "0          https://www.geonames.org/nan  \n",
       "1      https://www.geonames.org/6252001  \n",
       "2      https://www.geonames.org/1269750  \n",
       "3      https://www.geonames.org/2643743  \n",
       "4      https://www.geonames.org/6252001  \n",
       "...                                 ...  \n",
       "19995  https://www.geonames.org/4563309  \n",
       "19996      https://www.geonames.org/nan  \n",
       "19997      https://www.geonames.org/nan  \n",
       "19998      https://www.geonames.org/nan  \n",
       "19999      https://www.geonames.org/nan  \n",
       "\n",
       "[20000 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
