{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "Loading the datasets and cleaning. The following datasets are expected:\n",
    "* `locations_clean_user_location.tsv`: The original provided list of raw locations with corresponding number of occurances\n",
    "* In `/data`:\n",
    "  * `cities1000.tsv`, cities with > 1000 pop. (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/cities1000.zip\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `countryInfo.tsv`, countries (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/countryInfo.txt\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `admin1CodesASCII.txt`, states and provinces (admin1) (GeoNames)\n",
    "    * https://download.geonames.org/export/dump/admin1CodesASCII.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_user_location  tweet_id\n",
       "0                None   4994911\n",
       "1       United States    190257\n",
       "2               India     97652"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets user locations list\n",
    "# Loading using pandas' read_csv (tab-deleted) to set 'tweet_id' dtype to int\n",
    "\n",
    "tweets_user_locations = os.path.join(current_dir, \"locations_clean_user_location.tsv\")\n",
    "df = pd.read_csv(tweets_user_locations, sep='\\t', dtype={'tweet_id': int})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pndurette/.pyenv/versions/3.8.3/envs/chumblab/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039154</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>Ehl Tarter,Эл Тартер</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1721</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2012-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>San Julia,San Julià,Sant Julia de Loria,Sant J...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2013-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3039604</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Kasa,Пас де ла Каса</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2363</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-06-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid                 name            asciiname  \\\n",
       "0    3039154            El Tarter            El Tarter   \n",
       "1    3039163  Sant Julià de Lòria  Sant Julia de Loria   \n",
       "2    3039604       Pas de la Casa       Pas de la Casa   \n",
       "\n",
       "                                            altnames  latitude  longitude  \\\n",
       "0                               Ehl Tarter,Эл Тартер  42.57952    1.65362   \n",
       "1  San Julia,San Julià,Sant Julia de Loria,Sant J...  42.46372    1.49129   \n",
       "2                      Pas de la Kasa,Пас де ла Каса  42.54277    1.73361   \n",
       "\n",
       "  featclass featcode country  cc2 admin1 admin2 admin3 admin4  population  \\\n",
       "0         P      PPL      AD  NaN     02    NaN    NaN    NaN        1052   \n",
       "1         P     PPLA      AD  NaN     06    NaN    NaN    NaN        8022   \n",
       "2         P      PPL      AD  NaN     03    NaN    NaN    NaN        2363   \n",
       "\n",
       "   elevation  gtopo30        timezone     moddate  \n",
       "0        NaN     1721  Europe/Andorra  2012-11-03  \n",
       "1        NaN      921  Europe/Andorra  2013-11-23  \n",
       "2     2050.0     2106  Europe/Andorra  2008-06-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Cities with > 1000 inabitants)\n",
    "# https://download.geonames.org/export/dump/cities1000.zip\n",
    "# Loading using geopandas for geometry (usefulness tbd)\n",
    "# NB: We can ignore 'DtypeWarning' as we don't need column 13\n",
    "\n",
    "cities = os.path.join(current_dir, data_dir, \"cities1000.tsv\")\n",
    "# cities_df = gpd.read_file(cities)\n",
    "cities_df = pd.read_csv(cities, sep='\\t',\n",
    "            names=['geonameid', 'name', 'asciiname', 'altnames', 'latitude', 'longitude',\n",
    "                   'featclass', 'featcode', 'country', 'cc2', 'admin1', 'admin2', 'admin3', 'admin4',\n",
    "                   'population', 'elevation', 'gtopo30', 'timezone', 'moddate'],\n",
    "            dtype={'admin3': str}) # can't set column 13\n",
    "cities_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "      <th>altname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627577</th>\n",
       "      <td>5128581</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Aebura,Bandar Raya New York,Big Apple,Cathair ...</td>\n",
       "      <td>40.71427</td>\n",
       "      <td>-74.00597</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8175133</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid           name      asciiname  \\\n",
       "627577    5128581  New York City  New York City   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "627577  Aebura,Bandar Raya New York,Big Apple,Cathair ...  40.71427   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "627577  -74.00597         P      PPL      US  NaN     NY    NaN    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30          timezone     moddate altname  \n",
       "627577     8175133       10.0       57  America/New_York  2019-09-23     NYC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate City names\n",
    "# The cities_df dataframe has an 'altnames' column that are CSVs\n",
    "# We transform it to a list then explode it to make searching easier\n",
    "# (and reset the index). The new column 'altname' can be used to search.\n",
    "\n",
    "cities_alt_df = cities_df.assign(\n",
    "    altname=cities_df['altnames'].str.split(',')\n",
    "    ).explode('altname').reset_index(drop=True)\n",
    "\n",
    "cities_alt_df.head(3)\n",
    "\n",
    "cities_alt_df[cities_alt_df['altname'] == 'NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>6058560</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landona,London,Londonas,Londono,YXU,leondeon,l...</td>\n",
       "      <td>42.98339</td>\n",
       "      <td>-81.23304</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>America/Toronto</td>\n",
       "      <td>2012-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48817</th>\n",
       "      <td>2643743</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENG</td>\n",
       "      <td>GLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7556900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>2019-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118957</th>\n",
       "      <td>4119617</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Haddoxburg,London</td>\n",
       "      <td>35.32897</td>\n",
       "      <td>-93.25296</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>115</td>\n",
       "      <td>90813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1046</td>\n",
       "      <td>116.0</td>\n",
       "      <td>121</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120898</th>\n",
       "      <td>4298960</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...</td>\n",
       "      <td>37.12898</td>\n",
       "      <td>-84.08326</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KY</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8126</td>\n",
       "      <td>378.0</td>\n",
       "      <td>379</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122937</th>\n",
       "      <td>4517009</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landon,Limerick,London,New London,lndn,lndn  a...</td>\n",
       "      <td>39.88645</td>\n",
       "      <td>-83.44825</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>097</td>\n",
       "      <td>44674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10060</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132245</th>\n",
       "      <td>5367815</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>London,Londres,New London</td>\n",
       "      <td>36.47606</td>\n",
       "      <td>-119.44318</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1869</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>2011-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid    name asciiname  \\\n",
       "13904     6058560  London    London   \n",
       "48817     2643743  London    London   \n",
       "118957    4119617  London    London   \n",
       "120898    4298960  London    London   \n",
       "122937    4517009  London    London   \n",
       "132245    5367815  London    London   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "13904   Landona,London,Londonas,Londono,YXU,leondeon,l...  42.98339   \n",
       "48817   ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...  51.50853   \n",
       "118957                                  Haddoxburg,London  35.32897   \n",
       "120898  LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...  37.12898   \n",
       "122937  Landon,Limerick,London,New London,lndn,lndn  a...  39.88645   \n",
       "132245                          London,Londres,New London  36.47606   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "13904   -81.23304         P      PPL      CA  NaN     08    NaN    NaN    NaN   \n",
       "48817    -0.12574         P     PPLC      GB  NaN    ENG    GLA    NaN    NaN   \n",
       "118957  -93.25296         P      PPL      US  NaN     AR    115  90813    NaN   \n",
       "120898  -84.08326         P    PPLA2      US  NaN     KY    125    NaN    NaN   \n",
       "122937  -83.44825         P    PPLA2      US  NaN     OH    097  44674    NaN   \n",
       "132245 -119.44318         P      PPL      US  NaN     CA    107    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30             timezone     moddate  \n",
       "13904       346765        NaN      252      America/Toronto  2012-08-19  \n",
       "48817      7556900        NaN       25        Europe/London  2019-09-18  \n",
       "118957        1046      116.0      121      America/Chicago  2017-05-23  \n",
       "120898        8126      378.0      379     America/New_York  2017-03-09  \n",
       "122937       10060      321.0      321     America/New_York  2017-05-23  \n",
       "132245        1869       91.0       93  America/Los_Angeles  2011-05-14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cities finding\n",
    "# City\n",
    "city_test = cities_df[(cities_df['name'] == 'London')]\n",
    "city_test\n",
    "\n",
    "# City & admin1\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG')]\n",
    "city_test\n",
    "\n",
    "# City & admin1 & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City (with the largest population)\n",
    "cities_df[(cities_df['name'] == 'London')].nlargest(1, ['population']) \n",
    "city_test\n",
    "\n",
    "# City with alternative names\n",
    "\n",
    "city_test = cities_df[(cities_df['name'] == 'London')].copy()\n",
    "city_test\n",
    "\n",
    "# city_test.apply(lambda x: x.astype('str').str.split(',')).explode('altnames')\n",
    "# city_test.apply(lambda x: x.astype(str).str.split(',').explode()).reset_index(\n",
    "\n",
    "# city_test = cities_df[(cities_df['name'] == 'LON') | ('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test = cities_df[('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test\n",
    "\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #ISO ISO3  ISO-Numeric fips               Country           Capital  \\\n",
       "0   AD  AND           20   AN               Andorra  Andorra la Vella   \n",
       "1   AE  ARE          784   AE  United Arab Emirates         Abu Dhabi   \n",
       "2   AF  AFG            4   AF           Afghanistan             Kabul   \n",
       "\n",
       "   Area(in sq km)  Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "0           468.0       77006        EU  .ad          EUR         Euro   376   \n",
       "1         82880.0     9630959        AS  .ae          AED       Dirham   971   \n",
       "2        647500.0    37172386        AS  .af          AFN      Afghani    93   \n",
       "\n",
       "  Postal Code Format Postal Code Regex          Languages  geonameid  \\\n",
       "0              AD###  ^(?:AD)*(\\d{3})$                 ca    3041565   \n",
       "1                NaN               NaN  ar-AE,fa,en,hi,ur     290557   \n",
       "2                NaN               NaN  fa-AF,ps,uz-AF,tk    1149361   \n",
       "\n",
       "          neighbours EquivalentFipsCode  \n",
       "0              ES,FR                NaN  \n",
       "1              SA,OM                NaN  \n",
       "2  TM,CN,IR,TJ,PK,UZ                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Countries info)\n",
    "# https://download.geonames.org/export/dump/countryInfo.txt\n",
    "# Loading using pandas' read_csv (tab-deleted), ignore lines 1-48\n",
    "\n",
    "countries = os.path.join(current_dir, data_dir, \"countryInfo.tsv\")\n",
    "countries_df = pd.read_csv(countries, sep='\\t', header=49)\n",
    "countries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 name           name ascii  geonameid\n",
       "0  AD.06  Sant Julià de Loria  Sant Julia de Loria    3039162\n",
       "1  AD.05               Ordino               Ordino    3039676\n",
       "2  AD.04           La Massana           La Massana    3040131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (states and provinces, admin1)\n",
    "# https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
    "# Loading using pandas' read_csv (tab-deleted),\n",
    "# Column names from https://download.geonames.org/export/dump/readme.txt\n",
    "# 'code' is '<country>.<admin1 for country>'\n",
    "\n",
    "admin1 = os.path.join(current_dir, data_dir, \"admin1CodesASCII.txt\")\n",
    "admin1_df = pd.read_csv(admin1, sep='\\t', names=['code', 'name', 'name ascii', 'geonameid'])\n",
    "admin1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>CA.01</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>5883102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>CA.02</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>5909050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>CA.03</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>6065171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>CA.04</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>6087430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>CA.13</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>6091069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>CA.07</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>6091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>CA.14</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>6091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>CA.08</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>6093943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>CA.09</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>6113358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>CA.10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>6115047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>CA.11</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>6141242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>CA.12</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>6185811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>CA.05</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>6354959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>CA.AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>5883102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>CA.BC</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>5909050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>CA.MB</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>6065171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>CA.NB</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>6087430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>CA.NT</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>6091069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>CA.NS</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>6091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>CA.NU</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>6091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>CA.ON</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>6093943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>CA.PE</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>6113358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>CA.QC</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>6115047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>CA.SK</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>6141242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>CA.YK</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>6185811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>CA.NL</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>6354959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                       name                 name ascii  geonameid\n",
       "466   CA.01                    Alberta                    Alberta    5883102\n",
       "467   CA.02           British Columbia           British Columbia    5909050\n",
       "468   CA.03                   Manitoba                   Manitoba    6065171\n",
       "469   CA.04              New Brunswick              New Brunswick    6087430\n",
       "470   CA.13      Northwest Territories      Northwest Territories    6091069\n",
       "471   CA.07                Nova Scotia                Nova Scotia    6091530\n",
       "472   CA.14                    Nunavut                    Nunavut    6091732\n",
       "473   CA.08                    Ontario                    Ontario    6093943\n",
       "474   CA.09       Prince Edward Island       Prince Edward Island    6113358\n",
       "475   CA.10                     Quebec                     Quebec    6115047\n",
       "476   CA.11               Saskatchewan               Saskatchewan    6141242\n",
       "477   CA.12                      Yukon                      Yukon    6185811\n",
       "478   CA.05  Newfoundland and Labrador  Newfoundland and Labrador    6354959\n",
       "3933  CA.AB                    Alberta                    Alberta    5883102\n",
       "3934  CA.BC           British Columbia           British Columbia    5909050\n",
       "3935  CA.MB                   Manitoba                   Manitoba    6065171\n",
       "3936  CA.NB              New Brunswick              New Brunswick    6087430\n",
       "3937  CA.NT      Northwest Territories      Northwest Territories    6091069\n",
       "3938  CA.NS                Nova Scotia                Nova Scotia    6091530\n",
       "3939  CA.NU                    Nunavut                    Nunavut    6091732\n",
       "3940  CA.ON                    Ontario                    Ontario    6093943\n",
       "3941  CA.PE       Prince Edward Island       Prince Edward Island    6113358\n",
       "3942  CA.QC                     Quebec                     Quebec    6115047\n",
       "3943  CA.SK               Saskatchewan               Saskatchewan    6141242\n",
       "3944  CA.YK                      Yukon                      Yukon    6185811\n",
       "3945  CA.NL  Newfoundland and Labrador  Newfoundland and Labrador    6354959"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames 'admin1' (admin1_df) for Canadian provinces uses a 2-digit code\n",
    "# Use postal abbreviation which people use\n",
    "\n",
    "# CA.01\tAlberta\tAlberta\t5883102\n",
    "# CA.02\tBritish Columbia\tBritish Columbia\t5909050\n",
    "# CA.03\tManitoba\tManitoba\t6065171\n",
    "# CA.04\tNew Brunswick\tNew Brunswick\t6087430\n",
    "# CA.13\tNorthwest Territories\tNorthwest Territories\t6091069\n",
    "# CA.07\tNova Scotia\tNova Scotia\t6091530\n",
    "# CA.14\tNunavut\tNunavut\t6091732\n",
    "# CA.08\tOntario\tOntario\t6093943\n",
    "# CA.09\tPrince Edward Island\tPrince Edward Island\t6113358\n",
    "# CA.10\tQuebec\tQuebec\t6115047\n",
    "# CA.11\tSaskatchewan\tSaskatchewan\t6141242\n",
    "# CA.12\tYukon\tYukon\t6185811\n",
    "# CA.05\tNewfoundland and Labrador\tNewfoundland and Labrador\t6354959\n",
    "\n",
    "province_abbr = {\n",
    "    'CA.01': 'CA.AB', # Alberta\n",
    "    'CA.02': 'CA.BC', # British Columbia\n",
    "    'CA.03': 'CA.MB', # Manitoba\n",
    "    'CA.04': 'CA.NB', # New Brunswick\n",
    "    'CA.05': 'CA.NL', # Newfoundland and Labrador\n",
    "    'CA.07': 'CA.NS', # Nova Scotia\n",
    "    'CA.08': 'CA.ON', # Ontario\n",
    "    'CA.09': 'CA.PE', # Prince Edward Island\n",
    "    'CA.10': 'CA.QC', # Quebec\n",
    "    'CA.11': 'CA.SK', # Saskatchewan\n",
    "    'CA.12': 'CA.YK', # Yukon\n",
    "    'CA.13': 'CA.NT', # Northwest Territories\n",
    "    'CA.14': 'CA.NU'  # Nunavut\n",
    "}\n",
    "\n",
    "new_provinces = admin1_df[admin1_df['code'].str.contains('^CA.')].copy()\n",
    "new_provinces['code'] = new_provinces['code'].map(province_abbr)\n",
    "admin1_df = pd.concat([admin1_df, new_provinces], ignore_index=True)\n",
    "admin1_df[admin1_df['code'].str.contains('^CA.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>BO.04</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>HN.12</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>SV.06</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code    name name ascii  geonameid\n",
       "351   BO.04  La Paz     La Paz         99\n",
       "1190  HN.12  La Paz     La Paz         99\n",
       "3288  SV.06  La Paz     La Paz         99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test when there's more than 1 admin1\n",
    "\n",
    "# admin1_df[admin1_df['code'].str.contains('^US.')]\n",
    "# admin1_df[admin1_df['name'] == 'La Paz']\n",
    "country_code = 'HN'\n",
    "element = 'La Paz'\n",
    "test1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "test1.loc[:, 'geonameid'] = 99\n",
    "test11 = test1.head(1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative names (huge DB)\n",
    "\n",
    "# alts = os.path.join(current_dir, data_dir, \"alternateNamesV2.txt\")\n",
    "# alts_df = pd.read_csv(alts, sep='\\t',\n",
    "#             names=['alternateNameId', 'geonameid', 'isolanguage', 'alternate name',\n",
    "#                    'isPreferredName', 'isShortName', 'isColloquial', 'isHistoric', 'from', 'to'])\n",
    "# alts_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alts_df[(alts_df['isPreferredName'] == 1) & (alts_df['alternate name'] == 'République Démocratique Du Congo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add alternative country names (e.g. USA, UK, etc.)\n",
    "# (we can't easily get alternative country names)\n",
    "alternative_country_names = {\n",
    "    6252001: ['USA', 'US','United States of America','America'], # United States\n",
    "    2510769: ['España'], # [Kingdom of] Spain\n",
    "    2635167: ['UK'],     # United Kingdom\n",
    "    1861060: ['日本'],    # Japan\n",
    "    298795: ['Türkiye'], # Turkey\n",
    "    3469034: ['Brasil'], # Brazil\n",
    "    3175395: ['Italia'], # Italy\n",
    "    1694008: ['Republic of the Philippines'], # Philipines\n",
    "    2921044: ['Deutschland'] # Germany\n",
    "}\n",
    "\n",
    "new_countries = pd.DataFrame([], columns=countries_df.columns)\n",
    "for geo, alt_names in alternative_country_names.items():\n",
    "    for name in alt_names:\n",
    "        alt_country = countries_df[countries_df['geonameid'] == geo].copy()\n",
    "        alt_country['Country'] = name\n",
    "        new_countries = pd.concat([new_countries, alt_country], ignore_index=True)\n",
    "\n",
    "countries_df = pd.concat([countries_df, new_countries], ignore_index=True)\n",
    "        \n",
    "# TODO: City alternartives\n",
    "# And others like abbreviations (e.g. CDMX)\n",
    "# Add to list of city alternatives\n",
    "# #3527646: 'CDMX',   # Mexico City "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard specific 'tweet_user_location' strings\n",
    "LOCATION_DISCARD = ['none', '\\\\n', 'global', 'earth',\n",
    "                    'planet earth', 'worldwide', 'everywhere',\n",
    "                    'internet', 'en todas partes',\n",
    "                    'europe', 'africa',\n",
    "                    'world']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the percentage of tweets that have a 'geonameid'\n",
    "# Skipping the ones we know aren't valid (discards)\n",
    "def print_geonameid_completeness(df):\n",
    "    all_tweets = df[~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)]['tweet_id'].sum()\n",
    "    geonameid_tweets = df[df.geonameid.notnull()]['tweet_id'].sum()\n",
    "    print(f'{geonameid_tweets/all_tweets*100:.3f}%')\n",
    "\n",
    "# Show dataframe df where 'geonameid' is NaN and location\n",
    "# is not known to be invalid (discards)\n",
    "def show_nan(df):\n",
    "    nan_df = df[(~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)) & df['geonameid'].isnull()]\n",
    "    print(f'Number of NaNs: {len(nan_df.index)}')\n",
    "    return nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ✈</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338215 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "0                                 None   4994911   \n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "...                                ...       ...   \n",
       "338210      N 52°27' 0'' / W 1°49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ✈          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "0                                 None  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "...                                ...  \n",
       "338210      N 52°27' 0'' / W 1°49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338215 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of 'tweet_user_location' so we leave the original intact\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location']\n",
    "\n",
    "# Discard specific 'tweet_user_location' strings\n",
    "# tweet_user_location_discard = ['None', '\\\\N']\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]\n",
    "\n",
    "# Discard locations that don't exist more than 2 times\n",
    "df = df[df['tweet_id'] > 2]\n",
    "\n",
    "# Filter out emojis and other symbols\n",
    "# * https://stackoverflow.com/a/49986645\n",
    "# * https://www.ling.upenn.edu/courses/Spring_2003/ling538/UnicodeRanges.html (Unicode symbol ranges)\n",
    "import re\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emojis: emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # emojis: symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # emojis: transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # emojis: flags (iOS)\n",
    "        u\"\\U00002700-\\U000027BF\"  # 'Dingbats' http://www.unicode.org/charts/PDF/U2700.pdf\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deEmojify(x))\n",
    "\n",
    "# Truncate leading and trailing spaces\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.strip())\n",
    "\n",
    "# Truncate trailing \",\" and \".\" characters\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip('.'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean: Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything used for comparison lowercase for simplicity\n",
    "\n",
    "# Locations\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].str.lower()\n",
    "\n",
    "# Cities\n",
    "cities_alt_df['name'] = cities_alt_df['name'].str.lower()\n",
    "cities_alt_df['asciiname'] = cities_alt_df['asciiname'].str.lower()\n",
    "cities_alt_df['altname'] = cities_alt_df['altname'].str.lower()\n",
    "\n",
    "# Admin1\n",
    "admin1_df['name'] = admin1_df['name'].str.lower()\n",
    "admin1_df['name ascii'] = admin1_df['name ascii'].str.lower()\n",
    "\n",
    "# Countries\n",
    "countries_df['Country'] = countries_df['Country'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Canada</td>\n",
       "      <td>723</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>712</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>canada</td>\n",
       "      <td>674</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>352</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>199</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Canada</td>\n",
       "      <td>177</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>🇨🇦 Canada</td>\n",
       "      <td>100</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>63</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>Canada🇨🇦</td>\n",
       "      <td>52</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24576</th>\n",
       "      <td>🇨🇦 CANADA</td>\n",
       "      <td>37</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32494</th>\n",
       "      <td>canada</td>\n",
       "      <td>28</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51637</th>\n",
       "      <td>CANADA 🇨🇦</td>\n",
       "      <td>18</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>🇨🇦Canada🇨🇦</td>\n",
       "      <td>17</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78821</th>\n",
       "      <td>🍁 Canada 🍁</td>\n",
       "      <td>12</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79402</th>\n",
       "      <td>Canada 🇨🇦😁</td>\n",
       "      <td>12</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83440</th>\n",
       "      <td>Canada</td>\n",
       "      <td>11</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84848</th>\n",
       "      <td>Canada 🇨🇦🇮🇳</td>\n",
       "      <td>11</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97153</th>\n",
       "      <td>Canada🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97288</th>\n",
       "      <td>CANADA 🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100693</th>\n",
       "      <td>Canada  🇨🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106456</th>\n",
       "      <td>canada🇨🇦🇲🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143425</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143617</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143790</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148946</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155483</th>\n",
       "      <td>🍁Canada🍁</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191476</th>\n",
       "      <td>CANADA 🇨🇦🇬🇧</td>\n",
       "      <td>5</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192221</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224870</th>\n",
       "      <td>Canada🇨🇦 🇵🇹</td>\n",
       "      <td>4</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244818</th>\n",
       "      <td>CANADA🇨🇦🇨🇦🇨🇦</td>\n",
       "      <td>4</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294426</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294428</th>\n",
       "      <td>Canada. 🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294536</th>\n",
       "      <td>Canada 🍁</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294551</th>\n",
       "      <td>Canada 🇨🇦🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_user_location  tweet_id tweet_user_location_copy\n",
       "18                  Canada     40858                   canada\n",
       "1497               Canada        723                   canada\n",
       "1520                CANADA       712                   canada\n",
       "1594                canada       674                   canada\n",
       "2846             Canada 🇨🇦       352                   canada\n",
       "4756               Canada.       199                   canada\n",
       "5333                Canada       177                   canada\n",
       "9208             🇨🇦 Canada       100                   canada\n",
       "14493           Canada 🇨🇦         63                   canada\n",
       "17363             Canada🇨🇦        52                   canada\n",
       "24576            🇨🇦 CANADA        37                   canada\n",
       "32494              canada         28                   canada\n",
       "51637            CANADA 🇨🇦        18                   canada\n",
       "52402           🇨🇦Canada🇨🇦        17                   canada\n",
       "78821           🍁 Canada 🍁        12                   canada\n",
       "79402           Canada 🇨🇦😁        12                   canada\n",
       "83440              Canada         11                   canada\n",
       "84848          Canada 🇨🇦🇮🇳        11                   canada\n",
       "97153              Canada🍁         9                   canada\n",
       "97288             CANADA 🍁         9                   canada\n",
       "100681            Canada           9                   canada\n",
       "100693          Canada  🇨🇦         9                   canada\n",
       "106456          canada🇨🇦🇲🇦         9                   canada\n",
       "143425           Canada 🇨🇦         6                   canada\n",
       "143617             CANADA          6                   canada\n",
       "143790              CANADA         6                   canada\n",
       "148946             CANADA          6                   canada\n",
       "155483            🍁Canada🍁         6                   canada\n",
       "191476         CANADA 🇨🇦🇬🇧         5                   canada\n",
       "192221              Canada         5                   canada\n",
       "224870         Canada🇨🇦 🇵🇹         4                   canada\n",
       "244818        CANADA🇨🇦🇨🇦🇨🇦         4                   canada\n",
       "294426            Canada.          3                   canada\n",
       "294428          Canada. 🇨🇦         3                   canada\n",
       "294536            Canada 🍁         3                   canada\n",
       "294551         Canada 🇨🇦🇨🇦         3                   canada"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations are verbatim the name of a country, e.g.:\n",
    "df[df['tweet_user_location_copy'] == 'canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[df['tweet_user_location'].isin(simple_countries_df['Country'])]\n",
    "# # simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]#.set_index('Country')\n",
    "\n",
    "# # Merge in country info (with goenameid) when there's an exact country match\n",
    "\n",
    "# # Keep the columns of countries_df we need.\n",
    "# simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]\n",
    "# #df = pd.merge(df, simple_countries_df, how='left', left_on='tweet_user_location_copy', right_on='Country')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_geonameid_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_cities_df = cities_df[['geonameid', 'name', 'asciiname', 'altnames']]\n",
    "# df = pd.merge(df, simple_cities_df, how='left', left_on='tweet_user_location', right_on='name')\n",
    "#df_copy = df[df['geonameid'].isnull()]\n",
    "#pd.merge(df_copy, simple_cities_df, how='left', left_on='tweet_user_location_copy', right_on='name')\n",
    "\n",
    "# NB: this can't work b/c cities name (unlike countries) aren't unique, e.g. there's a lot of \"London\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['tweet_user_location_copy'].str.count(',') > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"Toronto, Ontario, Canada, World\"\n",
    "# test = \"Toronto, Canada\"\n",
    "# test.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toronto']\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def split_fixed_parts(num_parts, location):\n",
    "#     parts = location.split(',')\n",
    "#     if num_parts > len(parts):\n",
    "#         for i in range(num_parts - len(parts)):\n",
    "#             parts.insert(0, None)\n",
    "#     else:\n",
    "#         for i in range(len(parts) - num_parts):\n",
    "#             parts.pop(0)\n",
    "#     return parts\n",
    "\n",
    "# def parts_dict(num_parts, location):\n",
    "#     parts = split_fixed_parts(num_parts, location)\n",
    "#     return {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "\n",
    "def split_parts(location):\n",
    "    return location.split(',')\n",
    "\n",
    "# print(split_fixed_parts(3, 'Toronto'))\n",
    "print(split_parts('Toronto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>19371</td>\n",
       "      <td>brooklyn, ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>19062</td>\n",
       "      <td>rio de janeiro, brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>18631</td>\n",
       "      <td>philadelphia, pa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Santiago, Chile</td>\n",
       "      <td>18399</td>\n",
       "      <td>santiago, chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>17821</td>\n",
       "      <td>austin, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>17303</td>\n",
       "      <td>dallas, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>16913</td>\n",
       "      <td>miami, fl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>16777</td>\n",
       "      <td>new jersey, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Madrid, Comunidad de Madrid</td>\n",
       "      <td>16691</td>\n",
       "      <td>madrid, comunidad de madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>İstanbul, Türkiye</td>\n",
       "      <td>16647</td>\n",
       "      <td>i̇stanbul, türkiye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15617</td>\n",
       "      <td>san diego, ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>15586</td>\n",
       "      <td>las vegas, nv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td>14163</td>\n",
       "      <td>michigan, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>14050</td>\n",
       "      <td>pennsylvania, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>North Carolina, USA</td>\n",
       "      <td>13896</td>\n",
       "      <td>north carolina, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>13799</td>\n",
       "      <td>lima, peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>London, UK</td>\n",
       "      <td>13695</td>\n",
       "      <td>london, uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>13605</td>\n",
       "      <td>abuja, nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>13509</td>\n",
       "      <td>sydney, new south wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>13124</td>\n",
       "      <td>johannesburg, south africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>12968</td>\n",
       "      <td>bengaluru, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hyderabad, India</td>\n",
       "      <td>12644</td>\n",
       "      <td>hyderabad, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>12375</td>\n",
       "      <td>ohio, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>12300</td>\n",
       "      <td>virginia, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>11606</td>\n",
       "      <td>portland, or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>11555</td>\n",
       "      <td>melbourne, victoria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_user_location  tweet_id     tweet_user_location_copy\n",
       "3                London, England     77542              london, england\n",
       "6                   New York, NY     64266                 new york, ny\n",
       "7                 Washington, DC     62869               washington, dc\n",
       "8                Los Angeles, CA     61941              los angeles, ca\n",
       "9                California, USA     54503              california, usa\n",
       "11                Lagos, Nigeria     52122               lagos, nigeria\n",
       "14                 Paris, France     46026                paris, france\n",
       "19              New Delhi, India     39714             new delhi, india\n",
       "21                   Chicago, IL     37747                  chicago, il\n",
       "22                  Florida, USA     36840                 florida, usa\n",
       "24       Buenos Aires, Argentina     34826      buenos aires, argentina\n",
       "25                    Texas, USA     33996                   texas, usa\n",
       "29                 New York, USA     31541                new york, usa\n",
       "31       England, United Kingdom     30857      england, united kingdom\n",
       "33                   Atlanta, GA     29293                  atlanta, ga\n",
       "35                 Mumbai, India     27054                mumbai, india\n",
       "36              Toronto, Ontario     27010             toronto, ontario\n",
       "39             San Francisco, CA     26438            san francisco, ca\n",
       "40                   Houston, TX     25425                  houston, tx\n",
       "42                    Boston, MA     24881                   boston, ma\n",
       "46            Caracas, Venezuela     22303           caracas, venezuela\n",
       "47                Nairobi, Kenya     22264               nairobi, kenya\n",
       "48             São Paulo, Brasil     21690            são paulo, brasil\n",
       "49                   Seattle, WA     21279                  seattle, wa\n",
       "54                  Brooklyn, NY     19371                 brooklyn, ny\n",
       "56        Rio de Janeiro, Brasil     19062       rio de janeiro, brasil\n",
       "57              Philadelphia, PA     18631             philadelphia, pa\n",
       "59               Santiago, Chile     18399              santiago, chile\n",
       "61                    Austin, TX     17821                   austin, tx\n",
       "62                    Dallas, TX     17303                   dallas, tx\n",
       "64                     Miami, FL     16913                    miami, fl\n",
       "65               New Jersey, USA     16777              new jersey, usa\n",
       "67   Madrid, Comunidad de Madrid     16691  madrid, comunidad de madrid\n",
       "68             İstanbul, Türkiye     16647           i̇stanbul, türkiye\n",
       "70                 San Diego, CA     15617                san diego, ca\n",
       "71                 Las Vegas, NV     15586                las vegas, nv\n",
       "77                 Michigan, USA     14163                michigan, usa\n",
       "78             Pennsylvania, USA     14050            pennsylvania, usa\n",
       "80           North Carolina, USA     13896          north carolina, usa\n",
       "82                    Lima, Peru     13799                   lima, peru\n",
       "84                    London, UK     13695                   london, uk\n",
       "88                Abuja, Nigeria     13605               abuja, nigeria\n",
       "89       Sydney, New South Wales     13509      sydney, new south wales\n",
       "91    Johannesburg, South Africa     13124   johannesburg, south africa\n",
       "94              Bengaluru, India     12968             bengaluru, india\n",
       "95              Hyderabad, India     12644             hyderabad, india\n",
       "96                     Ohio, USA     12375                    ohio, usa\n",
       "97                 Virginia, USA     12300                virginia, usa\n",
       "100                 Portland, OR     11606                 portland, or\n",
       "101          Melbourne, Victoria     11555          melbourne, victoria"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mini test dataset\n",
    "# df[['column_new_1', 'column_new_2', 'column_new_3']] = pd.DataFrame([[np.nan, 'dogs', 3]], index=df.index)\n",
    "test_df = df[df['tweet_user_location_copy'].str.count(',') == 1].head(50)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>[new york,  ny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>[washington,  dc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>[los angeles,  ca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "      <td>[california,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "      <td>[lagos,  nigeria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "      <td>[paris,  france]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "      <td>[new delhi,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>[chicago,  il]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "      <td>[florida,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "      <td>[buenos aires,  argentina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "      <td>[texas,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "      <td>[new york,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "      <td>[england,  united kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>[atlanta,  ga]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "      <td>[mumbai,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "      <td>[toronto,  ontario]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>[san francisco,  ca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "      <td>[houston,  tx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "      <td>[boston,  ma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "      <td>[caracas,  venezuela]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "      <td>[nairobi,  kenya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "      <td>[são paulo,  brasil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>[seattle,  wa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>19371</td>\n",
       "      <td>brooklyn, ny</td>\n",
       "      <td>[brooklyn,  ny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>19062</td>\n",
       "      <td>rio de janeiro, brasil</td>\n",
       "      <td>[rio de janeiro,  brasil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>18631</td>\n",
       "      <td>philadelphia, pa</td>\n",
       "      <td>[philadelphia,  pa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Santiago, Chile</td>\n",
       "      <td>18399</td>\n",
       "      <td>santiago, chile</td>\n",
       "      <td>[santiago,  chile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>17821</td>\n",
       "      <td>austin, tx</td>\n",
       "      <td>[austin,  tx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>17303</td>\n",
       "      <td>dallas, tx</td>\n",
       "      <td>[dallas,  tx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>16913</td>\n",
       "      <td>miami, fl</td>\n",
       "      <td>[miami,  fl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>16777</td>\n",
       "      <td>new jersey, usa</td>\n",
       "      <td>[new jersey,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Madrid, Comunidad de Madrid</td>\n",
       "      <td>16691</td>\n",
       "      <td>madrid, comunidad de madrid</td>\n",
       "      <td>[madrid,  comunidad de madrid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>İstanbul, Türkiye</td>\n",
       "      <td>16647</td>\n",
       "      <td>i̇stanbul, türkiye</td>\n",
       "      <td>[i̇stanbul,  türkiye]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15617</td>\n",
       "      <td>san diego, ca</td>\n",
       "      <td>[san diego,  ca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>15586</td>\n",
       "      <td>las vegas, nv</td>\n",
       "      <td>[las vegas,  nv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td>14163</td>\n",
       "      <td>michigan, usa</td>\n",
       "      <td>[michigan,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>14050</td>\n",
       "      <td>pennsylvania, usa</td>\n",
       "      <td>[pennsylvania,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>North Carolina, USA</td>\n",
       "      <td>13896</td>\n",
       "      <td>north carolina, usa</td>\n",
       "      <td>[north carolina,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>13799</td>\n",
       "      <td>lima, peru</td>\n",
       "      <td>[lima,  peru]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>London, UK</td>\n",
       "      <td>13695</td>\n",
       "      <td>london, uk</td>\n",
       "      <td>[london,  uk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>13605</td>\n",
       "      <td>abuja, nigeria</td>\n",
       "      <td>[abuja,  nigeria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>13509</td>\n",
       "      <td>sydney, new south wales</td>\n",
       "      <td>[sydney,  new south wales]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>13124</td>\n",
       "      <td>johannesburg, south africa</td>\n",
       "      <td>[johannesburg,  south africa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>12968</td>\n",
       "      <td>bengaluru, india</td>\n",
       "      <td>[bengaluru,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hyderabad, India</td>\n",
       "      <td>12644</td>\n",
       "      <td>hyderabad, india</td>\n",
       "      <td>[hyderabad,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>12375</td>\n",
       "      <td>ohio, usa</td>\n",
       "      <td>[ohio,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>12300</td>\n",
       "      <td>virginia, usa</td>\n",
       "      <td>[virginia,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>11606</td>\n",
       "      <td>portland, or</td>\n",
       "      <td>[portland,  or]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>11555</td>\n",
       "      <td>melbourne, victoria</td>\n",
       "      <td>[melbourne,  victoria]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_user_location  tweet_id     tweet_user_location_copy  \\\n",
       "3                London, England     77542              london, england   \n",
       "6                   New York, NY     64266                 new york, ny   \n",
       "7                 Washington, DC     62869               washington, dc   \n",
       "8                Los Angeles, CA     61941              los angeles, ca   \n",
       "9                California, USA     54503              california, usa   \n",
       "11                Lagos, Nigeria     52122               lagos, nigeria   \n",
       "14                 Paris, France     46026                paris, france   \n",
       "19              New Delhi, India     39714             new delhi, india   \n",
       "21                   Chicago, IL     37747                  chicago, il   \n",
       "22                  Florida, USA     36840                 florida, usa   \n",
       "24       Buenos Aires, Argentina     34826      buenos aires, argentina   \n",
       "25                    Texas, USA     33996                   texas, usa   \n",
       "29                 New York, USA     31541                new york, usa   \n",
       "31       England, United Kingdom     30857      england, united kingdom   \n",
       "33                   Atlanta, GA     29293                  atlanta, ga   \n",
       "35                 Mumbai, India     27054                mumbai, india   \n",
       "36              Toronto, Ontario     27010             toronto, ontario   \n",
       "39             San Francisco, CA     26438            san francisco, ca   \n",
       "40                   Houston, TX     25425                  houston, tx   \n",
       "42                    Boston, MA     24881                   boston, ma   \n",
       "46            Caracas, Venezuela     22303           caracas, venezuela   \n",
       "47                Nairobi, Kenya     22264               nairobi, kenya   \n",
       "48             São Paulo, Brasil     21690            são paulo, brasil   \n",
       "49                   Seattle, WA     21279                  seattle, wa   \n",
       "54                  Brooklyn, NY     19371                 brooklyn, ny   \n",
       "56        Rio de Janeiro, Brasil     19062       rio de janeiro, brasil   \n",
       "57              Philadelphia, PA     18631             philadelphia, pa   \n",
       "59               Santiago, Chile     18399              santiago, chile   \n",
       "61                    Austin, TX     17821                   austin, tx   \n",
       "62                    Dallas, TX     17303                   dallas, tx   \n",
       "64                     Miami, FL     16913                    miami, fl   \n",
       "65               New Jersey, USA     16777              new jersey, usa   \n",
       "67   Madrid, Comunidad de Madrid     16691  madrid, comunidad de madrid   \n",
       "68             İstanbul, Türkiye     16647           i̇stanbul, türkiye   \n",
       "70                 San Diego, CA     15617                san diego, ca   \n",
       "71                 Las Vegas, NV     15586                las vegas, nv   \n",
       "77                 Michigan, USA     14163                michigan, usa   \n",
       "78             Pennsylvania, USA     14050            pennsylvania, usa   \n",
       "80           North Carolina, USA     13896          north carolina, usa   \n",
       "82                    Lima, Peru     13799                   lima, peru   \n",
       "84                    London, UK     13695                   london, uk   \n",
       "88                Abuja, Nigeria     13605               abuja, nigeria   \n",
       "89       Sydney, New South Wales     13509      sydney, new south wales   \n",
       "91    Johannesburg, South Africa     13124   johannesburg, south africa   \n",
       "94              Bengaluru, India     12968             bengaluru, india   \n",
       "95              Hyderabad, India     12644             hyderabad, india   \n",
       "96                     Ohio, USA     12375                    ohio, usa   \n",
       "97                 Virginia, USA     12300                virginia, usa   \n",
       "100                 Portland, OR     11606                 portland, or   \n",
       "101          Melbourne, Victoria     11555          melbourne, victoria   \n",
       "\n",
       "                           elements  \n",
       "3                [london,  england]  \n",
       "6                   [new york,  ny]  \n",
       "7                 [washington,  dc]  \n",
       "8                [los angeles,  ca]  \n",
       "9                [california,  usa]  \n",
       "11                [lagos,  nigeria]  \n",
       "14                 [paris,  france]  \n",
       "19              [new delhi,  india]  \n",
       "21                   [chicago,  il]  \n",
       "22                  [florida,  usa]  \n",
       "24       [buenos aires,  argentina]  \n",
       "25                    [texas,  usa]  \n",
       "29                 [new york,  usa]  \n",
       "31       [england,  united kingdom]  \n",
       "33                   [atlanta,  ga]  \n",
       "35                 [mumbai,  india]  \n",
       "36              [toronto,  ontario]  \n",
       "39             [san francisco,  ca]  \n",
       "40                   [houston,  tx]  \n",
       "42                    [boston,  ma]  \n",
       "46            [caracas,  venezuela]  \n",
       "47                [nairobi,  kenya]  \n",
       "48             [são paulo,  brasil]  \n",
       "49                   [seattle,  wa]  \n",
       "54                  [brooklyn,  ny]  \n",
       "56        [rio de janeiro,  brasil]  \n",
       "57              [philadelphia,  pa]  \n",
       "59               [santiago,  chile]  \n",
       "61                    [austin,  tx]  \n",
       "62                    [dallas,  tx]  \n",
       "64                     [miami,  fl]  \n",
       "65               [new jersey,  usa]  \n",
       "67   [madrid,  comunidad de madrid]  \n",
       "68            [i̇stanbul,  türkiye]  \n",
       "70                 [san diego,  ca]  \n",
       "71                 [las vegas,  nv]  \n",
       "77                 [michigan,  usa]  \n",
       "78             [pennsylvania,  usa]  \n",
       "80           [north carolina,  usa]  \n",
       "82                    [lima,  peru]  \n",
       "84                    [london,  uk]  \n",
       "88                [abuja,  nigeria]  \n",
       "89       [sydney,  new south wales]  \n",
       "91    [johannesburg,  south africa]  \n",
       "94              [bengaluru,  india]  \n",
       "95              [hyderabad,  india]  \n",
       "96                     [ohio,  usa]  \n",
       "97                 [virginia,  usa]  \n",
       "100                 [portland,  or]  \n",
       "101          [melbourne,  victoria]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parts = 3\n",
    "\n",
    "# https://stackoverflow.com/a/16242202\n",
    "#test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))\n",
    "#test_df = pd.concat([test_df, test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))], axis=1)\n",
    "\n",
    "test_df['elements'] = test_df['tweet_user_location_copy'].map(lambda location: location.split(','))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Case incensitive mask/match\n",
    "# e.g. df2 = df1['company_name'].str.contains(\"apple\", na=False, case=False)\n",
    "\n",
    "def get_country(countries_df, element):\n",
    "    # Filter 'Country' field with 'element'\n",
    "    country = countries_df[countries_df['Country'] == element]\n",
    "    \n",
    "    # No results\n",
    "    if len(country) == 0:\n",
    "        return None\n",
    "    \n",
    "    # There can be only one result\n",
    "    return country\n",
    "\n",
    "\n",
    "def get_admin1(admin1_df, element, country_code=None):\n",
    "    if country_code is None:\n",
    "        # admin1 matching name (or ascii name) w/o country\n",
    "        admin1 = admin1_df[(admin1_df['name'] == element) | \\\n",
    "                           (admin1_df['name ascii'] == element)]\n",
    "    \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            return None\n",
    "    \n",
    "        if len(admin1) > 1:\n",
    "            # #ERROR:99\n",
    "            # This error happens when, w/o a country, there is\n",
    "            # more than 1 admin1 by that name/ascii name.\n",
    "            # There is not enough data to infer which one.\n",
    "            # e.g. \"La Paz\" district (Bolivia, Honduras, El Savador)\n",
    "            admin1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "            admin1.loc[:, 'geonameid'] = 99\n",
    "            return admin1.head(1)\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        # admin1 matching name (or ascii name) and country\n",
    "        admin1 = admin1_df[(admin1_df['code'].str.contains(f'^{country_code}.')) & \\\n",
    "                          ((admin1_df['name'] == element) | \\\n",
    "                           (admin1_df['name ascii'] == element))]\n",
    "        \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            # TODO: Look for an abbreviation else return None\n",
    "            return None\n",
    "    \n",
    "    return admin1\n",
    "\n",
    "\n",
    "def get_city(cities_df, element, admin1_code=None, country_code=None):\n",
    "    if admin1_code is None and country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element)]\n",
    "    \n",
    "    elif admin1_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                         (cities_df['country'] == country_code)]\n",
    "    \n",
    "    elif country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code)]\n",
    "    \n",
    "    else:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code) & \\\n",
    "                           (cities_df['country'] == country_code)]\n",
    "    \n",
    "    if len(cities) == 0:\n",
    "        # No results\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # More than one result,\n",
    "        # take the city with the largest population.\n",
    "        return cities.nlargest(1, ['population']) \n",
    "\n",
    "\"\"\"\n",
    "Cases:\n",
    "\n",
    "                  country\n",
    "      state/prov, country\n",
    "            city, country\n",
    "city, state/prov, country\n",
    "\n",
    "city, state/prov, country\n",
    "city, state/prov\n",
    "city, country\n",
    "city\n",
    "\n",
    "neighboorhood, city, country\n",
    "neighboorhood, city\n",
    "\n",
    "state/prov, country\n",
    "state/prov\n",
    "\"\"\"\n",
    "\n",
    "def infer_geonameid(elements):\n",
    "    # Datasets\n",
    "    # * countries_df\n",
    "    # * admin1_df\n",
    "    # * cities_df\n",
    "\n",
    "    # print(elements)\n",
    "    \n",
    "    # Remove leading/trailing spaces\n",
    "    elements = [e.strip() for e in elements]\n",
    "    \n",
    "    # Don't try to infer if element should be ignored\n",
    "    if elements[0] in LOCATION_DISCARD:\n",
    "        pass\n",
    "    \n",
    "    # One item\n",
    "    # TODO: Invert? Check city first, then state, then country?\n",
    "    # e.g. New York is always the city, not the state.\n",
    "    elif len(elements) == 1:\n",
    "        country = get_country(countries_df, elements[0])\n",
    "        \n",
    "        # \"<country>\" as-is\n",
    "        if country is not None:\n",
    "            return str(country['geonameid'].item())\n",
    "    \n",
    "        admin1 = get_admin1(admin1_df, elements[0])\n",
    "    \n",
    "        # \"<state/province>\" as-is\n",
    "        if admin1 is not None:\n",
    "            return str(admin1['geonameid'].item())\n",
    "\n",
    "        city = get_city(cities_alt_df, elements[0])\n",
    "        \n",
    "        # \"<city>\" as-is\n",
    "        if city is not None:\n",
    "            return str(city['geonameid'].item())\n",
    "\n",
    "    \n",
    "    # Two items (0, 1)\n",
    "    elif len(elements) == 2:\n",
    "        \n",
    "        country = get_country(countries_df, elements[1])\n",
    "        \n",
    "        # if element[1] is country:\n",
    "        if country is not None:\n",
    "            country_code = str(country['#ISO'].item())\n",
    "            \n",
    "            # Get admin1 (restrict to <country>)\n",
    "            admin1 = get_admin1(admin1_df, elements[0], country_code=country_code)\n",
    "    \n",
    "            # if element[0] is <state/province> within <country>:\n",
    "            if admin1 is not None:\n",
    "                return str(admin1['geonameid'].item())\n",
    "            \n",
    "            # Get city (restrict to <country>)\n",
    "            city = get_city(cities_alt_df, elements[0], country_code=country_code)\n",
    "        \n",
    "            # if element[0] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return country\n",
    "            return str(country['geonameid'].item())\n",
    "        \n",
    "        # if element[1] is <state/province>:\n",
    "            # if element[0] is <city> within <country>:\n",
    "                # return <city>\n",
    "                \n",
    "            # return <state/province>\n",
    "            \n",
    "        # if element[1] is <city>:\n",
    "        \n",
    "            # return <city>\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # Three items\n",
    "    elif len(elements) == 3:\n",
    "        \n",
    "        # if element[2] is country:\n",
    "            # if element[1] is <state/province> within <country>:\n",
    "                # if element[0] if <city> within <state/province>\n",
    "                    # return <city\n",
    "                    \n",
    "                # return <state/province>\n",
    "                \n",
    "            # if element[1] is city within country:\n",
    "                # return <city>\n",
    "                \n",
    "            # return <country>\n",
    "            \n",
    "        # if element[2] is <state/province>:\n",
    "            # if element[1] if <city> within <state/province>\n",
    "                    # return <city>\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5128581'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_geonameid(['nyc', 'usa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>[new york,  ny]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>[washington,  dc]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>[los angeles,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "      <td>[california,  usa]</td>\n",
       "      <td>5332921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "      <td>[lagos,  nigeria]</td>\n",
       "      <td>2332453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "      <td>[paris,  france]</td>\n",
       "      <td>2988507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "      <td>[new delhi,  india]</td>\n",
       "      <td>1273294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>[chicago,  il]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "      <td>[florida,  usa]</td>\n",
       "      <td>4155751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "      <td>[buenos aires,  argentina]</td>\n",
       "      <td>3435907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "      <td>[texas,  usa]</td>\n",
       "      <td>4736286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "      <td>[new york,  usa]</td>\n",
       "      <td>5128638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "      <td>[england,  united kingdom]</td>\n",
       "      <td>6269131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>[atlanta,  ga]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "      <td>[mumbai,  india]</td>\n",
       "      <td>1275339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "      <td>[toronto,  ontario]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>[san francisco,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "      <td>[houston,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "      <td>[boston,  ma]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "      <td>[caracas,  venezuela]</td>\n",
       "      <td>3646738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "      <td>[nairobi,  kenya]</td>\n",
       "      <td>184745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "      <td>[são paulo,  brasil]</td>\n",
       "      <td>3448433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>[seattle,  wa]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>19371</td>\n",
       "      <td>brooklyn, ny</td>\n",
       "      <td>[brooklyn,  ny]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Rio de Janeiro, Brasil</td>\n",
       "      <td>19062</td>\n",
       "      <td>rio de janeiro, brasil</td>\n",
       "      <td>[rio de janeiro,  brasil]</td>\n",
       "      <td>3451189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>18631</td>\n",
       "      <td>philadelphia, pa</td>\n",
       "      <td>[philadelphia,  pa]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Santiago, Chile</td>\n",
       "      <td>18399</td>\n",
       "      <td>santiago, chile</td>\n",
       "      <td>[santiago,  chile]</td>\n",
       "      <td>3871336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>17821</td>\n",
       "      <td>austin, tx</td>\n",
       "      <td>[austin,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>17303</td>\n",
       "      <td>dallas, tx</td>\n",
       "      <td>[dallas,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>16913</td>\n",
       "      <td>miami, fl</td>\n",
       "      <td>[miami,  fl]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>16777</td>\n",
       "      <td>new jersey, usa</td>\n",
       "      <td>[new jersey,  usa]</td>\n",
       "      <td>5101760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Madrid, Comunidad de Madrid</td>\n",
       "      <td>16691</td>\n",
       "      <td>madrid, comunidad de madrid</td>\n",
       "      <td>[madrid,  comunidad de madrid]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>İstanbul, Türkiye</td>\n",
       "      <td>16647</td>\n",
       "      <td>i̇stanbul, türkiye</td>\n",
       "      <td>[i̇stanbul,  türkiye]</td>\n",
       "      <td>745044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15617</td>\n",
       "      <td>san diego, ca</td>\n",
       "      <td>[san diego,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>15586</td>\n",
       "      <td>las vegas, nv</td>\n",
       "      <td>[las vegas,  nv]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Michigan, USA</td>\n",
       "      <td>14163</td>\n",
       "      <td>michigan, usa</td>\n",
       "      <td>[michigan,  usa]</td>\n",
       "      <td>5001836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>14050</td>\n",
       "      <td>pennsylvania, usa</td>\n",
       "      <td>[pennsylvania,  usa]</td>\n",
       "      <td>6254927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>North Carolina, USA</td>\n",
       "      <td>13896</td>\n",
       "      <td>north carolina, usa</td>\n",
       "      <td>[north carolina,  usa]</td>\n",
       "      <td>4482348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Lima, Peru</td>\n",
       "      <td>13799</td>\n",
       "      <td>lima, peru</td>\n",
       "      <td>[lima,  peru]</td>\n",
       "      <td>3936451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>London, UK</td>\n",
       "      <td>13695</td>\n",
       "      <td>london, uk</td>\n",
       "      <td>[london,  uk]</td>\n",
       "      <td>2643743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Abuja, Nigeria</td>\n",
       "      <td>13605</td>\n",
       "      <td>abuja, nigeria</td>\n",
       "      <td>[abuja,  nigeria]</td>\n",
       "      <td>2352778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>13509</td>\n",
       "      <td>sydney, new south wales</td>\n",
       "      <td>[sydney,  new south wales]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Johannesburg, South Africa</td>\n",
       "      <td>13124</td>\n",
       "      <td>johannesburg, south africa</td>\n",
       "      <td>[johannesburg,  south africa]</td>\n",
       "      <td>993800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>12968</td>\n",
       "      <td>bengaluru, india</td>\n",
       "      <td>[bengaluru,  india]</td>\n",
       "      <td>1277333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Hyderabad, India</td>\n",
       "      <td>12644</td>\n",
       "      <td>hyderabad, india</td>\n",
       "      <td>[hyderabad,  india]</td>\n",
       "      <td>1269843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ohio, USA</td>\n",
       "      <td>12375</td>\n",
       "      <td>ohio, usa</td>\n",
       "      <td>[ohio,  usa]</td>\n",
       "      <td>5165418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virginia, USA</td>\n",
       "      <td>12300</td>\n",
       "      <td>virginia, usa</td>\n",
       "      <td>[virginia,  usa]</td>\n",
       "      <td>6254928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>11606</td>\n",
       "      <td>portland, or</td>\n",
       "      <td>[portland,  or]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>11555</td>\n",
       "      <td>melbourne, victoria</td>\n",
       "      <td>[melbourne,  victoria]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_user_location  tweet_id     tweet_user_location_copy  \\\n",
       "3                London, England     77542              london, england   \n",
       "6                   New York, NY     64266                 new york, ny   \n",
       "7                 Washington, DC     62869               washington, dc   \n",
       "8                Los Angeles, CA     61941              los angeles, ca   \n",
       "9                California, USA     54503              california, usa   \n",
       "11                Lagos, Nigeria     52122               lagos, nigeria   \n",
       "14                 Paris, France     46026                paris, france   \n",
       "19              New Delhi, India     39714             new delhi, india   \n",
       "21                   Chicago, IL     37747                  chicago, il   \n",
       "22                  Florida, USA     36840                 florida, usa   \n",
       "24       Buenos Aires, Argentina     34826      buenos aires, argentina   \n",
       "25                    Texas, USA     33996                   texas, usa   \n",
       "29                 New York, USA     31541                new york, usa   \n",
       "31       England, United Kingdom     30857      england, united kingdom   \n",
       "33                   Atlanta, GA     29293                  atlanta, ga   \n",
       "35                 Mumbai, India     27054                mumbai, india   \n",
       "36              Toronto, Ontario     27010             toronto, ontario   \n",
       "39             San Francisco, CA     26438            san francisco, ca   \n",
       "40                   Houston, TX     25425                  houston, tx   \n",
       "42                    Boston, MA     24881                   boston, ma   \n",
       "46            Caracas, Venezuela     22303           caracas, venezuela   \n",
       "47                Nairobi, Kenya     22264               nairobi, kenya   \n",
       "48             São Paulo, Brasil     21690            são paulo, brasil   \n",
       "49                   Seattle, WA     21279                  seattle, wa   \n",
       "54                  Brooklyn, NY     19371                 brooklyn, ny   \n",
       "56        Rio de Janeiro, Brasil     19062       rio de janeiro, brasil   \n",
       "57              Philadelphia, PA     18631             philadelphia, pa   \n",
       "59               Santiago, Chile     18399              santiago, chile   \n",
       "61                    Austin, TX     17821                   austin, tx   \n",
       "62                    Dallas, TX     17303                   dallas, tx   \n",
       "64                     Miami, FL     16913                    miami, fl   \n",
       "65               New Jersey, USA     16777              new jersey, usa   \n",
       "67   Madrid, Comunidad de Madrid     16691  madrid, comunidad de madrid   \n",
       "68             İstanbul, Türkiye     16647           i̇stanbul, türkiye   \n",
       "70                 San Diego, CA     15617                san diego, ca   \n",
       "71                 Las Vegas, NV     15586                las vegas, nv   \n",
       "77                 Michigan, USA     14163                michigan, usa   \n",
       "78             Pennsylvania, USA     14050            pennsylvania, usa   \n",
       "80           North Carolina, USA     13896          north carolina, usa   \n",
       "82                    Lima, Peru     13799                   lima, peru   \n",
       "84                    London, UK     13695                   london, uk   \n",
       "88                Abuja, Nigeria     13605               abuja, nigeria   \n",
       "89       Sydney, New South Wales     13509      sydney, new south wales   \n",
       "91    Johannesburg, South Africa     13124   johannesburg, south africa   \n",
       "94              Bengaluru, India     12968             bengaluru, india   \n",
       "95              Hyderabad, India     12644             hyderabad, india   \n",
       "96                     Ohio, USA     12375                    ohio, usa   \n",
       "97                 Virginia, USA     12300                virginia, usa   \n",
       "100                 Portland, OR     11606                 portland, or   \n",
       "101          Melbourne, Victoria     11555          melbourne, victoria   \n",
       "\n",
       "                           elements geonameid  \n",
       "3                [london,  england]       NaN  \n",
       "6                   [new york,  ny]       NaN  \n",
       "7                 [washington,  dc]       NaN  \n",
       "8                [los angeles,  ca]       NaN  \n",
       "9                [california,  usa]   5332921  \n",
       "11                [lagos,  nigeria]   2332453  \n",
       "14                 [paris,  france]   2988507  \n",
       "19              [new delhi,  india]   1273294  \n",
       "21                   [chicago,  il]       NaN  \n",
       "22                  [florida,  usa]   4155751  \n",
       "24       [buenos aires,  argentina]   3435907  \n",
       "25                    [texas,  usa]   4736286  \n",
       "29                 [new york,  usa]   5128638  \n",
       "31       [england,  united kingdom]   6269131  \n",
       "33                   [atlanta,  ga]       NaN  \n",
       "35                 [mumbai,  india]   1275339  \n",
       "36              [toronto,  ontario]       NaN  \n",
       "39             [san francisco,  ca]       NaN  \n",
       "40                   [houston,  tx]       NaN  \n",
       "42                    [boston,  ma]       NaN  \n",
       "46            [caracas,  venezuela]   3646738  \n",
       "47                [nairobi,  kenya]    184745  \n",
       "48             [são paulo,  brasil]   3448433  \n",
       "49                   [seattle,  wa]       NaN  \n",
       "54                  [brooklyn,  ny]       NaN  \n",
       "56        [rio de janeiro,  brasil]   3451189  \n",
       "57              [philadelphia,  pa]       NaN  \n",
       "59               [santiago,  chile]   3871336  \n",
       "61                    [austin,  tx]       NaN  \n",
       "62                    [dallas,  tx]       NaN  \n",
       "64                     [miami,  fl]       NaN  \n",
       "65               [new jersey,  usa]   5101760  \n",
       "67   [madrid,  comunidad de madrid]       NaN  \n",
       "68            [i̇stanbul,  türkiye]    745044  \n",
       "70                 [san diego,  ca]       NaN  \n",
       "71                 [las vegas,  nv]       NaN  \n",
       "77                 [michigan,  usa]   5001836  \n",
       "78             [pennsylvania,  usa]   6254927  \n",
       "80           [north carolina,  usa]   4482348  \n",
       "82                    [lima,  peru]   3936451  \n",
       "84                    [london,  uk]   2643743  \n",
       "88                [abuja,  nigeria]   2352778  \n",
       "89       [sydney,  new south wales]       NaN  \n",
       "91    [johannesburg,  south africa]    993800  \n",
       "94              [bengaluru,  india]   1277333  \n",
       "95              [hyderabad,  india]   1269843  \n",
       "96                     [ohio,  usa]   5165418  \n",
       "97                 [virginia,  usa]   6254928  \n",
       "100                 [portland,  or]       NaN  \n",
       "101          [melbourne,  victoria]       NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_df['geonameid'] = np.nan\n",
    "test_df['geonameid'] = test_df['elements'].map(lambda elements: infer_geonameid(elements))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.454%\n"
     ]
    }
   ],
   "source": [
    "print_geonameid_completeness(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>[new york,  ny]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>[washington,  dc]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>[los angeles,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>[chicago,  il]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>[atlanta,  ga]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "      <td>[toronto,  ontario]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>[san francisco,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "      <td>[houston,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "      <td>[boston,  ma]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>[seattle,  wa]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>19371</td>\n",
       "      <td>brooklyn, ny</td>\n",
       "      <td>[brooklyn,  ny]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>18631</td>\n",
       "      <td>philadelphia, pa</td>\n",
       "      <td>[philadelphia,  pa]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>17821</td>\n",
       "      <td>austin, tx</td>\n",
       "      <td>[austin,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>17303</td>\n",
       "      <td>dallas, tx</td>\n",
       "      <td>[dallas,  tx]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>16913</td>\n",
       "      <td>miami, fl</td>\n",
       "      <td>[miami,  fl]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Madrid, Comunidad de Madrid</td>\n",
       "      <td>16691</td>\n",
       "      <td>madrid, comunidad de madrid</td>\n",
       "      <td>[madrid,  comunidad de madrid]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>15617</td>\n",
       "      <td>san diego, ca</td>\n",
       "      <td>[san diego,  ca]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>15586</td>\n",
       "      <td>las vegas, nv</td>\n",
       "      <td>[las vegas,  nv]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>13509</td>\n",
       "      <td>sydney, new south wales</td>\n",
       "      <td>[sydney,  new south wales]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>11606</td>\n",
       "      <td>portland, or</td>\n",
       "      <td>[portland,  or]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>11555</td>\n",
       "      <td>melbourne, victoria</td>\n",
       "      <td>[melbourne,  victoria]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_user_location  tweet_id     tweet_user_location_copy  \\\n",
       "3                London, England     77542              london, england   \n",
       "6                   New York, NY     64266                 new york, ny   \n",
       "7                 Washington, DC     62869               washington, dc   \n",
       "8                Los Angeles, CA     61941              los angeles, ca   \n",
       "21                   Chicago, IL     37747                  chicago, il   \n",
       "33                   Atlanta, GA     29293                  atlanta, ga   \n",
       "36              Toronto, Ontario     27010             toronto, ontario   \n",
       "39             San Francisco, CA     26438            san francisco, ca   \n",
       "40                   Houston, TX     25425                  houston, tx   \n",
       "42                    Boston, MA     24881                   boston, ma   \n",
       "49                   Seattle, WA     21279                  seattle, wa   \n",
       "54                  Brooklyn, NY     19371                 brooklyn, ny   \n",
       "57              Philadelphia, PA     18631             philadelphia, pa   \n",
       "61                    Austin, TX     17821                   austin, tx   \n",
       "62                    Dallas, TX     17303                   dallas, tx   \n",
       "64                     Miami, FL     16913                    miami, fl   \n",
       "67   Madrid, Comunidad de Madrid     16691  madrid, comunidad de madrid   \n",
       "70                 San Diego, CA     15617                san diego, ca   \n",
       "71                 Las Vegas, NV     15586                las vegas, nv   \n",
       "89       Sydney, New South Wales     13509      sydney, new south wales   \n",
       "100                 Portland, OR     11606                 portland, or   \n",
       "101          Melbourne, Victoria     11555          melbourne, victoria   \n",
       "\n",
       "                           elements geonameid  \n",
       "3                [london,  england]       NaN  \n",
       "6                   [new york,  ny]       NaN  \n",
       "7                 [washington,  dc]       NaN  \n",
       "8                [los angeles,  ca]       NaN  \n",
       "21                   [chicago,  il]       NaN  \n",
       "33                   [atlanta,  ga]       NaN  \n",
       "36              [toronto,  ontario]       NaN  \n",
       "39             [san francisco,  ca]       NaN  \n",
       "40                   [houston,  tx]       NaN  \n",
       "42                    [boston,  ma]       NaN  \n",
       "49                   [seattle,  wa]       NaN  \n",
       "54                  [brooklyn,  ny]       NaN  \n",
       "57              [philadelphia,  pa]       NaN  \n",
       "61                    [austin,  tx]       NaN  \n",
       "62                    [dallas,  tx]       NaN  \n",
       "64                     [miami,  fl]       NaN  \n",
       "67   [madrid,  comunidad de madrid]       NaN  \n",
       "70                 [san diego,  ca]       NaN  \n",
       "71                 [las vegas,  nv]       NaN  \n",
       "89       [sydney,  new south wales]       NaN  \n",
       "100                 [portland,  or]       NaN  \n",
       "101          [melbourne,  victoria]       NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nan(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
