{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "Loading the datasets and cleaning. The following datasets are expected:\n",
    "* `locations_clean_user_location.tsv`: The original provided list of raw locations with corresponding number of occurances\n",
    "* In `/data`:\n",
    "  * `cities1000.tsv`, cities with > 1000 pop. (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/cities1000.zip\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `countryInfo.tsv`, countries (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/countryInfo.txt\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `admin1CodesASCII.txt`, states and provinces (admin1) (GeoNames)\n",
    "    * https://download.geonames.org/export/dump/admin1CodesASCII.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_user_location  tweet_id\n",
       "0                None   4994911\n",
       "1       United States    190257\n",
       "2               India     97652"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets user locations list\n",
    "# Loading using pandas' read_csv (tab-deleted) to set 'tweet_id' dtype to int\n",
    "\n",
    "tweets_user_locations = os.path.join(current_dir, \"locations_clean_user_location.tsv\")\n",
    "df = pd.read_csv(tweets_user_locations, sep='\\t', dtype={'tweet_id': int})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039154</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>Ehl Tarter,–≠–ª –¢–∞—Ä—Ç–µ—Ä</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1721</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2012-11-03</td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Juli√† de L√≤ria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>San Julia,San Juli√†,Sant Julia de Loria,Sant J...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3039604</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Kasa,–ü–∞—Å –¥–µ –ª–∞ –ö–∞—Å–∞</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2363.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>POINT (1.73361 42.54277)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geonameid                 name            asciiname  \\\n",
       "0   3039154            El Tarter            El Tarter   \n",
       "1   3039163  Sant Juli√† de L√≤ria  Sant Julia de Loria   \n",
       "2   3039604       Pas de la Casa       Pas de la Casa   \n",
       "\n",
       "                                            altnames  latitude  longitude  \\\n",
       "0                               Ehl Tarter,–≠–ª –¢–∞—Ä—Ç–µ—Ä  42.57952    1.65362   \n",
       "1  San Julia,San Juli√†,Sant Julia de Loria,Sant J...  42.46372    1.49129   \n",
       "2                      Pas de la Kasa,–ü–∞—Å –¥–µ –ª–∞ –ö–∞—Å–∞  42.54277    1.73361   \n",
       "\n",
       "  featclass featcode country cc2 admin1 admin2 admin3 admin4  population  \\\n",
       "0         P      PPL      AD         02                           1052.0   \n",
       "1         P     PPLA      AD         06                           8022.0   \n",
       "2         P      PPL      AD         03                           2363.0   \n",
       "\n",
       "   elevation  gtopo30        timezone     moddate                  geometry  \n",
       "0        NaN     1721  Europe/Andorra  2012-11-03  POINT (1.65362 42.57952)  \n",
       "1        NaN      921  Europe/Andorra  2013-11-23  POINT (1.49129 42.46372)  \n",
       "2     2050.0     2106  Europe/Andorra  2008-06-09  POINT (1.73361 42.54277)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Cities with > 1000 inabitants)\n",
    "# https://download.geonames.org/export/dump/cities1000.zip\n",
    "# Loading using geopandas for geometry (usefulness tbd)\n",
    "\n",
    "cities = os.path.join(current_dir, data_dir, \"cities1000.tsv\")\n",
    "cities_df = gpd.read_file(cities)\n",
    "cities_df.columns = cities_df.columns.str.lower() # lowercase headers\n",
    "cities_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #ISO ISO3  ISO-Numeric fips               Country           Capital  \\\n",
       "0   AD  AND           20   AN               Andorra  Andorra la Vella   \n",
       "1   AE  ARE          784   AE  United Arab Emirates         Abu Dhabi   \n",
       "2   AF  AFG            4   AF           Afghanistan             Kabul   \n",
       "\n",
       "   Area(in sq km)  Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "0           468.0       77006        EU  .ad          EUR         Euro   376   \n",
       "1         82880.0     9630959        AS  .ae          AED       Dirham   971   \n",
       "2        647500.0    37172386        AS  .af          AFN      Afghani    93   \n",
       "\n",
       "  Postal Code Format Postal Code Regex          Languages  geonameid  \\\n",
       "0              AD###  ^(?:AD)*(\\d{3})$                 ca    3041565   \n",
       "1                NaN               NaN  ar-AE,fa,en,hi,ur     290557   \n",
       "2                NaN               NaN  fa-AF,ps,uz-AF,tk    1149361   \n",
       "\n",
       "          neighbours EquivalentFipsCode  \n",
       "0              ES,FR                NaN  \n",
       "1              SA,OM                NaN  \n",
       "2  TM,CN,IR,TJ,PK,UZ                NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Countries info)\n",
    "# https://download.geonames.org/export/dump/countryInfo.txt\n",
    "# Loading using pandas' read_csv (tab-deleted), ignore lines 1-48\n",
    "\n",
    "countries = os.path.join(current_dir, data_dir, \"countryInfo.tsv\")\n",
    "countries_df = pd.read_csv(countries, sep='\\t', header=49)\n",
    "countries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Juli√† de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 name           name ascii  geonameid\n",
       "0  AD.06  Sant Juli√† de Loria  Sant Julia de Loria    3039162\n",
       "1  AD.05               Ordino               Ordino    3039676\n",
       "2  AD.04           La Massana           La Massana    3040131"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (states and provinces, admin1)\n",
    "# https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
    "# Loading using pandas' read_csv (tab-deleted),\n",
    "# Column names from https://download.geonames.org/export/dump/readme.txt\n",
    "# 'code' is '<country>.<admin1 for country>'\n",
    "\n",
    "admin1 = os.path.join(current_dir, data_dir, \"admin1CodesASCII.txt\")\n",
    "admin1_df = pd.read_csv(admin1, sep='\\t', names=['code', 'name', 'name ascii', 'geonameid'])\n",
    "admin1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>CA.01</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>5883102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>CA.02</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>5909050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>CA.03</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>6065171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>CA.04</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>6087430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>CA.13</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>6091069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>CA.07</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>6091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>CA.14</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>6091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>CA.08</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>6093943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>CA.09</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>6113358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>CA.10</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>6115047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>CA.11</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>6141242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>CA.12</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>6185811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>CA.05</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>6354959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>CA.AB</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>5883102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>CA.BC</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>5909050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>CA.MB</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>6065171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>CA.NB</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>New Brunswick</td>\n",
       "      <td>6087430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>CA.NT</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>Northwest Territories</td>\n",
       "      <td>6091069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>CA.NS</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>Nova Scotia</td>\n",
       "      <td>6091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3939</th>\n",
       "      <td>CA.NU</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>Nunavut</td>\n",
       "      <td>6091732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>CA.ON</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>6093943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3941</th>\n",
       "      <td>CA.PE</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>Prince Edward Island</td>\n",
       "      <td>6113358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>CA.QC</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>6115047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>CA.SK</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>6141242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>CA.YK</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>6185811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>CA.NL</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>Newfoundland and Labrador</td>\n",
       "      <td>6354959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code                       name                 name ascii  geonameid\n",
       "466   CA.01                    Alberta                    Alberta    5883102\n",
       "467   CA.02           British Columbia           British Columbia    5909050\n",
       "468   CA.03                   Manitoba                   Manitoba    6065171\n",
       "469   CA.04              New Brunswick              New Brunswick    6087430\n",
       "470   CA.13      Northwest Territories      Northwest Territories    6091069\n",
       "471   CA.07                Nova Scotia                Nova Scotia    6091530\n",
       "472   CA.14                    Nunavut                    Nunavut    6091732\n",
       "473   CA.08                    Ontario                    Ontario    6093943\n",
       "474   CA.09       Prince Edward Island       Prince Edward Island    6113358\n",
       "475   CA.10                     Quebec                     Quebec    6115047\n",
       "476   CA.11               Saskatchewan               Saskatchewan    6141242\n",
       "477   CA.12                      Yukon                      Yukon    6185811\n",
       "478   CA.05  Newfoundland and Labrador  Newfoundland and Labrador    6354959\n",
       "3933  CA.AB                    Alberta                    Alberta    5883102\n",
       "3934  CA.BC           British Columbia           British Columbia    5909050\n",
       "3935  CA.MB                   Manitoba                   Manitoba    6065171\n",
       "3936  CA.NB              New Brunswick              New Brunswick    6087430\n",
       "3937  CA.NT      Northwest Territories      Northwest Territories    6091069\n",
       "3938  CA.NS                Nova Scotia                Nova Scotia    6091530\n",
       "3939  CA.NU                    Nunavut                    Nunavut    6091732\n",
       "3940  CA.ON                    Ontario                    Ontario    6093943\n",
       "3941  CA.PE       Prince Edward Island       Prince Edward Island    6113358\n",
       "3942  CA.QC                     Quebec                     Quebec    6115047\n",
       "3943  CA.SK               Saskatchewan               Saskatchewan    6141242\n",
       "3944  CA.YK                      Yukon                      Yukon    6185811\n",
       "3945  CA.NL  Newfoundland and Labrador  Newfoundland and Labrador    6354959"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames 'admin1' (admin1_df) for Canadian provinces uses a 2-digit code\n",
    "# Use postal abbreviation which people use\n",
    "\n",
    "# CA.01\tAlberta\tAlberta\t5883102\n",
    "# CA.02\tBritish Columbia\tBritish Columbia\t5909050\n",
    "# CA.03\tManitoba\tManitoba\t6065171\n",
    "# CA.04\tNew Brunswick\tNew Brunswick\t6087430\n",
    "# CA.13\tNorthwest Territories\tNorthwest Territories\t6091069\n",
    "# CA.07\tNova Scotia\tNova Scotia\t6091530\n",
    "# CA.14\tNunavut\tNunavut\t6091732\n",
    "# CA.08\tOntario\tOntario\t6093943\n",
    "# CA.09\tPrince Edward Island\tPrince Edward Island\t6113358\n",
    "# CA.10\tQuebec\tQuebec\t6115047\n",
    "# CA.11\tSaskatchewan\tSaskatchewan\t6141242\n",
    "# CA.12\tYukon\tYukon\t6185811\n",
    "# CA.05\tNewfoundland and Labrador\tNewfoundland and Labrador\t6354959\n",
    "\n",
    "province_abbr = {\n",
    "    'CA.01': 'CA.AB', # Alberta\n",
    "    'CA.02': 'CA.BC', # British Columbia\n",
    "    'CA.03': 'CA.MB', # Manitoba\n",
    "    'CA.04': 'CA.NB', # New Brunswick\n",
    "    'CA.05': 'CA.NL', # Newfoundland and Labrador\n",
    "    'CA.07': 'CA.NS', # Nova Scotia\n",
    "    'CA.08': 'CA.ON', # Ontario\n",
    "    'CA.09': 'CA.PE', # Prince Edward Island\n",
    "    'CA.10': 'CA.QC', # Quebec\n",
    "    'CA.11': 'CA.SK', # Saskatchewan\n",
    "    'CA.12': 'CA.YK', # Yukon\n",
    "    'CA.13': 'CA.NT', # Northwest Territories\n",
    "    'CA.14': 'CA.NU'  # Nunavut\n",
    "}\n",
    "\n",
    "new_provinces = admin1_df[admin1_df['code'].str.contains('^CA.')].copy()\n",
    "new_provinces['code'] = new_provinces['code'].map(province_abbr)\n",
    "admin1_df = pd.concat([admin1_df, new_provinces], ignore_index=True)\n",
    "admin1_df[admin1_df['code'].str.contains('^CA.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add alternative country names (USA, UK, etc.z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the percentage of tweets that have a 'geonameid'\n",
    "def print_geonameid_completeness(df):\n",
    "    all_tweets = df['tweet_id'].sum()\n",
    "    geonameid_tweets = df[df.geonameid.notnull()]['tweet_id'].sum()\n",
    "    print(f'{geonameid_tweets/all_tweets*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52¬∞27' 0'' / W 1¬∞49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52¬∞27' 0'' / W 1¬∞49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ‚úà</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338213 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "5                               London     66315   \n",
       "...                                ...       ...   \n",
       "338210      N 52¬∞27' 0'' / W 1¬∞49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ‚úà          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "5                               London  \n",
       "...                                ...  \n",
       "338210      N 52¬∞27' 0'' / W 1¬∞49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338213 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of 'tweet_user_location' so we leave the original intact\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location']\n",
    "\n",
    "# Discard specific 'tweet_user_location' strings\n",
    "tweet_user_location_discard = ['None', '\\\\N']\n",
    "df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]\n",
    "\n",
    "# Discard locations that don't exist more than 2 times\n",
    "df = df[df['tweet_id'] > 2]\n",
    "\n",
    "# Filter out emojis and other symbols\n",
    "# * https://stackoverflow.com/a/49986645\n",
    "# * https://www.ling.upenn.edu/courses/Spring_2003/ling538/UnicodeRanges.html (Unicode symbol ranges)\n",
    "import re\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emojis: emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # emojis: symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # emojis: transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # emojis: flags (iOS)\n",
    "        u\"\\U00002700-\\U000027BF\"  # 'Dingbats' http://www.unicode.org/charts/PDF/U2700.pdf\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deEmojify(x))\n",
    "\n",
    "# Truncate leading and trailing spaces\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.strip())\n",
    "\n",
    "# Truncate trailing \",\" and \".\" characters\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip('.'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Canada</td>\n",
       "      <td>723</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Canada üá®üá¶</td>\n",
       "      <td>352</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>199</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Canada</td>\n",
       "      <td>177</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>üá®üá¶ Canada</td>\n",
       "      <td>100</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>Canada üá®üá¶</td>\n",
       "      <td>63</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>Canadaüá®üá¶</td>\n",
       "      <td>52</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>üá®üá¶Canadaüá®üá¶</td>\n",
       "      <td>17</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78821</th>\n",
       "      <td>üçÅ Canada üçÅ</td>\n",
       "      <td>12</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79402</th>\n",
       "      <td>Canada üá®üá¶üòÅ</td>\n",
       "      <td>12</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83440</th>\n",
       "      <td>Canada</td>\n",
       "      <td>11</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84848</th>\n",
       "      <td>Canada üá®üá¶üáÆüá≥</td>\n",
       "      <td>11</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97153</th>\n",
       "      <td>CanadaüçÅ</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100693</th>\n",
       "      <td>Canada  üá®üá¶</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143425</th>\n",
       "      <td>Canada üá®üá¶</td>\n",
       "      <td>6</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155483</th>\n",
       "      <td>üçÅCanadaüçÅ</td>\n",
       "      <td>6</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192221</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224870</th>\n",
       "      <td>Canadaüá®üá¶ üáµüáπ</td>\n",
       "      <td>4</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294426</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294428</th>\n",
       "      <td>Canada. üá®üá¶</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294536</th>\n",
       "      <td>Canada üçÅ</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294551</th>\n",
       "      <td>Canada üá®üá¶üá®üá¶</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_user_location  tweet_id tweet_user_location_copy\n",
       "18                  Canada     40858                   Canada\n",
       "1497               Canada        723                   Canada\n",
       "2846             Canada üá®üá¶       352                   Canada\n",
       "4756               Canada.       199                   Canada\n",
       "5333                Canada       177                   Canada\n",
       "9208             üá®üá¶ Canada       100                   Canada\n",
       "14493           Canada üá®üá¶         63                   Canada\n",
       "17363             Canadaüá®üá¶        52                   Canada\n",
       "52402           üá®üá¶Canadaüá®üá¶        17                   Canada\n",
       "78821           üçÅ Canada üçÅ        12                   Canada\n",
       "79402           Canada üá®üá¶üòÅ        12                   Canada\n",
       "83440              Canada         11                   Canada\n",
       "84848          Canada üá®üá¶üáÆüá≥        11                   Canada\n",
       "97153              CanadaüçÅ         9                   Canada\n",
       "100681            Canada           9                   Canada\n",
       "100693          Canada  üá®üá¶         9                   Canada\n",
       "143425           Canada üá®üá¶         6                   Canada\n",
       "155483            üçÅCanadaüçÅ         6                   Canada\n",
       "192221              Canada         5                   Canada\n",
       "224870         Canadaüá®üá¶ üáµüáπ         4                   Canada\n",
       "294426            Canada.          3                   Canada\n",
       "294428          Canada. üá®üá¶         3                   Canada\n",
       "294536            Canada üçÅ         3                   Canada\n",
       "294551         Canada üá®üá¶üá®üá¶         3                   Canada"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations are verbatim the name of a country, e.g.:\n",
    "df[df['tweet_user_location_copy'] == 'Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[df['tweet_user_location'].isin(simple_countries_df['Country'])]\n",
    "# # simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]#.set_index('Country')\n",
    "\n",
    "# # Merge in country info (with goenameid) when there's an exact country match\n",
    "\n",
    "# # Keep the columns of countries_df we need.\n",
    "# simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]\n",
    "# #df = pd.merge(df, simple_countries_df, how='left', left_on='tweet_user_location_copy', right_on='Country')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_geonameid_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_cities_df = cities_df[['geonameid', 'name', 'asciiname', 'altnames']]\n",
    "# df = pd.merge(df, simple_cities_df, how='left', left_on='tweet_user_location', right_on='name')\n",
    "#df_copy = df[df['geonameid'].isnull()]\n",
    "#pd.merge(df_copy, simple_cities_df, how='left', left_on='tweet_user_location_copy', right_on='name')\n",
    "\n",
    "# NB: this can't work b/c cities name (unlike countries) aren't unique, e.g. there's a lot of \"London\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['tweet_user_location_copy'].str.count(',') > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"Toronto, Ontario, Canada, World\"\n",
    "# test = \"Toronto, Canada\"\n",
    "# test.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toronto']\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def split_fixed_parts(num_parts, location):\n",
    "#     parts = location.split(',')\n",
    "#     if num_parts > len(parts):\n",
    "#         for i in range(num_parts - len(parts)):\n",
    "#             parts.insert(0, None)\n",
    "#     else:\n",
    "#         for i in range(len(parts) - num_parts):\n",
    "#             parts.pop(0)\n",
    "#     return parts\n",
    "\n",
    "# def parts_dict(num_parts, location):\n",
    "#     parts = split_fixed_parts(num_parts, location)\n",
    "#     return {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "\n",
    "def split_parts(location):\n",
    "    return location.split(',')\n",
    "\n",
    "# print(split_fixed_parts(3, 'Toronto'))\n",
    "print(split_parts('Toronto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M√©xico</td>\n",
       "      <td>46987</td>\n",
       "      <td>M√©xico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>44838</td>\n",
       "      <td>Espa√±a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_user_location  tweet_id tweet_user_location_copy\n",
       "1        United States    190257            United States\n",
       "2                India     97652                    India\n",
       "4                  USA     67336                      USA\n",
       "5               London     66315                   London\n",
       "10              France     54481                   France\n",
       "12      United Kingdom     48965           United Kingdom\n",
       "13              M√©xico     46987                   M√©xico\n",
       "15              Espa√±a     44838                   Espa√±a\n",
       "16             Nigeria     44185                  Nigeria\n",
       "17           Venezuela     42657                Venezuela"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mini test dataset\n",
    "# df[['column_new_1', 'column_new_2', 'column_new_3']] = pd.DataFrame([[np.nan, 'dogs', 3]], index=df.index)\n",
    "test_df = df[df['tweet_user_location_copy'].str.count(',') == 0].head(10)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "      <td>[India]</td>\n",
       "      <td>1269750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "      <td>[London]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>France</td>\n",
       "      <td>[France]</td>\n",
       "      <td>3017382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>2635167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M√©xico</td>\n",
       "      <td>46987</td>\n",
       "      <td>M√©xico</td>\n",
       "      <td>[M√©xico]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>44838</td>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>[Espa√±a]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>[Nigeria]</td>\n",
       "      <td>2328926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>[Venezuela]</td>\n",
       "      <td>3625428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_user_location  tweet_id tweet_user_location_copy          elements  \\\n",
       "1        United States    190257            United States   [United States]   \n",
       "2                India     97652                    India           [India]   \n",
       "4                  USA     67336                      USA             [USA]   \n",
       "5               London     66315                   London          [London]   \n",
       "10              France     54481                   France          [France]   \n",
       "12      United Kingdom     48965           United Kingdom  [United Kingdom]   \n",
       "13              M√©xico     46987                   M√©xico          [M√©xico]   \n",
       "15              Espa√±a     44838                   Espa√±a          [Espa√±a]   \n",
       "16             Nigeria     44185                  Nigeria         [Nigeria]   \n",
       "17           Venezuela     42657                Venezuela       [Venezuela]   \n",
       "\n",
       "   geonameid  \n",
       "1    6252001  \n",
       "2    1269750  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "10   3017382  \n",
       "12   2635167  \n",
       "13       NaN  \n",
       "15       NaN  \n",
       "16   2328926  \n",
       "17   3625428  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parts = 3\n",
    "\n",
    "# https://stackoverflow.com/a/16242202\n",
    "#test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))\n",
    "#test_df = pd.concat([test_df, test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))], axis=1)\n",
    "\n",
    "test_df['elements'] = test_df['tweet_user_location_copy'].map(lambda location: location.split(','))\n",
    "# test_df['elements'] = test_df['elements'].map(lambda x: [i.strip() for i in x if i is not None])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(countries_df, element):\n",
    "    # Filter 'Country' field with 'element'\n",
    "    country = countries_df[countries_df['Country'] == element]\n",
    "    \n",
    "    if len(country) == 0:\n",
    "        # No results\n",
    "        return None\n",
    "    \n",
    "    # There can be only one result\n",
    "    return country\n",
    "    \n",
    "def is_city(element):\n",
    "    pass\n",
    "\n",
    "\"\"\"\n",
    "Cases:\n",
    "\n",
    "                  country\n",
    "      state/prov, country\n",
    "            city, country\n",
    "city, state/prov, country\n",
    "\n",
    "\n",
    "\n",
    "city, state/prov, country\n",
    "city, state/prov\n",
    "city, country\n",
    "city\n",
    "\n",
    "neighboorhood, city, country\n",
    "neighboorhood, city\n",
    "\n",
    "state/prov, country\n",
    "state/prov\n",
    "\"\"\"\n",
    "\n",
    "# def infer_geonameid(elements):\n",
    "#     # Datasets\n",
    "#     # * countries_df\n",
    "#     # * admin1_df\n",
    "#     # * cities_df\n",
    "    \n",
    "#     # print(elements)\n",
    "    \n",
    "#     # Last item is country\n",
    "#     country = get_country(countries_df, elements[-1])\n",
    "#     if country is not None:\n",
    "        \n",
    "#         # Before last item is empty\n",
    "#         if elements[-2] is None:\n",
    "#             return country['geonameid'].item()\n",
    "        \n",
    "#         # Before last item is not empty\n",
    "#         else:\n",
    "#             country_iso_code = country['#ISO'].item()\n",
    "#             return country_iso_code\n",
    "            \n",
    "#     return np.nan\n",
    "\n",
    "def infer_geonameid(elements):\n",
    "    # Datasets\n",
    "    # * countries_df\n",
    "    # * admin1_df\n",
    "    # * cities_df\n",
    "\n",
    "    # print(elements)\n",
    "    \n",
    "    # One item\n",
    "    if len(elements) == 1:\n",
    "        country = get_country(countries_df, elements[0])\n",
    "        \n",
    "        # \"<country>\"\n",
    "        if country is not None:\n",
    "            return str(country['geonameid'].item())\n",
    "    \n",
    "        # \"<state/province>\"\n",
    "        # else check for admin\n",
    "        \n",
    "        # \"<city>\"\n",
    "        # else check for city\n",
    "    \n",
    "    # Two items\n",
    "    elif len(elements) == 2:\n",
    "        \n",
    "        # if element[1] is country:\n",
    "            # if element[0] is <state/province> within <country>:\n",
    "                # return <state/province>\n",
    "                \n",
    "            # if element[0] is <city> within <country>:\n",
    "                # return <city>\n",
    "                \n",
    "            # return country\n",
    "        \n",
    "        # if element[1] is <state/province>:\n",
    "            # if element[0] is <city> within <country>:\n",
    "                # return <city>\n",
    "                \n",
    "            # return <state/province>\n",
    "            \n",
    "        # if element[1] is <city>:\n",
    "        \n",
    "            # return <city>\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    # Three items\n",
    "    elif len(elements) == 3:\n",
    "        \n",
    "        # if element[2] is country:\n",
    "            # if element[1] is <state/province> within <country>:\n",
    "                # if element[0] if <city> within <state/province>\n",
    "                    # return <city\n",
    "                    \n",
    "                # return <state/province>\n",
    "                \n",
    "            # if element[1] is city within country:\n",
    "                # return <city>\n",
    "                \n",
    "            # return <country>\n",
    "            \n",
    "        # if element[2] is <state/province>:\n",
    "            # if element[1] if <city> within <state/province>\n",
    "                    # return <city>\n",
    "        \n",
    "        pass\n",
    "            \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "      <td>[United States]</td>\n",
       "      <td>6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "      <td>[India]</td>\n",
       "      <td>1269750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "      <td>[London]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>France</td>\n",
       "      <td>[France]</td>\n",
       "      <td>3017382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>[United Kingdom]</td>\n",
       "      <td>2635167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M√©xico</td>\n",
       "      <td>46987</td>\n",
       "      <td>M√©xico</td>\n",
       "      <td>[M√©xico]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>44838</td>\n",
       "      <td>Espa√±a</td>\n",
       "      <td>[Espa√±a]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>Nigeria</td>\n",
       "      <td>[Nigeria]</td>\n",
       "      <td>2328926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>[Venezuela]</td>\n",
       "      <td>3625428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_user_location  tweet_id tweet_user_location_copy          elements  \\\n",
       "1        United States    190257            United States   [United States]   \n",
       "2                India     97652                    India           [India]   \n",
       "4                  USA     67336                      USA             [USA]   \n",
       "5               London     66315                   London          [London]   \n",
       "10              France     54481                   France          [France]   \n",
       "12      United Kingdom     48965           United Kingdom  [United Kingdom]   \n",
       "13              M√©xico     46987                   M√©xico          [M√©xico]   \n",
       "15              Espa√±a     44838                   Espa√±a          [Espa√±a]   \n",
       "16             Nigeria     44185                  Nigeria         [Nigeria]   \n",
       "17           Venezuela     42657                Venezuela       [Venezuela]   \n",
       "\n",
       "   geonameid  \n",
       "1    6252001  \n",
       "2    1269750  \n",
       "4        NaN  \n",
       "5        NaN  \n",
       "10   3017382  \n",
       "12   2635167  \n",
       "13       NaN  \n",
       "15       NaN  \n",
       "16   2328926  \n",
       "17   3625428  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['geonameid'] = np.nan\n",
    "test_df['geonameid'] = test_df['elements'].map(lambda elements: infer_geonameid(elements))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.957%\n"
     ]
    }
   ],
   "source": [
    "print_geonameid_completeness(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
