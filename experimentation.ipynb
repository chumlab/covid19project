{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "Loading the datasets and cleaning. The following datasets are expected:\n",
    "* `locations_clean_user_location.tsv`: The original provided list of raw locations with corresponding number of occurances\n",
    "* In `/data`:\n",
    "  * `cities1000.tsv`, cities with > 1000 pop. (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/cities1000.zip\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `countryInfo.tsv`, countries (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/countryInfo.txt\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `admin1CodesASCII.txt`, states and provinces (admin1) (GeoNames)\n",
    "    * https://download.geonames.org/export/dump/admin1CodesASCII.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_user_location  tweet_id\n",
       "0                None   4994911\n",
       "1       United States    190257\n",
       "2               India     97652"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets user locations list\n",
    "# Loading using pandas' read_csv (tab-deleted) to set 'tweet_id' dtype to int\n",
    "\n",
    "tweets_user_locations = os.path.join(current_dir, \"locations_clean_user_location.tsv\")\n",
    "df = pd.read_csv(tweets_user_locations, sep='\\t', dtype={'tweet_id': int})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039154</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>Ehl Tarter,Эл Тартер</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1721</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2012-11-03</td>\n",
       "      <td>POINT (1.65362 42.57952)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>San Julia,San Julià,Sant Julia de Loria,Sant J...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>06</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2013-11-23</td>\n",
       "      <td>POINT (1.49129 42.46372)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3039604</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Kasa,Пас де ла Каса</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td></td>\n",
       "      <td>03</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2363.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>POINT (1.73361 42.54277)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  geonameid                 name            asciiname  \\\n",
       "0   3039154            El Tarter            El Tarter   \n",
       "1   3039163  Sant Julià de Lòria  Sant Julia de Loria   \n",
       "2   3039604       Pas de la Casa       Pas de la Casa   \n",
       "\n",
       "                                            altnames  latitude  longitude  \\\n",
       "0                               Ehl Tarter,Эл Тартер  42.57952    1.65362   \n",
       "1  San Julia,San Julià,Sant Julia de Loria,Sant J...  42.46372    1.49129   \n",
       "2                      Pas de la Kasa,Пас де ла Каса  42.54277    1.73361   \n",
       "\n",
       "  featclass featcode country cc2 admin1 admin2 admin3 admin4  population  \\\n",
       "0         P      PPL      AD         02                           1052.0   \n",
       "1         P     PPLA      AD         06                           8022.0   \n",
       "2         P      PPL      AD         03                           2363.0   \n",
       "\n",
       "   elevation  gtopo30        timezone     moddate                  geometry  \n",
       "0        NaN     1721  Europe/Andorra  2012-11-03  POINT (1.65362 42.57952)  \n",
       "1        NaN      921  Europe/Andorra  2013-11-23  POINT (1.49129 42.46372)  \n",
       "2     2050.0     2106  Europe/Andorra  2008-06-09  POINT (1.73361 42.54277)  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Cities with > 1000 inabitants)\n",
    "# https://download.geonames.org/export/dump/cities1000.zip\n",
    "# Loading using geopandas for geometry (usefulness tbd)\n",
    "\n",
    "cities = os.path.join(current_dir, data_dir, \"cities1000.tsv\")\n",
    "cities_df = gpd.read_file(cities)\n",
    "cities_df.columns = cities_df.columns.str.lower() # lowercase headers\n",
    "cities_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #ISO ISO3  ISO-Numeric fips               Country           Capital  \\\n",
       "0   AD  AND           20   AN               Andorra  Andorra la Vella   \n",
       "1   AE  ARE          784   AE  United Arab Emirates         Abu Dhabi   \n",
       "2   AF  AFG            4   AF           Afghanistan             Kabul   \n",
       "\n",
       "   Area(in sq km)  Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "0           468.0       77006        EU  .ad          EUR         Euro   376   \n",
       "1         82880.0     9630959        AS  .ae          AED       Dirham   971   \n",
       "2        647500.0    37172386        AS  .af          AFN      Afghani    93   \n",
       "\n",
       "  Postal Code Format Postal Code Regex          Languages  geonameid  \\\n",
       "0              AD###  ^(?:AD)*(\\d{3})$                 ca    3041565   \n",
       "1                NaN               NaN  ar-AE,fa,en,hi,ur     290557   \n",
       "2                NaN               NaN  fa-AF,ps,uz-AF,tk    1149361   \n",
       "\n",
       "          neighbours EquivalentFipsCode  \n",
       "0              ES,FR                NaN  \n",
       "1              SA,OM                NaN  \n",
       "2  TM,CN,IR,TJ,PK,UZ                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Countries info)\n",
    "# https://download.geonames.org/export/dump/countryInfo.txt\n",
    "# Loading using pandas' read_csv (tab-deleted), ignore lines 1-48\n",
    "\n",
    "countries = os.path.join(current_dir, data_dir, \"countryInfo.tsv\")\n",
    "countries_df = pd.read_csv(countries, sep='\\t', header=49)\n",
    "countries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 name           name ascii  geonameid\n",
       "0  AD.06  Sant Julià de Loria  Sant Julia de Loria    3039162\n",
       "1  AD.05               Ordino               Ordino    3039676\n",
       "2  AD.04           La Massana           La Massana    3040131"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (states and provinces, admin1)\n",
    "# https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
    "# Loading using pandas' read_csv (tab-deleted),\n",
    "# Column names from https://download.geonames.org/export/dump/readme.txt\n",
    "# 'code' is '<country>.<admin1 for country>'\n",
    "\n",
    "admin1 = os.path.join(current_dir, data_dir, \"admin1CodesASCII.txt\")\n",
    "admin1_df = pd.read_csv(admin1, sep='\\t', names=['code', 'name', 'name ascii', 'geonameid'])\n",
    "admin1_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the percentage of tweets that have a 'geonameid'\n",
    "def print_geonameid_completeness(df):\n",
    "    all_tweets = df['tweet_id'].sum()\n",
    "    geonameid_tweets = df[df.geonameid.notnull()]['tweet_id'].sum()\n",
    "    print(f'{geonameid_tweets/all_tweets*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ✈</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338213 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "5                               London     66315   \n",
       "...                                ...       ...   \n",
       "338210      N 52°27' 0'' / W 1°49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ✈          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "5                               London  \n",
       "...                                ...  \n",
       "338210      N 52°27' 0'' / W 1°49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338213 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of 'tweet_user_location' so we leave the original intact\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location']\n",
    "\n",
    "# Discard specific 'tweet_user_location' strings\n",
    "tweet_user_location_discard = ['None', '\\\\N']\n",
    "df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]\n",
    "\n",
    "# Discard locations that don't exist more than 2 times\n",
    "df = df[df['tweet_id'] > 2]\n",
    "\n",
    "# Filter out emojis and other symbols\n",
    "# * https://stackoverflow.com/a/49986645\n",
    "# * https://www.ling.upenn.edu/courses/Spring_2003/ling538/UnicodeRanges.html (Unicode symbol ranges)\n",
    "import re\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emojis: emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # emojis: symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # emojis: transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # emojis: flags (iOS)\n",
    "        u\"\\U00002700-\\U000027BF\"  # 'Dingbats' http://www.unicode.org/charts/PDF/U2700.pdf\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deEmojify(x))\n",
    "\n",
    "# Truncate leading and trailing spaces\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.strip())\n",
    "\n",
    "# Truncate trailing \",\" and \".\" characters\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip('.'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Canada</td>\n",
       "      <td>723</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>352</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>199</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Canada</td>\n",
       "      <td>177</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>🇨🇦 Canada</td>\n",
       "      <td>100</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>63</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>Canada🇨🇦</td>\n",
       "      <td>52</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>🇨🇦Canada🇨🇦</td>\n",
       "      <td>17</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78821</th>\n",
       "      <td>🍁 Canada 🍁</td>\n",
       "      <td>12</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79402</th>\n",
       "      <td>Canada 🇨🇦😁</td>\n",
       "      <td>12</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83440</th>\n",
       "      <td>Canada</td>\n",
       "      <td>11</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84848</th>\n",
       "      <td>Canada 🇨🇦🇮🇳</td>\n",
       "      <td>11</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97153</th>\n",
       "      <td>Canada🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100693</th>\n",
       "      <td>Canada  🇨🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143425</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>6</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155483</th>\n",
       "      <td>🍁Canada🍁</td>\n",
       "      <td>6</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192221</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224870</th>\n",
       "      <td>Canada🇨🇦 🇵🇹</td>\n",
       "      <td>4</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294426</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294428</th>\n",
       "      <td>Canada. 🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294536</th>\n",
       "      <td>Canada 🍁</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294551</th>\n",
       "      <td>Canada 🇨🇦🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_user_location  tweet_id tweet_user_location_copy\n",
       "18                  Canada     40858                   Canada\n",
       "1497               Canada        723                   Canada\n",
       "2846             Canada 🇨🇦       352                   Canada\n",
       "4756               Canada.       199                   Canada\n",
       "5333                Canada       177                   Canada\n",
       "9208             🇨🇦 Canada       100                   Canada\n",
       "14493           Canada 🇨🇦         63                   Canada\n",
       "17363             Canada🇨🇦        52                   Canada\n",
       "52402           🇨🇦Canada🇨🇦        17                   Canada\n",
       "78821           🍁 Canada 🍁        12                   Canada\n",
       "79402           Canada 🇨🇦😁        12                   Canada\n",
       "83440              Canada         11                   Canada\n",
       "84848          Canada 🇨🇦🇮🇳        11                   Canada\n",
       "97153              Canada🍁         9                   Canada\n",
       "100681            Canada           9                   Canada\n",
       "100693          Canada  🇨🇦         9                   Canada\n",
       "143425           Canada 🇨🇦         6                   Canada\n",
       "155483            🍁Canada🍁         6                   Canada\n",
       "192221              Canada         5                   Canada\n",
       "224870         Canada🇨🇦 🇵🇹         4                   Canada\n",
       "294426            Canada.          3                   Canada\n",
       "294428          Canada. 🇨🇦         3                   Canada\n",
       "294536            Canada 🍁         3                   Canada\n",
       "294551         Canada 🇨🇦🇨🇦         3                   Canada"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations are verbatim the name of a country, e.g.:\n",
    "df[df['tweet_user_location_copy'] == 'Canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ✈</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338213 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "5                               London     66315   \n",
       "...                                ...       ...   \n",
       "338210      N 52°27' 0'' / W 1°49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ✈          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "5                               London  \n",
       "...                                ...  \n",
       "338210      N 52°27' 0'' / W 1°49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338213 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['tweet_user_location'].isin(simple_countries_df['Country'])]\n",
    "# simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]#.set_index('Country')\n",
    "\n",
    "# Merge in country info (with goenameid) when there's an exact country match\n",
    "\n",
    "# Keep the columns of countries_df we need.\n",
    "simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]\n",
    "#df = pd.merge(df, simple_countries_df, how='left', left_on='tweet_user_location_copy', right_on='Country')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_geonameid_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_cities_df = cities_df[['geonameid', 'name', 'asciiname', 'altnames']]\n",
    "# df = pd.merge(df, simple_cities_df, how='left', left_on='tweet_user_location', right_on='name')\n",
    "#df_copy = df[df['geonameid'].isnull()]\n",
    "#pd.merge(df_copy, simple_cities_df, how='left', left_on='tweet_user_location_copy', right_on='name')\n",
    "\n",
    "# NB: this can't work b/c cities name (unlike countries) aren't unique, e.g. there's a lot of \"London\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Bogotá, D.C., Colombia</td>\n",
       "      <td>19367</td>\n",
       "      <td>Bogotá, D.C., Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>2052</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>1398</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Bogotá, DC, Colombia</td>\n",
       "      <td>1176</td>\n",
       "      <td>Bogotá, DC, Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Ottawa, Ontario, Canada</td>\n",
       "      <td>1022</td>\n",
       "      <td>Ottawa, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338095</th>\n",
       "      <td>Chicago, DC, Philly, NYC</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, DC, Philly, NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338103</th>\n",
       "      <td>Winterfel, Banlieue, Velodrome</td>\n",
       "      <td>3</td>\n",
       "      <td>Winterfel, Banlieue, Velodrome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338127</th>\n",
       "      <td>Chapel Hill, NC/Syracuse, NY</td>\n",
       "      <td>3</td>\n",
       "      <td>Chapel Hill, NC/Syracuse, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338191</th>\n",
       "      <td>Chicago, IL &amp; Wangulei,S Sudan</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL &amp; Wangulei,S Sudan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338200</th>\n",
       "      <td>posadas, misiones, argentina</td>\n",
       "      <td>3</td>\n",
       "      <td>posadas, misiones, argentina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16140 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "55              Bogotá, D.C., Colombia     19367   \n",
       "572           Toronto, Ontario, Canada      2052   \n",
       "843     Melbourne, Victoria, Australia      1398   \n",
       "975               Bogotá, DC, Colombia      1176   \n",
       "1111           Ottawa, Ontario, Canada      1022   \n",
       "...                                ...       ...   \n",
       "338095        Chicago, DC, Philly, NYC         3   \n",
       "338103  Winterfel, Banlieue, Velodrome         3   \n",
       "338127    Chapel Hill, NC/Syracuse, NY         3   \n",
       "338191  Chicago, IL & Wangulei,S Sudan         3   \n",
       "338200    posadas, misiones, argentina         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "55              Bogotá, D.C., Colombia  \n",
       "572           Toronto, Ontario, Canada  \n",
       "843     Melbourne, Victoria, Australia  \n",
       "975               Bogotá, DC, Colombia  \n",
       "1111           Ottawa, Ontario, Canada  \n",
       "...                                ...  \n",
       "338095        Chicago, DC, Philly, NYC  \n",
       "338103  Winterfel, Banlieue, Velodrome  \n",
       "338127    Chapel Hill, NC/Syracuse, NY  \n",
       "338191  Chicago, IL & Wangulei,S Sudan  \n",
       "338200    posadas, misiones, argentina  \n",
       "\n",
       "[16140 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tweet_user_location'].str.contains(',.+,')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "      <td>333</td>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "      <td>238</td>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "      <td>202</td>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "      <td>199</td>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Durham, England, UK, EU till I die.</td>\n",
       "      <td>169</td>\n",
       "      <td>Durham, England, UK, EU till I die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336979</th>\n",
       "      <td>Central, Southside, SW, VA</td>\n",
       "      <td>3</td>\n",
       "      <td>Central, Southside, SW, VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337241</th>\n",
       "      <td>EX:Sugar,A2B,eG,RL,CZ,aV,Eyy</td>\n",
       "      <td>3</td>\n",
       "      <td>EX:Sugar,A2B,eG,RL,CZ,aV,Eyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337521</th>\n",
       "      <td>Chicago, Austin, NYC, LA</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, Austin, NYC, LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337587</th>\n",
       "      <td>Chicago, DC, Los Angeles, New York</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, DC, Los Angeles, New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338095</th>\n",
       "      <td>Chicago, DC, Philly, NYC</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, DC, Philly, NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1672 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tweet_user_location  tweet_id  \\\n",
       "2988                           LA,Houston, NYC, ATL,Tampa       333   \n",
       "4053    Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...       238   \n",
       "4698    Paris, France/La Habana, Cuba/México/Roma, Italia       202   \n",
       "4753       Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC       199   \n",
       "5556                  Durham, England, UK, EU till I die.       169   \n",
       "...                                                   ...       ...   \n",
       "336979                         Central, Southside, SW, VA         3   \n",
       "337241                       EX:Sugar,A2B,eG,RL,CZ,aV,Eyy         3   \n",
       "337521                           Chicago, Austin, NYC, LA         3   \n",
       "337587                 Chicago, DC, Los Angeles, New York         3   \n",
       "338095                           Chicago, DC, Philly, NYC         3   \n",
       "\n",
       "                                 tweet_user_location_copy  \n",
       "2988                           LA,Houston, NYC, ATL,Tampa  \n",
       "4053    Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...  \n",
       "4698    Paris, France/La Habana, Cuba/México/Roma, Italia  \n",
       "4753       Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC  \n",
       "5556                   Durham, England, UK, EU till I die  \n",
       "...                                                   ...  \n",
       "336979                         Central, Southside, SW, VA  \n",
       "337241                       EX:Sugar,A2B,eG,RL,CZ,aV,Eyy  \n",
       "337521                           Chicago, Austin, NYC, LA  \n",
       "337587                 Chicago, DC, Los Angeles, New York  \n",
       "338095                           Chicago, DC, Philly, NYC  \n",
       "\n",
       "[1672 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tweet_user_location_copy'].str.count(',') > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toronto', ' Canada']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"Toronto, Ontario, Canada, World\"\n",
    "test = \"Toronto, Canada\"\n",
    "test.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, 'Toronto', ' Canada']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_to_cols(num_parts, location):\n",
    "    parts = location.split(',')\n",
    "    if num_parts > len(parts):\n",
    "        for i in range(num_parts - len(parts)):\n",
    "            parts.insert(0, np.nan)\n",
    "    else:\n",
    "        for i in range(len(parts) - num_parts):\n",
    "            parts.pop(0)\n",
    "    return parts\n",
    "\n",
    "def split_col_names(num_parts):\n",
    "    return [f'element{i}' for i in range(num_parts)]\n",
    "\n",
    "def new_series(num_parts, location):\n",
    "    parts = split_to_cols(num_parts, location)\n",
    "    return {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "\n",
    "#col_parts = {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "#col_parts\n",
    "\n",
    "num_parts = 3  # num_parts-1 commas\n",
    "split_to_cols(num_parts, test)\n",
    "#split_col_names(num_parts)\n",
    "\n",
    "# df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "      <td>333</td>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "      <td>238</td>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "      <td>202</td>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "      <td>199</td>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Durham, England, UK, EU till I die.</td>\n",
       "      <td>169</td>\n",
       "      <td>Durham, England, UK, EU till I die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>Roma, Lazio, Italia, Europa</td>\n",
       "      <td>164</td>\n",
       "      <td>Roma, Lazio, Italia, Europa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>Born: Roma, Italia, Cuban Exile Parents, Grew ...</td>\n",
       "      <td>154</td>\n",
       "      <td>Born: Roma, Italia, Cuban Exile Parents, Grew ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>Ca, Co, NY, Fl, Ak, USA</td>\n",
       "      <td>138</td>\n",
       "      <td>Ca, Co, NY, Fl, Ak, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>Amherst, Pelham, Granby, MA</td>\n",
       "      <td>133</td>\n",
       "      <td>Amherst, Pelham, Granby, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>Bhilai, Pune, Miraj, Riyadh</td>\n",
       "      <td>130</td>\n",
       "      <td>Bhilai, Pune, Miraj, Riyadh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tweet_user_location  tweet_id  \\\n",
       "2988                         LA,Houston, NYC, ATL,Tampa       333   \n",
       "4053  Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...       238   \n",
       "4698  Paris, France/La Habana, Cuba/México/Roma, Italia       202   \n",
       "4753     Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC       199   \n",
       "5556                Durham, England, UK, EU till I die.       169   \n",
       "5732                        Roma, Lazio, Italia, Europa       164   \n",
       "6055  Born: Roma, Italia, Cuban Exile Parents, Grew ...       154   \n",
       "6713                            Ca, Co, NY, Fl, Ak, USA       138   \n",
       "6944                        Amherst, Pelham, Granby, MA       133   \n",
       "7128                        Bhilai, Pune, Miraj, Riyadh       130   \n",
       "\n",
       "                               tweet_user_location_copy  \n",
       "2988                         LA,Houston, NYC, ATL,Tampa  \n",
       "4053  Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...  \n",
       "4698  Paris, France/La Habana, Cuba/México/Roma, Italia  \n",
       "4753     Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC  \n",
       "5556                 Durham, England, UK, EU till I die  \n",
       "5732                        Roma, Lazio, Italia, Europa  \n",
       "6055  Born: Roma, Italia, Cuban Exile Parents, Grew ...  \n",
       "6713                            Ca, Co, NY, Fl, Ak, USA  \n",
       "6944                        Amherst, Pelham, Granby, MA  \n",
       "7128                        Bhilai, Pune, Miraj, Riyadh  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['column_new_1', 'column_new_2', 'column_new_3']] = pd.DataFrame([[np.nan, 'dogs', 3]], index=df.index)\n",
    "test_df = df[df['tweet_user_location_copy'].str.count(',') > 2].head(10)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>el-0</th>\n",
       "      <th>el-1</th>\n",
       "      <th>el-2</th>\n",
       "      <th>el-3</th>\n",
       "      <th>el-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "      <td>333</td>\n",
       "      <td>LA,Houston, NYC, ATL,Tampa</td>\n",
       "      <td>LA</td>\n",
       "      <td>Houston</td>\n",
       "      <td>NYC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Tampa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "      <td>238</td>\n",
       "      <td>Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...</td>\n",
       "      <td>Gedung Graha Pena Lt.10</td>\n",
       "      <td>Jl. Raya Kebayoran Lama No. 12</td>\n",
       "      <td>Kebayoran Lama</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>Indonesia 12210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "      <td>202</td>\n",
       "      <td>Paris, France/La Habana, Cuba/México/Roma, Italia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France/La Habana</td>\n",
       "      <td>Cuba/México/Roma</td>\n",
       "      <td>Italia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "      <td>199</td>\n",
       "      <td>Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC</td>\n",
       "      <td>Lucerne</td>\n",
       "      <td>Suisse</td>\n",
       "      <td>Kinshasa</td>\n",
       "      <td>Bruxelles</td>\n",
       "      <td>Boston RDC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>Durham, England, UK, EU till I die.</td>\n",
       "      <td>169</td>\n",
       "      <td>Durham, England, UK, EU till I die</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durham</td>\n",
       "      <td>England</td>\n",
       "      <td>UK</td>\n",
       "      <td>EU till I die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>Roma, Lazio, Italia, Europa</td>\n",
       "      <td>164</td>\n",
       "      <td>Roma, Lazio, Italia, Europa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Lazio</td>\n",
       "      <td>Italia</td>\n",
       "      <td>Europa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6055</th>\n",
       "      <td>Born: Roma, Italia, Cuban Exile Parents, Grew ...</td>\n",
       "      <td>154</td>\n",
       "      <td>Born: Roma, Italia, Cuban Exile Parents, Grew ...</td>\n",
       "      <td>Born: Roma</td>\n",
       "      <td>Italia</td>\n",
       "      <td>Cuban Exile Parents</td>\n",
       "      <td>Grew Up: NYC Boy</td>\n",
       "      <td>Now Loving Boston!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>Ca, Co, NY, Fl, Ak, USA</td>\n",
       "      <td>138</td>\n",
       "      <td>Ca, Co, NY, Fl, Ak, USA</td>\n",
       "      <td>Co</td>\n",
       "      <td>NY</td>\n",
       "      <td>Fl</td>\n",
       "      <td>Ak</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6944</th>\n",
       "      <td>Amherst, Pelham, Granby, MA</td>\n",
       "      <td>133</td>\n",
       "      <td>Amherst, Pelham, Granby, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amherst</td>\n",
       "      <td>Pelham</td>\n",
       "      <td>Granby</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7128</th>\n",
       "      <td>Bhilai, Pune, Miraj, Riyadh</td>\n",
       "      <td>130</td>\n",
       "      <td>Bhilai, Pune, Miraj, Riyadh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bhilai</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Miraj</td>\n",
       "      <td>Riyadh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tweet_user_location  tweet_id  \\\n",
       "2988                         LA,Houston, NYC, ATL,Tampa       333   \n",
       "4053  Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...       238   \n",
       "4698  Paris, France/La Habana, Cuba/México/Roma, Italia       202   \n",
       "4753     Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC       199   \n",
       "5556                Durham, England, UK, EU till I die.       169   \n",
       "5732                        Roma, Lazio, Italia, Europa       164   \n",
       "6055  Born: Roma, Italia, Cuban Exile Parents, Grew ...       154   \n",
       "6713                            Ca, Co, NY, Fl, Ak, USA       138   \n",
       "6944                        Amherst, Pelham, Granby, MA       133   \n",
       "7128                        Bhilai, Pune, Miraj, Riyadh       130   \n",
       "\n",
       "                               tweet_user_location_copy  \\\n",
       "2988                         LA,Houston, NYC, ATL,Tampa   \n",
       "4053  Gedung Graha Pena Lt.10, Jl. Raya Kebayoran La...   \n",
       "4698  Paris, France/La Habana, Cuba/México/Roma, Italia   \n",
       "4753     Lucerne, Suisse, Kinshasa,Bruxelles,Boston RDC   \n",
       "5556                 Durham, England, UK, EU till I die   \n",
       "5732                        Roma, Lazio, Italia, Europa   \n",
       "6055  Born: Roma, Italia, Cuban Exile Parents, Grew ...   \n",
       "6713                            Ca, Co, NY, Fl, Ak, USA   \n",
       "6944                        Amherst, Pelham, Granby, MA   \n",
       "7128                        Bhilai, Pune, Miraj, Riyadh   \n",
       "\n",
       "                         el-0                             el-1  \\\n",
       "2988                       LA                          Houston   \n",
       "4053  Gedung Graha Pena Lt.10   Jl. Raya Kebayoran Lama No. 12   \n",
       "4698                      NaN                            Paris   \n",
       "4753                  Lucerne                           Suisse   \n",
       "5556                      NaN                           Durham   \n",
       "5732                      NaN                             Roma   \n",
       "6055               Born: Roma                           Italia   \n",
       "6713                       Co                               NY   \n",
       "6944                      NaN                          Amherst   \n",
       "7128                      NaN                           Bhilai   \n",
       "\n",
       "                      el-2               el-3                 el-4  \n",
       "2988                   NYC                ATL                Tampa  \n",
       "4053        Kebayoran Lama    Jakarta Selatan      Indonesia 12210  \n",
       "4698      France/La Habana   Cuba/México/Roma               Italia  \n",
       "4753              Kinshasa          Bruxelles           Boston RDC  \n",
       "5556               England                 UK        EU till I die  \n",
       "5732                 Lazio             Italia               Europa  \n",
       "6055   Cuban Exile Parents   Grew Up: NYC Boy   Now Loving Boston!  \n",
       "6713                    Fl                 Ak                  USA  \n",
       "6944                Pelham             Granby                   MA  \n",
       "7128                  Pune              Miraj               Riyadh  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_parts = 5\n",
    "# for i in split_col_names(num_parts):\n",
    "#     test_df[i] = np.nan\n",
    "    \n",
    "#test_df[split_col_names(num_parts)] = split_to_cols(num_parts, test)\n",
    "#test_df[split_col_names(num_parts)] = test_df[split_col_names(num_parts)].apply(lambda x: [1,2,3])\n",
    "#test_df\n",
    "\n",
    "# test_df.apply(lambda x: x['tweet_user_location_copy'], axis=0)\n",
    "\n",
    "# split_to_cols(num_parts, \"Bogotá, D.C., Colombia\")\n",
    "\n",
    "# https://stackoverflow.com/a/16242202\n",
    "test_df.tweet_user_location_copy.apply(lambda s: pd.Series(new_series(num_parts, s)))\n",
    "pd.concat([test_df, test_df.tweet_user_location_copy.apply(lambda s: pd.Series(new_series(num_parts, s)))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
