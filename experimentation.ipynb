{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation\n",
    "\n",
    "Loading the datasets and cleaning. The following datasets are expected:\n",
    "* `locations_clean_user_location.tsv`: The original provided list of raw locations with corresponding number of occurances\n",
    "* In `/data`:\n",
    "  * `cities1000.tsv`, cities with > 1000 pop. (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/cities1000.zip\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `countryInfo.tsv`, countries (GeoNames):\n",
    "    * https://download.geonames.org/export/dump/countryInfo.txt\n",
    "    * Unzipped and renamed to `.tsv`\n",
    "  * `admin1CodesASCII.txt`, states and provinces (admin1) (GeoNames)\n",
    "    * https://download.geonames.org/export/dump/admin1CodesASCII.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_user_location  tweet_id\n",
       "0                None   4994911\n",
       "1       United States    190257\n",
       "2               India     97652"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tweets user locations list\n",
    "# Loading using pandas' read_csv (tab-deleted) to set 'tweet_id' dtype to int\n",
    "\n",
    "tweets_user_locations = os.path.join(current_dir, \"locations_clean_user_location.tsv\")\n",
    "df = pd.read_csv(tweets_user_locations, sep='\\t', dtype={'tweet_id': int})\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pndurette/.pyenv/versions/3.8.3/envs/chumblab/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3039154</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>Ehl Tarter,Эл Тартер</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1721</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2012-11-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3039163</td>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>San Julia,San Julià,Sant Julia de Loria,Sant J...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>921</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2013-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3039604</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Kasa,Пас де ла Каса</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2363</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2106</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-06-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geonameid                 name            asciiname  \\\n",
       "0    3039154            El Tarter            El Tarter   \n",
       "1    3039163  Sant Julià de Lòria  Sant Julia de Loria   \n",
       "2    3039604       Pas de la Casa       Pas de la Casa   \n",
       "\n",
       "                                            altnames  latitude  longitude  \\\n",
       "0                               Ehl Tarter,Эл Тартер  42.57952    1.65362   \n",
       "1  San Julia,San Julià,Sant Julia de Loria,Sant J...  42.46372    1.49129   \n",
       "2                      Pas de la Kasa,Пас де ла Каса  42.54277    1.73361   \n",
       "\n",
       "  featclass featcode country  cc2 admin1 admin2 admin3 admin4  population  \\\n",
       "0         P      PPL      AD  NaN     02    NaN    NaN    NaN        1052   \n",
       "1         P     PPLA      AD  NaN     06    NaN    NaN    NaN        8022   \n",
       "2         P      PPL      AD  NaN     03    NaN    NaN    NaN        2363   \n",
       "\n",
       "   elevation  gtopo30        timezone     moddate  \n",
       "0        NaN     1721  Europe/Andorra  2012-11-03  \n",
       "1        NaN      921  Europe/Andorra  2013-11-23  \n",
       "2     2050.0     2106  Europe/Andorra  2008-06-09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Cities with > 1000 inabitants)\n",
    "# https://download.geonames.org/export/dump/cities1000.zip\n",
    "# Loading using geopandas for geometry (usefulness tbd)\n",
    "# NB: We can ignore 'DtypeWarning' as we don't need column 13\n",
    "\n",
    "cities = os.path.join(current_dir, data_dir, \"cities1000.tsv\")\n",
    "# cities_df = gpd.read_file(cities)\n",
    "cities_df = pd.read_csv(cities, sep='\\t',\n",
    "            names=['geonameid', 'name', 'asciiname', 'altnames', 'latitude', 'longitude',\n",
    "                   'featclass', 'featcode', 'country', 'cc2', 'admin1', 'admin2', 'admin3', 'admin4',\n",
    "                   'population', 'elevation', 'gtopo30', 'timezone', 'moddate'],\n",
    "            dtype={'admin3': str}) # can't set column 13\n",
    "cities_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "      <th>altname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>627577</th>\n",
       "      <td>5128581</td>\n",
       "      <td>New York City</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Aebura,Bandar Raya New York,Big Apple,Cathair ...</td>\n",
       "      <td>40.71427</td>\n",
       "      <td>-74.00597</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8175133</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid           name      asciiname  \\\n",
       "627577    5128581  New York City  New York City   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "627577  Aebura,Bandar Raya New York,Big Apple,Cathair ...  40.71427   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "627577  -74.00597         P      PPL      US  NaN     NY    NaN    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30          timezone     moddate altname  \n",
       "627577     8175133       10.0       57  America/New_York  2019-09-23     NYC  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternate City names\n",
    "# The cities_df dataframe has an 'altnames' column that are CSVs\n",
    "# We transform it to a list then explode it to make searching easier\n",
    "# (and reset the index). The new column 'altname' can be used to search.\n",
    "\n",
    "cities_alt_df = cities_df.assign(\n",
    "    altname=cities_df['altnames'].str.split(',')\n",
    "    ).explode('altname').reset_index(drop=True)\n",
    "\n",
    "cities_alt_df.head(3)\n",
    "\n",
    "cities_alt_df[cities_alt_df['altname'] == 'NYC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>admin1</th>\n",
       "      <th>admin2</th>\n",
       "      <th>admin3</th>\n",
       "      <th>admin4</th>\n",
       "      <th>population</th>\n",
       "      <th>elevation</th>\n",
       "      <th>gtopo30</th>\n",
       "      <th>timezone</th>\n",
       "      <th>moddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13904</th>\n",
       "      <td>6058560</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landona,London,Londonas,Londono,YXU,leondeon,l...</td>\n",
       "      <td>42.98339</td>\n",
       "      <td>-81.23304</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252</td>\n",
       "      <td>America/Toronto</td>\n",
       "      <td>2012-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48817</th>\n",
       "      <td>2643743</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...</td>\n",
       "      <td>51.50853</td>\n",
       "      <td>-0.12574</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>GB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENG</td>\n",
       "      <td>GLA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7556900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>Europe/London</td>\n",
       "      <td>2019-09-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118957</th>\n",
       "      <td>4119617</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Haddoxburg,London</td>\n",
       "      <td>35.32897</td>\n",
       "      <td>-93.25296</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AR</td>\n",
       "      <td>115</td>\n",
       "      <td>90813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1046</td>\n",
       "      <td>116.0</td>\n",
       "      <td>121</td>\n",
       "      <td>America/Chicago</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120898</th>\n",
       "      <td>4298960</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...</td>\n",
       "      <td>37.12898</td>\n",
       "      <td>-84.08326</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KY</td>\n",
       "      <td>125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8126</td>\n",
       "      <td>378.0</td>\n",
       "      <td>379</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122937</th>\n",
       "      <td>4517009</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Landon,Limerick,London,New London,lndn,lndn  a...</td>\n",
       "      <td>39.88645</td>\n",
       "      <td>-83.44825</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA2</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH</td>\n",
       "      <td>097</td>\n",
       "      <td>44674</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10060</td>\n",
       "      <td>321.0</td>\n",
       "      <td>321</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132245</th>\n",
       "      <td>5367815</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>London,Londres,New London</td>\n",
       "      <td>36.47606</td>\n",
       "      <td>-119.44318</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA</td>\n",
       "      <td>107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1869</td>\n",
       "      <td>91.0</td>\n",
       "      <td>93</td>\n",
       "      <td>America/Los_Angeles</td>\n",
       "      <td>2011-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geonameid    name asciiname  \\\n",
       "13904     6058560  London    London   \n",
       "48817     2643743  London    London   \n",
       "118957    4119617  London    London   \n",
       "120898    4298960  London    London   \n",
       "122937    4517009  London    London   \n",
       "132245    5367815  London    London   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "13904   Landona,London,Londonas,Londono,YXU,leondeon,l...  42.98339   \n",
       "48817   ILondon,LON,Lakana,Landan,Landen,Ljondan,Llund...  51.50853   \n",
       "118957                                  Haddoxburg,London  35.32897   \n",
       "120898  LOZ,Landon,London,Riceton,lndn,lndn  kntaky,lu...  37.12898   \n",
       "122937  Landon,Limerick,London,New London,lndn,lndn  a...  39.88645   \n",
       "132245                          London,Londres,New London  36.47606   \n",
       "\n",
       "        longitude featclass featcode country  cc2 admin1 admin2 admin3 admin4  \\\n",
       "13904   -81.23304         P      PPL      CA  NaN     08    NaN    NaN    NaN   \n",
       "48817    -0.12574         P     PPLC      GB  NaN    ENG    GLA    NaN    NaN   \n",
       "118957  -93.25296         P      PPL      US  NaN     AR    115  90813    NaN   \n",
       "120898  -84.08326         P    PPLA2      US  NaN     KY    125    NaN    NaN   \n",
       "122937  -83.44825         P    PPLA2      US  NaN     OH    097  44674    NaN   \n",
       "132245 -119.44318         P      PPL      US  NaN     CA    107    NaN    NaN   \n",
       "\n",
       "        population  elevation  gtopo30             timezone     moddate  \n",
       "13904       346765        NaN      252      America/Toronto  2012-08-19  \n",
       "48817      7556900        NaN       25        Europe/London  2019-09-18  \n",
       "118957        1046      116.0      121      America/Chicago  2017-05-23  \n",
       "120898        8126      378.0      379     America/New_York  2017-03-09  \n",
       "122937       10060      321.0      321     America/New_York  2017-05-23  \n",
       "132245        1869       91.0       93  America/Los_Angeles  2011-05-14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cities finding\n",
    "# City\n",
    "city_test = cities_df[(cities_df['name'] == 'London')]\n",
    "city_test\n",
    "\n",
    "# City & admin1\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG')]\n",
    "city_test\n",
    "\n",
    "# City & admin1 & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['admin1'] == 'ENG') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City & country\n",
    "city_test = cities_df[(cities_df['name'] == 'London') & \\\n",
    "                      (cities_df['country'] == 'GB')]\n",
    "city_test\n",
    "\n",
    "# City (with the largest population)\n",
    "cities_df[(cities_df['name'] == 'London')].nlargest(1, ['population']) \n",
    "city_test\n",
    "\n",
    "# City with alternative names\n",
    "\n",
    "city_test = cities_df[(cities_df['name'] == 'London')].copy()\n",
    "city_test\n",
    "\n",
    "# city_test.apply(lambda x: x.astype('str').str.split(',')).explode('altnames')\n",
    "# city_test.apply(lambda x: x.astype(str).str.split(',').explode()).reset_index(\n",
    "\n",
    "# city_test = cities_df[(cities_df['name'] == 'LON') | ('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test = cities_df[('LON' in cities_df['altnames'].str.split(',') )]\n",
    "# city_test\n",
    "\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>AND</td>\n",
       "      <td>20</td>\n",
       "      <td>AN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>468.0</td>\n",
       "      <td>77006</td>\n",
       "      <td>EU</td>\n",
       "      <td>.ad</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Euro</td>\n",
       "      <td>376</td>\n",
       "      <td>AD###</td>\n",
       "      <td>^(?:AD)*(\\d{3})$</td>\n",
       "      <td>ca</td>\n",
       "      <td>3041565</td>\n",
       "      <td>ES,FR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>ARE</td>\n",
       "      <td>784</td>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>9630959</td>\n",
       "      <td>AS</td>\n",
       "      <td>.ae</td>\n",
       "      <td>AED</td>\n",
       "      <td>Dirham</td>\n",
       "      <td>971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ar-AE,fa,en,hi,ur</td>\n",
       "      <td>290557</td>\n",
       "      <td>SA,OM</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AF</td>\n",
       "      <td>AFG</td>\n",
       "      <td>4</td>\n",
       "      <td>AF</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Kabul</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>37172386</td>\n",
       "      <td>AS</td>\n",
       "      <td>.af</td>\n",
       "      <td>AFN</td>\n",
       "      <td>Afghani</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fa-AF,ps,uz-AF,tk</td>\n",
       "      <td>1149361</td>\n",
       "      <td>TM,CN,IR,TJ,PK,UZ</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #ISO ISO3  ISO-Numeric fips               Country           Capital  \\\n",
       "0   AD  AND           20   AN               Andorra  Andorra la Vella   \n",
       "1   AE  ARE          784   AE  United Arab Emirates         Abu Dhabi   \n",
       "2   AF  AFG            4   AF           Afghanistan             Kabul   \n",
       "\n",
       "   Area(in sq km)  Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "0           468.0       77006        EU  .ad          EUR         Euro   376   \n",
       "1         82880.0     9630959        AS  .ae          AED       Dirham   971   \n",
       "2        647500.0    37172386        AS  .af          AFN      Afghani    93   \n",
       "\n",
       "  Postal Code Format Postal Code Regex          Languages  geonameid  \\\n",
       "0              AD###  ^(?:AD)*(\\d{3})$                 ca    3041565   \n",
       "1                NaN               NaN  ar-AE,fa,en,hi,ur     290557   \n",
       "2                NaN               NaN  fa-AF,ps,uz-AF,tk    1149361   \n",
       "\n",
       "          neighbours EquivalentFipsCode  \n",
       "0              ES,FR                NaN  \n",
       "1              SA,OM                NaN  \n",
       "2  TM,CN,IR,TJ,PK,UZ                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (Countries info)\n",
    "# https://download.geonames.org/export/dump/countryInfo.txt\n",
    "# Loading using pandas' read_csv (tab-deleted), ignore lines 1-48\n",
    "\n",
    "countries = os.path.join(current_dir, data_dir, \"countryInfo.tsv\")\n",
    "countries_df = pd.read_csv(countries, sep='\\t', header=49)\n",
    "countries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD.06</td>\n",
       "      <td>Sant Julià de Loria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>3039162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD.05</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>3039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD.04</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>La Massana</td>\n",
       "      <td>3040131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                 name           name ascii  geonameid\n",
       "0  AD.06  Sant Julià de Loria  Sant Julia de Loria    3039162\n",
       "1  AD.05               Ordino               Ordino    3039676\n",
       "2  AD.04           La Massana           La Massana    3040131"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames (states and provinces, admin1)\n",
    "# https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
    "# Loading using pandas' read_csv (tab-deleted),\n",
    "# Column names from https://download.geonames.org/export/dump/readme.txt\n",
    "# 'code' is '<country>.<admin1 for country>'\n",
    "\n",
    "admin1 = os.path.join(current_dir, data_dir, \"admin1CodesASCII.txt\")\n",
    "admin1_df = pd.read_csv(admin1, sep='\\t', names=['code', 'name', 'name ascii', 'geonameid'])\n",
    "admin1_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>CA.08</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>6093943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      code     name name ascii  geonameid\n",
       "473  CA.08  Ontario    Ontario    6093943"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin1_df[admin1_df['name'] == 'Ontario']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>altnames</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>featclass</th>\n",
       "      <th>featcode</th>\n",
       "      <th>country</th>\n",
       "      <th>cc2</th>\n",
       "      <th>...</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678465</th>\n",
       "      <td>5882600</td>\n",
       "      <td>Agincourt North</td>\n",
       "      <td>Agincourt North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.80418</td>\n",
       "      <td>-79.27528</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678466</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678467</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678468</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678469</th>\n",
       "      <td>5882873</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax</td>\n",
       "      <td>Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...</td>\n",
       "      <td>43.85012</td>\n",
       "      <td>-79.03288</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679962</th>\n",
       "      <td>12156903</td>\n",
       "      <td>Downsview-Roding-CFB</td>\n",
       "      <td>Downsview-Roding-CFB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.73329</td>\n",
       "      <td>-79.49049</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679963</th>\n",
       "      <td>12156904</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>Glenfield-Jane Heights</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.74564</td>\n",
       "      <td>-79.51347</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679964</th>\n",
       "      <td>12156905</td>\n",
       "      <td>High Park-Swansea</td>\n",
       "      <td>High Park-Swansea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.64506</td>\n",
       "      <td>-79.46787</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679965</th>\n",
       "      <td>12156906</td>\n",
       "      <td>Kingsview Village-The Westway</td>\n",
       "      <td>Kingsview Village-The Westway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.69899</td>\n",
       "      <td>-79.54786</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679966</th>\n",
       "      <td>12156907</td>\n",
       "      <td>Kingsway South</td>\n",
       "      <td>Kingsway South</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.65352</td>\n",
       "      <td>-79.51058</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLX</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1502 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geonameid                           name  \\\n",
       "678465   5882600                Agincourt North   \n",
       "678466   5882873                           Ajax   \n",
       "678467   5882873                           Ajax   \n",
       "678468   5882873                           Ajax   \n",
       "678469   5882873                           Ajax   \n",
       "...          ...                            ...   \n",
       "679962  12156903           Downsview-Roding-CFB   \n",
       "679963  12156904         Glenfield-Jane Heights   \n",
       "679964  12156905              High Park-Swansea   \n",
       "679965  12156906  Kingsview Village-The Westway   \n",
       "679966  12156907                 Kingsway South   \n",
       "\n",
       "                            asciiname  \\\n",
       "678465                Agincourt North   \n",
       "678466                           Ajax   \n",
       "678467                           Ajax   \n",
       "678468                           Ajax   \n",
       "678469                           Ajax   \n",
       "...                               ...   \n",
       "679962           Downsview-Roding-CFB   \n",
       "679963         Glenfield-Jane Heights   \n",
       "679964              High Park-Swansea   \n",
       "679965  Kingsview Village-The Westway   \n",
       "679966                 Kingsway South   \n",
       "\n",
       "                                                 altnames  latitude  \\\n",
       "678465                                                NaN  43.80418   \n",
       "678466  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678467  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678468  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "678469  Adzhaks,Ehjdzhaks,Ejdzaks,ajaks,ajaks  antaryw...  43.85012   \n",
       "...                                                   ...       ...   \n",
       "679962                                                NaN  43.73329   \n",
       "679963                                                NaN  43.74564   \n",
       "679964                                                NaN  43.64506   \n",
       "679965                                                NaN  43.69899   \n",
       "679966                                                NaN  43.65352   \n",
       "\n",
       "        longitude featclass featcode country  cc2  ... Continent  tld  \\\n",
       "678465  -79.27528         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "678466  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678467  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678468  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "678469  -79.03288         P      PPL      CA  NaN  ...       NaN  NaN   \n",
       "...           ...       ...      ...     ...  ...  ...       ...  ...   \n",
       "679962  -79.49049         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679963  -79.51347         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679964  -79.46787         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679965  -79.54786         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "679966  -79.51058         P     PPLX      CA  NaN  ...       NaN  NaN   \n",
       "\n",
       "       CurrencyCode CurrencyName  Phone  Postal Code Format  \\\n",
       "678465          NaN          NaN    NaN                 NaN   \n",
       "678466          NaN          NaN    NaN                 NaN   \n",
       "678467          NaN          NaN    NaN                 NaN   \n",
       "678468          NaN          NaN    NaN                 NaN   \n",
       "678469          NaN          NaN    NaN                 NaN   \n",
       "...             ...          ...    ...                 ...   \n",
       "679962          NaN          NaN    NaN                 NaN   \n",
       "679963          NaN          NaN    NaN                 NaN   \n",
       "679964          NaN          NaN    NaN                 NaN   \n",
       "679965          NaN          NaN    NaN                 NaN   \n",
       "679966          NaN          NaN    NaN                 NaN   \n",
       "\n",
       "        Postal Code Regex Languages neighbours EquivalentFipsCode  \n",
       "678465                NaN       NaN        NaN                NaN  \n",
       "678466                NaN       NaN        NaN                NaN  \n",
       "678467                NaN       NaN        NaN                NaN  \n",
       "678468                NaN       NaN        NaN                NaN  \n",
       "678469                NaN       NaN        NaN                NaN  \n",
       "...                   ...       ...        ...                ...  \n",
       "679962                NaN       NaN        NaN                NaN  \n",
       "679963                NaN       NaN        NaN                NaN  \n",
       "679964                NaN       NaN        NaN                NaN  \n",
       "679965                NaN       NaN        NaN                NaN  \n",
       "679966                NaN       NaN        NaN                NaN  \n",
       "\n",
       "[1502 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GeoNames 'admin1' (admin1_df) for Canadian provinces uses a 2-digit code\n",
    "# Use postal abbreviation which people use\n",
    "\n",
    "# CA.01\tAlberta\tAlberta\t5883102\n",
    "# CA.02\tBritish Columbia\tBritish Columbia\t5909050\n",
    "# CA.03\tManitoba\tManitoba\t6065171\n",
    "# CA.04\tNew Brunswick\tNew Brunswick\t6087430\n",
    "# CA.13\tNorthwest Territories\tNorthwest Territories\t6091069\n",
    "# CA.07\tNova Scotia\tNova Scotia\t6091530\n",
    "# CA.14\tNunavut\tNunavut\t6091732\n",
    "# CA.08\tOntario\tOntario\t6093943\n",
    "# CA.09\tPrince Edward Island\tPrince Edward Island\t6113358\n",
    "# CA.10\tQuebec\tQuebec\t6115047\n",
    "# CA.11\tSaskatchewan\tSaskatchewan\t6141242\n",
    "# CA.12\tYukon\tYukon\t6185811\n",
    "# CA.05\tNewfoundland and Labrador\tNewfoundland and Labrador\t6354959\n",
    "\n",
    "province_abbr = {\n",
    "    'CA.01': 'CA.AB', # Alberta\n",
    "    'CA.02': 'CA.BC', # British Columbia\n",
    "    'CA.03': 'CA.MB', # Manitoba\n",
    "    'CA.04': 'CA.NB', # New Brunswick\n",
    "    'CA.05': 'CA.NL', # Newfoundland and Labrador\n",
    "    'CA.07': 'CA.NS', # Nova Scotia\n",
    "    'CA.08': 'CA.ON', # Ontario\n",
    "    'CA.09': 'CA.PE', # Prince Edward Island\n",
    "    'CA.10': 'CA.QC', # Quebec\n",
    "    'CA.11': 'CA.SK', # Saskatchewan\n",
    "    'CA.12': 'CA.YK', # Yukon\n",
    "    'CA.13': 'CA.NT', # Northwest Territories\n",
    "    'CA.14': 'CA.NU'  # Nunavut\n",
    "}\n",
    "\n",
    "new_provinces = admin1_df[admin1_df['code'].str.contains('^CA.')].copy()\n",
    "new_provinces['code'] = new_provinces['code'].map(province_abbr)\n",
    "admin1_df = pd.concat([admin1_df, new_provinces], ignore_index=True)\n",
    "admin1_df[admin1_df['code'].str.contains('^CA.')]\n",
    "\n",
    "# Add to cities too\n",
    "# Query the cities with country CA and num code, copy,\n",
    "# replace num code by letter code, then concat back\n",
    "new_cities = pd.DataFrame([], columns=countries_df.columns)\n",
    "for num_code, letter_code in province_abbr.items():\n",
    "    country, num = tuple(num_code.split('.'))\n",
    "    country, letter = tuple(letter_code.split('.'))\n",
    " \n",
    "    alt_cities = cities_alt_df[(cities_alt_df['country'] == country) & \\\n",
    "                               (cities_alt_df['admin1'] == num)].copy()\n",
    "    alt_cities['admin1'] = letter\n",
    "    new_cities = pd.concat([new_cities, alt_cities], ignore_index=True)\n",
    "\n",
    "cities_alt_df = pd.concat([cities_alt_df, new_cities], ignore_index=True)\n",
    "cities_alt_df[cities_alt_df['admin1'] == 'ON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>BO.04</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>HN.12</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>SV.06</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>La Paz</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code    name name ascii  geonameid\n",
       "351   BO.04  La Paz     La Paz         99\n",
       "1190  HN.12  La Paz     La Paz         99\n",
       "3288  SV.06  La Paz     La Paz         99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test when there's more than 1 admin1\n",
    "\n",
    "# admin1_df[admin1_df['code'].str.contains('^US.')]\n",
    "# admin1_df[admin1_df['name'] == 'La Paz']\n",
    "country_code = 'HN'\n",
    "element = 'La Paz'\n",
    "test1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "test1.loc[:, 'geonameid'] = 99\n",
    "test11 = test1.head(1)\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>US.FL</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4155751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code     name name ascii  geonameid\n",
       "3660  US.FL  Florida    Florida    4155751"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With both country-code and admin1-code\n",
    "country_code = 'CA'\n",
    "admin1_code = 'ON'\n",
    "admin1_df[(admin1_df['code'].str.contains(f'^{country_code}.{admin1_code}'))]\n",
    "\n",
    "# With only an admin1-code\n",
    "admin1_code = 'FL'\n",
    "admin1_df[(admin1_df['code'].str.contains(f'.{admin1_code}$'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative names (huge DB)\n",
    "\n",
    "# alts = os.path.join(current_dir, data_dir, \"alternateNamesV2.txt\")\n",
    "# alts_df = pd.read_csv(alts, sep='\\t',\n",
    "#             names=['alternateNameId', 'geonameid', 'isolanguage', 'alternate name',\n",
    "#                    'isPreferredName', 'isShortName', 'isColloquial', 'isHistoric', 'from', 'to'])\n",
    "# alts_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alts_df[(alts_df['isPreferredName'] == 1) & (alts_df['alternate name'] == 'République Démocratique Du Congo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add alternative country names (e.g. USA, UK, etc.)\n",
    "# (we can't easily get alternative country names)\n",
    "alternative_country_names = {\n",
    "    6252001: ['USA', 'US','United States of America','America'], # United States\n",
    "    2510769: ['España'], # [Kingdom of] Spain\n",
    "    2635167: ['UK'],     # United Kingdom\n",
    "    1861060: ['日本'],    # Japan\n",
    "    298795: ['Türkiye'], # Turkey\n",
    "    3469034: ['Brasil'], # Brazil\n",
    "    3175395: ['Italia'], # Italy\n",
    "    1694008: ['Republic of the Philippines'], # Philipines\n",
    "    2921044: ['Deutschland'] # Germany\n",
    "}\n",
    "\n",
    "new_countries = pd.DataFrame([], columns=countries_df.columns)\n",
    "for geo, alt_names in alternative_country_names.items():\n",
    "    for name in alt_names:\n",
    "        alt_country = countries_df[countries_df['geonameid'] == geo].copy()\n",
    "        alt_country['Country'] = name\n",
    "        new_countries = pd.concat([new_countries, alt_country], ignore_index=True)\n",
    "\n",
    "countries_df = pd.concat([countries_df, new_countries], ignore_index=True)\n",
    "        \n",
    "# TODO: City alternartives\n",
    "# And others like abbreviations (e.g. CDMX)\n",
    "# Add to list of city alternatives\n",
    "# #3527646: 'CDMX',   # Mexico City "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard specific 'tweet_user_location' strings\n",
    "LOCATION_DISCARD = ['', 'none', '\\\\n', 'global', 'earth',\n",
    "                    'planet earth', 'worldwide', 'everywhere',\n",
    "                    'internet', 'en todas partes',\n",
    "                    'europe', 'africa',\n",
    "                    'world']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the percentage of tweets that have a 'geonameid'\n",
    "# Skipping the ones we know aren't valid (discards)\n",
    "def print_geonameid_completeness(df):\n",
    "    all_tweets = df[~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)]['tweet_id'].sum()\n",
    "    geonameid_tweets = df[df.geonameid.notnull()]['tweet_id'].sum()\n",
    "    print(f'{geonameid_tweets/all_tweets*100:.3f}%')\n",
    "\n",
    "# Show dataframe df where 'geonameid' is NaN and location\n",
    "# is not known to be invalid (discards)\n",
    "def show_nan(df):\n",
    "    nan_df = df[(~df['tweet_user_location_copy'].isin(LOCATION_DISCARD)) & df['geonameid'].isnull()]\n",
    "    print(f'Number of NaNs: {len(nan_df.index)}')\n",
    "    return nan_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338210</th>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "      <td>3</td>\n",
       "      <td>N 52°27' 0'' / W 1°49' 0''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338211</th>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "      <td>3</td>\n",
       "      <td>Villerupt-Luxembourg-Oslo-Stoc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338212</th>\n",
       "      <td>Chicago ✈</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338213</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>3</td>\n",
       "      <td>Catch Me If You Can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338214</th>\n",
       "      <td>On all your devices</td>\n",
       "      <td>3</td>\n",
       "      <td>On all your devices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338215 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_user_location  tweet_id  \\\n",
       "0                                 None   4994911   \n",
       "1                        United States    190257   \n",
       "2                                India     97652   \n",
       "3                      London, England     77542   \n",
       "4                                  USA     67336   \n",
       "...                                ...       ...   \n",
       "338210      N 52°27' 0'' / W 1°49' 0''         3   \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc         3   \n",
       "338212                      Chicago ✈          3   \n",
       "338213            Catch Me If You Can          3   \n",
       "338214             On all your devices         3   \n",
       "\n",
       "              tweet_user_location_copy  \n",
       "0                                 None  \n",
       "1                        United States  \n",
       "2                                India  \n",
       "3                      London, England  \n",
       "4                                  USA  \n",
       "...                                ...  \n",
       "338210      N 52°27' 0'' / W 1°49' 0''  \n",
       "338211  Villerupt-Luxembourg-Oslo-Stoc  \n",
       "338212                         Chicago  \n",
       "338213             Catch Me If You Can  \n",
       "338214             On all your devices  \n",
       "\n",
       "[338215 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy of 'tweet_user_location' so we leave the original intact\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location']\n",
    "\n",
    "# Discard specific 'tweet_user_location' strings\n",
    "# tweet_user_location_discard = ['None', '\\\\N']\n",
    "# df = df[~df['tweet_user_location'].isin(tweet_user_location_discard)]\n",
    "\n",
    "# Discard locations that don't exist more than 2 times\n",
    "df = df[df['tweet_id'] > 2]\n",
    "\n",
    "# Filter out emojis and other symbols\n",
    "# * https://stackoverflow.com/a/49986645\n",
    "# * https://www.ling.upenn.edu/courses/Spring_2003/ling538/UnicodeRanges.html (Unicode symbol ranges)\n",
    "import re\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emojis: emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # emojis: symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # emojis: transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # emojis: flags (iOS)\n",
    "        u\"\\U00002700-\\U000027BF\"  # 'Dingbats' http://www.unicode.org/charts/PDF/U2700.pdf\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: deEmojify(x))\n",
    "\n",
    "# Truncate leading and trailing spaces\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.strip())\n",
    "\n",
    "# Truncate trailing \",\" and \".\" characters\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip(','))\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].map(lambda x: x.rstrip('.'))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean: Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything used for comparison lowercase for simplicity\n",
    "\n",
    "# Locations\n",
    "df['tweet_user_location_copy'] = df['tweet_user_location_copy'].str.lower()\n",
    "\n",
    "# Cities\n",
    "cities_alt_df['name'] = cities_alt_df['name'].str.lower()\n",
    "cities_alt_df['asciiname'] = cities_alt_df['asciiname'].str.lower()\n",
    "cities_alt_df['altname'] = cities_alt_df['altname'].str.lower()\n",
    "cities_alt_df['admin1'] = cities_alt_df['admin1'].str.lower()\n",
    "\n",
    "# Admin1\n",
    "admin1_df['code'] = admin1_df['code'].str.lower()\n",
    "admin1_df['name'] = admin1_df['name'].str.lower()\n",
    "admin1_df['name ascii'] = admin1_df['name ascii'].str.lower()\n",
    "\n",
    "# Countries\n",
    "countries_df['Country'] = countries_df['Country'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>Canada</td>\n",
       "      <td>723</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>712</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>canada</td>\n",
       "      <td>674</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>352</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>199</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>Canada</td>\n",
       "      <td>177</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>🇨🇦 Canada</td>\n",
       "      <td>100</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14493</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>63</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17363</th>\n",
       "      <td>Canada🇨🇦</td>\n",
       "      <td>52</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24576</th>\n",
       "      <td>🇨🇦 CANADA</td>\n",
       "      <td>37</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32494</th>\n",
       "      <td>canada</td>\n",
       "      <td>28</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51637</th>\n",
       "      <td>CANADA 🇨🇦</td>\n",
       "      <td>18</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>🇨🇦Canada🇨🇦</td>\n",
       "      <td>17</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78821</th>\n",
       "      <td>🍁 Canada 🍁</td>\n",
       "      <td>12</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79402</th>\n",
       "      <td>Canada 🇨🇦😁</td>\n",
       "      <td>12</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83440</th>\n",
       "      <td>Canada</td>\n",
       "      <td>11</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84848</th>\n",
       "      <td>Canada 🇨🇦🇮🇳</td>\n",
       "      <td>11</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97153</th>\n",
       "      <td>Canada🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97288</th>\n",
       "      <td>CANADA 🍁</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100681</th>\n",
       "      <td>Canada</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100693</th>\n",
       "      <td>Canada  🇨🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106456</th>\n",
       "      <td>canada🇨🇦🇲🇦</td>\n",
       "      <td>9</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143425</th>\n",
       "      <td>Canada 🇨🇦</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143617</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143790</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148946</th>\n",
       "      <td>CANADA</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155483</th>\n",
       "      <td>🍁Canada🍁</td>\n",
       "      <td>6</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191476</th>\n",
       "      <td>CANADA 🇨🇦🇬🇧</td>\n",
       "      <td>5</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192221</th>\n",
       "      <td>Canada</td>\n",
       "      <td>5</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224870</th>\n",
       "      <td>Canada🇨🇦 🇵🇹</td>\n",
       "      <td>4</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244818</th>\n",
       "      <td>CANADA🇨🇦🇨🇦🇨🇦</td>\n",
       "      <td>4</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294426</th>\n",
       "      <td>Canada.</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294428</th>\n",
       "      <td>Canada. 🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294536</th>\n",
       "      <td>Canada 🍁</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294551</th>\n",
       "      <td>Canada 🇨🇦🇨🇦</td>\n",
       "      <td>3</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_user_location  tweet_id tweet_user_location_copy\n",
       "18                  Canada     40858                   canada\n",
       "1497               Canada        723                   canada\n",
       "1520                CANADA       712                   canada\n",
       "1594                canada       674                   canada\n",
       "2846             Canada 🇨🇦       352                   canada\n",
       "4756               Canada.       199                   canada\n",
       "5333                Canada       177                   canada\n",
       "9208             🇨🇦 Canada       100                   canada\n",
       "14493           Canada 🇨🇦         63                   canada\n",
       "17363             Canada🇨🇦        52                   canada\n",
       "24576            🇨🇦 CANADA        37                   canada\n",
       "32494              canada         28                   canada\n",
       "51637            CANADA 🇨🇦        18                   canada\n",
       "52402           🇨🇦Canada🇨🇦        17                   canada\n",
       "78821           🍁 Canada 🍁        12                   canada\n",
       "79402           Canada 🇨🇦😁        12                   canada\n",
       "83440              Canada         11                   canada\n",
       "84848          Canada 🇨🇦🇮🇳        11                   canada\n",
       "97153              Canada🍁         9                   canada\n",
       "97288             CANADA 🍁         9                   canada\n",
       "100681            Canada           9                   canada\n",
       "100693          Canada  🇨🇦         9                   canada\n",
       "106456          canada🇨🇦🇲🇦         9                   canada\n",
       "143425           Canada 🇨🇦         6                   canada\n",
       "143617             CANADA          6                   canada\n",
       "143790              CANADA         6                   canada\n",
       "148946             CANADA          6                   canada\n",
       "155483            🍁Canada🍁         6                   canada\n",
       "191476         CANADA 🇨🇦🇬🇧         5                   canada\n",
       "192221              Canada         5                   canada\n",
       "224870         Canada🇨🇦 🇵🇹         4                   canada\n",
       "244818        CANADA🇨🇦🇨🇦🇨🇦         4                   canada\n",
       "294426            Canada.          3                   canada\n",
       "294428          Canada. 🇨🇦         3                   canada\n",
       "294536            Canada 🍁         3                   canada\n",
       "294551         Canada 🇨🇦🇨🇦         3                   canada"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some locations are verbatim the name of a country, e.g.:\n",
    "df[df['tweet_user_location_copy'] == 'canada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df[df['tweet_user_location'].isin(simple_countries_df['Country'])]\n",
    "# # simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]#.set_index('Country')\n",
    "\n",
    "# # Merge in country info (with goenameid) when there's an exact country match\n",
    "\n",
    "# # Keep the columns of countries_df we need.\n",
    "# simple_countries_df = countries_df[['#ISO','Country', 'geonameid']]\n",
    "# #df = pd.merge(df, simple_countries_df, how='left', left_on='tweet_user_location_copy', right_on='Country')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_geonameid_completeness(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_cities_df = cities_df[['geonameid', 'name', 'asciiname', 'altnames']]\n",
    "# df = pd.merge(df, simple_cities_df, how='left', left_on='tweet_user_location', right_on='name')\n",
    "#df_copy = df[df['geonameid'].isnull()]\n",
    "#pd.merge(df_copy, simple_cities_df, how='left', left_on='tweet_user_location_copy', right_on='name')\n",
    "\n",
    "# NB: this can't work b/c cities name (unlike countries) aren't unique, e.g. there's a lot of \"London\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['tweet_user_location_copy'].str.count(',') > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = \"Toronto, Ontario, Canada, World\"\n",
    "# test = \"Toronto, Canada\"\n",
    "# test.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toronto']\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def split_fixed_parts(num_parts, location):\n",
    "#     parts = location.split(',')\n",
    "#     if num_parts > len(parts):\n",
    "#         for i in range(num_parts - len(parts)):\n",
    "#             parts.insert(0, None)\n",
    "#     else:\n",
    "#         for i in range(len(parts) - num_parts):\n",
    "#             parts.pop(0)\n",
    "#     return parts\n",
    "\n",
    "# def parts_dict(num_parts, location):\n",
    "#     parts = split_fixed_parts(num_parts, location)\n",
    "#     return {f'el-{k}':parts[k] for k in range(num_parts)}\n",
    "\n",
    "def split_parts(location):\n",
    "    return location.split(',')\n",
    "\n",
    "# print(split_fixed_parts(3, 'Toronto'))\n",
    "print(split_parts('Toronto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>México</td>\n",
       "      <td>46987</td>\n",
       "      <td>méxico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>España</td>\n",
       "      <td>44838</td>\n",
       "      <td>españa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\N</td>\n",
       "      <td>39268</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UK</td>\n",
       "      <td>36063</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>33687</td>\n",
       "      <td>argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>33580</td>\n",
       "      <td>brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Italia</td>\n",
       "      <td>32502</td>\n",
       "      <td>italia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Australia</td>\n",
       "      <td>30921</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Paris</td>\n",
       "      <td>29451</td>\n",
       "      <td>paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>28946</td>\n",
       "      <td>madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Earth</td>\n",
       "      <td>26727</td>\n",
       "      <td>earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>New York</td>\n",
       "      <td>26546</td>\n",
       "      <td>new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>25048</td>\n",
       "      <td>colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>24684</td>\n",
       "      <td>indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Chile</td>\n",
       "      <td>22545</td>\n",
       "      <td>chile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Worldwide</td>\n",
       "      <td>22394</td>\n",
       "      <td>worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_user_location  tweet_id tweet_user_location_copy\n",
       "0                      None   4994911                     none\n",
       "1             United States    190257            united states\n",
       "2                     India     97652                    india\n",
       "3           London, England     77542          london, england\n",
       "4                       USA     67336                      usa\n",
       "5                    London     66315                   london\n",
       "6              New York, NY     64266             new york, ny\n",
       "7            Washington, DC     62869           washington, dc\n",
       "8           Los Angeles, CA     61941          los angeles, ca\n",
       "9           California, USA     54503          california, usa\n",
       "10                   France     54481                   france\n",
       "11           Lagos, Nigeria     52122           lagos, nigeria\n",
       "12           United Kingdom     48965           united kingdom\n",
       "13                   México     46987                   méxico\n",
       "14            Paris, France     46026            paris, france\n",
       "15                   España     44838                   españa\n",
       "16                  Nigeria     44185                  nigeria\n",
       "17                Venezuela     42657                venezuela\n",
       "18                   Canada     40858                   canada\n",
       "19         New Delhi, India     39714         new delhi, india\n",
       "20                       \\N     39268                       \\n\n",
       "21              Chicago, IL     37747              chicago, il\n",
       "22             Florida, USA     36840             florida, usa\n",
       "23                       UK     36063                       uk\n",
       "24  Buenos Aires, Argentina     34826  buenos aires, argentina\n",
       "25               Texas, USA     33996               texas, usa\n",
       "26                Argentina     33687                argentina\n",
       "27                   Brasil     33580                   brasil\n",
       "28                   Italia     32502                   italia\n",
       "29            New York, USA     31541            new york, usa\n",
       "30                Australia     30921                australia\n",
       "31  England, United Kingdom     30857  england, united kingdom\n",
       "32                    Paris     29451                    paris\n",
       "33              Atlanta, GA     29293              atlanta, ga\n",
       "34                   Madrid     28946                   madrid\n",
       "35            Mumbai, India     27054            mumbai, india\n",
       "36         Toronto, Ontario     27010         toronto, ontario\n",
       "37                    Earth     26727                    earth\n",
       "38                 New York     26546                 new york\n",
       "39        San Francisco, CA     26438        san francisco, ca\n",
       "40              Houston, TX     25425              houston, tx\n",
       "41                 Colombia     25048                 colombia\n",
       "42               Boston, MA     24881               boston, ma\n",
       "43                Indonesia     24684                indonesia\n",
       "44                    Chile     22545                    chile\n",
       "45                Worldwide     22394                worldwide\n",
       "46       Caracas, Venezuela     22303       caracas, venezuela\n",
       "47           Nairobi, Kenya     22264           nairobi, kenya\n",
       "48        São Paulo, Brasil     21690        são paulo, brasil\n",
       "49              Seattle, WA     21279              seattle, wa"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mini test dataset\n",
    "# test_df = df[df['tweet_user_location_copy'].str.count(',') == 2].head(50)\n",
    "test_df = df.head(50).copy()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>none</td>\n",
       "      <td>[none]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>united states</td>\n",
       "      <td>[united states]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>india</td>\n",
       "      <td>[india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>usa</td>\n",
       "      <td>[usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>london</td>\n",
       "      <td>[london]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>[new york,  ny]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>[washington,  dc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>[los angeles,  ca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "      <td>[california,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>france</td>\n",
       "      <td>[france]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "      <td>[lagos,  nigeria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>[united kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>México</td>\n",
       "      <td>46987</td>\n",
       "      <td>méxico</td>\n",
       "      <td>[méxico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "      <td>[paris,  france]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>España</td>\n",
       "      <td>44838</td>\n",
       "      <td>españa</td>\n",
       "      <td>[españa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>[nigeria]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>[venezuela]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "      <td>[canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "      <td>[new delhi,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\N</td>\n",
       "      <td>39268</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>[chicago,  il]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "      <td>[florida,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UK</td>\n",
       "      <td>36063</td>\n",
       "      <td>uk</td>\n",
       "      <td>[uk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "      <td>[buenos aires,  argentina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "      <td>[texas,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>33687</td>\n",
       "      <td>argentina</td>\n",
       "      <td>[argentina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>33580</td>\n",
       "      <td>brasil</td>\n",
       "      <td>[brasil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Italia</td>\n",
       "      <td>32502</td>\n",
       "      <td>italia</td>\n",
       "      <td>[italia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "      <td>[new york,  usa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Australia</td>\n",
       "      <td>30921</td>\n",
       "      <td>australia</td>\n",
       "      <td>[australia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "      <td>[england,  united kingdom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Paris</td>\n",
       "      <td>29451</td>\n",
       "      <td>paris</td>\n",
       "      <td>[paris]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>[atlanta,  ga]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>28946</td>\n",
       "      <td>madrid</td>\n",
       "      <td>[madrid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "      <td>[mumbai,  india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "      <td>[toronto,  ontario]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Earth</td>\n",
       "      <td>26727</td>\n",
       "      <td>earth</td>\n",
       "      <td>[earth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>New York</td>\n",
       "      <td>26546</td>\n",
       "      <td>new york</td>\n",
       "      <td>[new york]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>[san francisco,  ca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "      <td>[houston,  tx]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>25048</td>\n",
       "      <td>colombia</td>\n",
       "      <td>[colombia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "      <td>[boston,  ma]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>24684</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>[indonesia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Chile</td>\n",
       "      <td>22545</td>\n",
       "      <td>chile</td>\n",
       "      <td>[chile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Worldwide</td>\n",
       "      <td>22394</td>\n",
       "      <td>worldwide</td>\n",
       "      <td>[worldwide]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "      <td>[caracas,  venezuela]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "      <td>[nairobi,  kenya]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "      <td>[são paulo,  brasil]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>[seattle,  wa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_user_location  tweet_id tweet_user_location_copy  \\\n",
       "0                      None   4994911                     none   \n",
       "1             United States    190257            united states   \n",
       "2                     India     97652                    india   \n",
       "3           London, England     77542          london, england   \n",
       "4                       USA     67336                      usa   \n",
       "5                    London     66315                   london   \n",
       "6              New York, NY     64266             new york, ny   \n",
       "7            Washington, DC     62869           washington, dc   \n",
       "8           Los Angeles, CA     61941          los angeles, ca   \n",
       "9           California, USA     54503          california, usa   \n",
       "10                   France     54481                   france   \n",
       "11           Lagos, Nigeria     52122           lagos, nigeria   \n",
       "12           United Kingdom     48965           united kingdom   \n",
       "13                   México     46987                   méxico   \n",
       "14            Paris, France     46026            paris, france   \n",
       "15                   España     44838                   españa   \n",
       "16                  Nigeria     44185                  nigeria   \n",
       "17                Venezuela     42657                venezuela   \n",
       "18                   Canada     40858                   canada   \n",
       "19         New Delhi, India     39714         new delhi, india   \n",
       "20                       \\N     39268                       \\n   \n",
       "21              Chicago, IL     37747              chicago, il   \n",
       "22             Florida, USA     36840             florida, usa   \n",
       "23                       UK     36063                       uk   \n",
       "24  Buenos Aires, Argentina     34826  buenos aires, argentina   \n",
       "25               Texas, USA     33996               texas, usa   \n",
       "26                Argentina     33687                argentina   \n",
       "27                   Brasil     33580                   brasil   \n",
       "28                   Italia     32502                   italia   \n",
       "29            New York, USA     31541            new york, usa   \n",
       "30                Australia     30921                australia   \n",
       "31  England, United Kingdom     30857  england, united kingdom   \n",
       "32                    Paris     29451                    paris   \n",
       "33              Atlanta, GA     29293              atlanta, ga   \n",
       "34                   Madrid     28946                   madrid   \n",
       "35            Mumbai, India     27054            mumbai, india   \n",
       "36         Toronto, Ontario     27010         toronto, ontario   \n",
       "37                    Earth     26727                    earth   \n",
       "38                 New York     26546                 new york   \n",
       "39        San Francisco, CA     26438        san francisco, ca   \n",
       "40              Houston, TX     25425              houston, tx   \n",
       "41                 Colombia     25048                 colombia   \n",
       "42               Boston, MA     24881               boston, ma   \n",
       "43                Indonesia     24684                indonesia   \n",
       "44                    Chile     22545                    chile   \n",
       "45                Worldwide     22394                worldwide   \n",
       "46       Caracas, Venezuela     22303       caracas, venezuela   \n",
       "47           Nairobi, Kenya     22264           nairobi, kenya   \n",
       "48        São Paulo, Brasil     21690        são paulo, brasil   \n",
       "49              Seattle, WA     21279              seattle, wa   \n",
       "\n",
       "                      elements  \n",
       "0                       [none]  \n",
       "1              [united states]  \n",
       "2                      [india]  \n",
       "3           [london,  england]  \n",
       "4                        [usa]  \n",
       "5                     [london]  \n",
       "6              [new york,  ny]  \n",
       "7            [washington,  dc]  \n",
       "8           [los angeles,  ca]  \n",
       "9           [california,  usa]  \n",
       "10                    [france]  \n",
       "11           [lagos,  nigeria]  \n",
       "12            [united kingdom]  \n",
       "13                    [méxico]  \n",
       "14            [paris,  france]  \n",
       "15                    [españa]  \n",
       "16                   [nigeria]  \n",
       "17                 [venezuela]  \n",
       "18                    [canada]  \n",
       "19         [new delhi,  india]  \n",
       "20                        [\\n]  \n",
       "21              [chicago,  il]  \n",
       "22             [florida,  usa]  \n",
       "23                        [uk]  \n",
       "24  [buenos aires,  argentina]  \n",
       "25               [texas,  usa]  \n",
       "26                 [argentina]  \n",
       "27                    [brasil]  \n",
       "28                    [italia]  \n",
       "29            [new york,  usa]  \n",
       "30                 [australia]  \n",
       "31  [england,  united kingdom]  \n",
       "32                     [paris]  \n",
       "33              [atlanta,  ga]  \n",
       "34                    [madrid]  \n",
       "35            [mumbai,  india]  \n",
       "36         [toronto,  ontario]  \n",
       "37                     [earth]  \n",
       "38                  [new york]  \n",
       "39        [san francisco,  ca]  \n",
       "40              [houston,  tx]  \n",
       "41                  [colombia]  \n",
       "42               [boston,  ma]  \n",
       "43                 [indonesia]  \n",
       "44                     [chile]  \n",
       "45                 [worldwide]  \n",
       "46       [caracas,  venezuela]  \n",
       "47           [nairobi,  kenya]  \n",
       "48        [são paulo,  brasil]  \n",
       "49              [seattle,  wa]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parts = 3\n",
    "\n",
    "# https://stackoverflow.com/a/16242202\n",
    "#test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))\n",
    "#test_df = pd.concat([test_df, test_df.tweet_user_location_copy.apply(lambda s: pd.Series(parts_dict(num_parts, s)))], axis=1)\n",
    "\n",
    "test_df['elements'] = test_df['tweet_user_location_copy'].map(lambda location: location.split(','))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(countries_df, element):\n",
    "    # Filter 'Country' field with 'element'\n",
    "    country = countries_df[countries_df['Country'] == element]\n",
    "    \n",
    "    # No results\n",
    "    if len(country) == 0:\n",
    "        return None\n",
    "    \n",
    "    # There can be only one result\n",
    "    return country\n",
    "\n",
    "\n",
    "def get_admin1(admin1_df, element, country_code=None):\n",
    "    if country_code is None:\n",
    "        # admin1 matching name (or ascii name), or admin1 code w/o country\n",
    "        admin1 = admin1_df[(admin1_df['name'] == element) | \\\n",
    "                           (admin1_df['name ascii'] == element) | \\\n",
    "                           (admin1_df['code'].str.contains(rf'.{element}$'))]\n",
    "        \n",
    "        # We duplicated some rows (e.g. to add Canadian provices by letter)\n",
    "        # Drop geonameid duplicates. It doesn't matter which ones we keep\n",
    "        admin1 = admin1.drop_duplicates(subset=['geonameid'])\n",
    "        \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            return None\n",
    "    \n",
    "        if len(admin1) > 1:\n",
    "            # If it's an admin1 code\n",
    "            if len(element) == 2:\n",
    "                # If there's more than 1 admin1 codes and it's a 2 letter code,\n",
    "                # take the one that is either USA or Canada\n",
    "                admin1_ = admin1.copy()\n",
    "                admin1 = admin1_[(admin1_['code'].str.contains(rf'us.{element}$')) | \\\n",
    "                                 (admin1_['code'].str.contains(rf'ca.{element}$'))]\n",
    "                \n",
    "                if len(admin1) == 1:\n",
    "                    return admin1\n",
    "                \n",
    "                else:\n",
    "                    # #ERROR:99\n",
    "                    # This error happens when for an admin1 code,\n",
    "                    # w/o a country, there is more than 1 admin1 row that is not USA or Canada\n",
    "                    admin1 = admin1_df[admin1_df['code'].str.contains(rf'.{element}$')].copy()\n",
    "                    admin1.loc[:, 'geonameid'] = 99\n",
    "                    return admin1.head(1)\n",
    "            \n",
    "            # #ERROR:98\n",
    "            # This error happens when, w/o a country, there is\n",
    "            # more than 1 admin1 by that name/ascii name.\n",
    "            # There is not enough data to infer which one.\n",
    "            # e.g. \"La Paz\" district (Bolivia, Honduras, El Savador)\n",
    "            admin1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "            admin1.loc[:, 'geonameid'] = 98\n",
    "            return admin1.head(1)\n",
    "    \n",
    "    else:\n",
    "        country_code = country_code.lower()\n",
    "        # admin1 code matching <country_code>.<abbreviation>\n",
    "        # or (admin1 code starts with <country_code> and (match name (or ascii name)))\n",
    "        admin1 = admin1_df[\n",
    "            (admin1_df['code'] == f'{country_code}.{element}') | \\\n",
    "                ((admin1_df['code'].str.contains(rf'^{country_code}.')) & \\\n",
    "                 ((admin1_df['name'] == element) | (admin1_df['name ascii'] == element)))]\n",
    "        \n",
    "        if len(admin1) == 0:\n",
    "            # No results\n",
    "            return None\n",
    "        \n",
    "        if len(admin1) > 1:\n",
    "            # #ERROR:97\n",
    "            # This error happens when, with a country, there is\n",
    "            # more than 1 admin1 by that name/ascii name.\n",
    "            admin1 = admin1_df[(admin1_df['name'] == element)].copy()\n",
    "            admin1.loc[:, 'geonameid'] = 97\n",
    "            return admin1.head(1)\n",
    "    \n",
    "    return admin1\n",
    "\n",
    "\n",
    "def get_city(cities_df, element, admin1_code=None, country_code=None):\n",
    "    # print(f'admin1_code: {admin1_code}, country_code: {country_code}')\n",
    "    if admin1_code is None and country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element)]\n",
    "    \n",
    "    elif admin1_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                         (cities_df['country'] == country_code)]\n",
    "    \n",
    "    elif country_code is None:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code)]\n",
    "    \n",
    "    else:\n",
    "        cities = cities_df[(cities_df['altname'] == element) & \\\n",
    "                           (cities_df['admin1'] == admin1_code) & \\\n",
    "                           (cities_df['country'] == country_code)]\n",
    "    \n",
    "    if len(cities) == 0:\n",
    "        # No results\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        # More than one result,\n",
    "        # take the city with the largest population.\n",
    "        return cities.nlargest(1, ['population']) \n",
    "\n",
    "\"\"\"\n",
    "Cases:\n",
    "\n",
    "country\n",
    "\n",
    "city, state/prov, country\n",
    "city, state/prov\n",
    "city, country\n",
    "city\n",
    "\n",
    "neighboorhood, city, country\n",
    "neighboorhood, city\n",
    "\n",
    "state/prov, country\n",
    "state/prov\n",
    "\"\"\"\n",
    "\n",
    "# Filter out Regex 'metacharacters' (compile regex for performance)\n",
    "# https://docs.python.org/3/howto/regex.html#matching-characters\n",
    "meta_chars = \".^$*+?{}[]\\|()\"\n",
    "meta_chars = [re.escape(i) for i in list(meta_chars)]\n",
    "regrex_pattern = re.compile(\"|\".join(meta_chars))\n",
    "\n",
    "def infer_geonameid(elements):\n",
    "    # Datasets\n",
    "    # * countries_df\n",
    "    # * admin1_df\n",
    "    # * cities_df\n",
    "\n",
    "    # Remove leading/trailing spaces, lowercase\n",
    "    elements = [e.strip().lower() for e in elements]\n",
    "    \n",
    "    # Don't try to infer if element should be ignored\n",
    "    if elements[0] in LOCATION_DISCARD:\n",
    "        return np.nan\n",
    "    \n",
    "    # Filter out Regex 'metacharacters'\n",
    "    elements = [regrex_pattern.sub(r'', e) for e in elements]\n",
    "    \n",
    "    # One item\n",
    "    # TODO: Invert? Check city first, then state, then country?\n",
    "    # e.g. New York is always the city, not the state.\n",
    "    if len(elements) == 1:\n",
    "        country = get_country(countries_df, elements[0])\n",
    "        \n",
    "        # \"<country>\" as-is\n",
    "        if country is not None:\n",
    "            return str(country['geonameid'].item())\n",
    "    \n",
    "        admin1 = get_admin1(admin1_df, elements[0])\n",
    "    \n",
    "        # \"<state/province>\" as-is\n",
    "        if admin1 is not None:\n",
    "            return str(admin1['geonameid'].item())\n",
    "\n",
    "        city = get_city(cities_alt_df, elements[0])\n",
    "        \n",
    "        # \"<city>\" as-is\n",
    "        if city is not None:\n",
    "            return str(city['geonameid'].item())\n",
    "\n",
    "    \n",
    "    # Two items (0, 1)\n",
    "    elif len(elements) == 2:\n",
    "        \n",
    "        country = get_country(countries_df, elements[1])\n",
    "        \n",
    "        # if element[1] is country:\n",
    "        if country is not None:\n",
    "            country_code = str(country['#ISO'].item())\n",
    "            \n",
    "            # Get admin1 (restrict to <country>)\n",
    "            admin1 = get_admin1(admin1_df, elements[0], country_code=country_code)\n",
    "    \n",
    "            # if element[0] is <state/province> within <country>:\n",
    "            if admin1 is not None:\n",
    "                return str(admin1['geonameid'].item())\n",
    "            \n",
    "            # Get city (restrict to <country>)\n",
    "            city = get_city(cities_alt_df, elements[0], country_code=country_code)\n",
    "        \n",
    "            # if element[0] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return country\n",
    "            return str(country['geonameid'].item())\n",
    "        \n",
    "        \n",
    "        admin1 = get_admin1(admin1_df, elements[1])\n",
    "        \n",
    "        # if element[1] is <state/province>:\n",
    "        if admin1 is not None:\n",
    "            \n",
    "            # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "            # Split it, then make it into a tuple\n",
    "            country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "            \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[0], admin1_code=admin1_code)\n",
    "            \n",
    "            # if element[0] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return <state/province>\n",
    "            return str(admin1['geonameid'].item())\n",
    "         \n",
    "        city = get_city(cities_alt_df, elements[1])\n",
    "        \n",
    "        # if element[1] is <city>:\n",
    "        if city is not None:\n",
    "            return str(city['geonameid'].item())\n",
    "    \n",
    "    # Three items\n",
    "    elif len(elements) == 3:\n",
    "        \n",
    "        country = get_country(countries_df, elements[2])\n",
    "        \n",
    "        # if element[2] is country:\n",
    "        if country is not None:\n",
    "            country_code = str(country['#ISO'].item())\n",
    "\n",
    "            # Get admin1 (restrict to <country>)\n",
    "            admin1 = get_admin1(admin1_df, elements[1], country_code=country_code)\n",
    "            \n",
    "            # if element[1] is <state/province> within <country>:\n",
    "            if admin1 is not None:\n",
    "                \n",
    "                # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "                # Split it, then make it into a tuple\n",
    "                country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "                \n",
    "                # Get city (restrict to <state/province>)\n",
    "                city = get_city(cities_alt_df, elements[0], admin1_code=admin1_code)\n",
    "                \n",
    "                # if element[0] if <city> within <state/province>\n",
    "                if city is not None:\n",
    "                    # return <city>\n",
    "                    return str(city['geonameid'].item())\n",
    "                   \n",
    "                # return <state/province>\n",
    "                return str(admin1['geonameid'].item())\n",
    "                \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[1], country_code=country_code)\n",
    "                \n",
    "            # if element[1] is <city> within <country>:\n",
    "            if city is not None:\n",
    "                # return <city>\n",
    "                return str(city['geonameid'].item())\n",
    "                \n",
    "            # return country\n",
    "            return str(country['geonameid'].item())\n",
    "            \n",
    "        admin1 = get_admin1(admin1_df, elements[2])\n",
    "        \n",
    "        # if element[2] is <state/province>:\n",
    "        if admin1 is not None:\n",
    "            \n",
    "            # Format is '<COUNTRY_CODE>.<ADMIN1_CODE>'\n",
    "            # Split it, then make it into a tuple\n",
    "            country_code, admin1_code = tuple(str(admin1['code'].item()).split('.'))\n",
    "            \n",
    "            # Get city (restrict to <state/province>)\n",
    "            city = get_city(cities_alt_df, elements[1], admin1_code=admin1_code)\n",
    "            \n",
    "            # if element[1] if <city> within <state/province>\n",
    "            if city is not None:\n",
    "                # return <city>\n",
    "                return str(city['geonameid'].item())\n",
    "            \n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>us.ca</td>\n",
       "      <td>california</td>\n",
       "      <td>california</td>\n",
       "      <td>5332921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code        name  name ascii  geonameid\n",
       "3689  us.ca  california  california    5332921"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#infer_geonameid(['ca'])\n",
    "get_admin1(admin1_df, 'ca')\n",
    "# element = \"CA\"\n",
    "# admin1_df[(admin1_df['name'] == element) | \\\n",
    "#                            (admin1_df['name ascii'] == element) | \\\n",
    "#                            (admin1_df['code'].str.contains(f'.{element}$'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>4994911</td>\n",
       "      <td>none</td>\n",
       "      <td>[none]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>190257</td>\n",
       "      <td>united states</td>\n",
       "      <td>[united states]</td>\n",
       "      <td>6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>97652</td>\n",
       "      <td>india</td>\n",
       "      <td>[india]</td>\n",
       "      <td>1269750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London, England</td>\n",
       "      <td>77542</td>\n",
       "      <td>london, england</td>\n",
       "      <td>[london,  england]</td>\n",
       "      <td>2643743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA</td>\n",
       "      <td>67336</td>\n",
       "      <td>usa</td>\n",
       "      <td>[usa]</td>\n",
       "      <td>6252001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>66315</td>\n",
       "      <td>london</td>\n",
       "      <td>[london]</td>\n",
       "      <td>2643743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>64266</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>[new york,  ny]</td>\n",
       "      <td>5128581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>62869</td>\n",
       "      <td>washington, dc</td>\n",
       "      <td>[washington,  dc]</td>\n",
       "      <td>4140963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>61941</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>[los angeles,  ca]</td>\n",
       "      <td>5368361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>California, USA</td>\n",
       "      <td>54503</td>\n",
       "      <td>california, usa</td>\n",
       "      <td>[california,  usa]</td>\n",
       "      <td>5332921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>France</td>\n",
       "      <td>54481</td>\n",
       "      <td>france</td>\n",
       "      <td>[france]</td>\n",
       "      <td>3017382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>52122</td>\n",
       "      <td>lagos, nigeria</td>\n",
       "      <td>[lagos,  nigeria]</td>\n",
       "      <td>2332453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>48965</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>[united kingdom]</td>\n",
       "      <td>2635167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>México</td>\n",
       "      <td>46987</td>\n",
       "      <td>méxico</td>\n",
       "      <td>[méxico]</td>\n",
       "      <td>3523272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Paris, France</td>\n",
       "      <td>46026</td>\n",
       "      <td>paris, france</td>\n",
       "      <td>[paris,  france]</td>\n",
       "      <td>2988507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>España</td>\n",
       "      <td>44838</td>\n",
       "      <td>españa</td>\n",
       "      <td>[españa]</td>\n",
       "      <td>2510769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>44185</td>\n",
       "      <td>nigeria</td>\n",
       "      <td>[nigeria]</td>\n",
       "      <td>2328926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>42657</td>\n",
       "      <td>venezuela</td>\n",
       "      <td>[venezuela]</td>\n",
       "      <td>3625428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Canada</td>\n",
       "      <td>40858</td>\n",
       "      <td>canada</td>\n",
       "      <td>[canada]</td>\n",
       "      <td>6251999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>39714</td>\n",
       "      <td>new delhi, india</td>\n",
       "      <td>[new delhi,  india]</td>\n",
       "      <td>1273294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\N</td>\n",
       "      <td>39268</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>37747</td>\n",
       "      <td>chicago, il</td>\n",
       "      <td>[chicago,  il]</td>\n",
       "      <td>4887398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>36840</td>\n",
       "      <td>florida, usa</td>\n",
       "      <td>[florida,  usa]</td>\n",
       "      <td>4155751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UK</td>\n",
       "      <td>36063</td>\n",
       "      <td>uk</td>\n",
       "      <td>[uk]</td>\n",
       "      <td>2635167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Buenos Aires, Argentina</td>\n",
       "      <td>34826</td>\n",
       "      <td>buenos aires, argentina</td>\n",
       "      <td>[buenos aires,  argentina]</td>\n",
       "      <td>3435907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>33996</td>\n",
       "      <td>texas, usa</td>\n",
       "      <td>[texas,  usa]</td>\n",
       "      <td>4736286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>33687</td>\n",
       "      <td>argentina</td>\n",
       "      <td>[argentina]</td>\n",
       "      <td>3865483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>33580</td>\n",
       "      <td>brasil</td>\n",
       "      <td>[brasil]</td>\n",
       "      <td>3469034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Italia</td>\n",
       "      <td>32502</td>\n",
       "      <td>italia</td>\n",
       "      <td>[italia]</td>\n",
       "      <td>3175395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>31541</td>\n",
       "      <td>new york, usa</td>\n",
       "      <td>[new york,  usa]</td>\n",
       "      <td>5128638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Australia</td>\n",
       "      <td>30921</td>\n",
       "      <td>australia</td>\n",
       "      <td>[australia]</td>\n",
       "      <td>2077456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>30857</td>\n",
       "      <td>england, united kingdom</td>\n",
       "      <td>[england,  united kingdom]</td>\n",
       "      <td>6269131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Paris</td>\n",
       "      <td>29451</td>\n",
       "      <td>paris</td>\n",
       "      <td>[paris]</td>\n",
       "      <td>2988507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>29293</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>[atlanta,  ga]</td>\n",
       "      <td>4180439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Madrid</td>\n",
       "      <td>28946</td>\n",
       "      <td>madrid</td>\n",
       "      <td>[madrid]</td>\n",
       "      <td>3117732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>27054</td>\n",
       "      <td>mumbai, india</td>\n",
       "      <td>[mumbai,  india]</td>\n",
       "      <td>1275339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Toronto, Ontario</td>\n",
       "      <td>27010</td>\n",
       "      <td>toronto, ontario</td>\n",
       "      <td>[toronto,  ontario]</td>\n",
       "      <td>6167865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Earth</td>\n",
       "      <td>26727</td>\n",
       "      <td>earth</td>\n",
       "      <td>[earth]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>New York</td>\n",
       "      <td>26546</td>\n",
       "      <td>new york</td>\n",
       "      <td>[new york]</td>\n",
       "      <td>5128638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>26438</td>\n",
       "      <td>san francisco, ca</td>\n",
       "      <td>[san francisco,  ca]</td>\n",
       "      <td>5391959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>25425</td>\n",
       "      <td>houston, tx</td>\n",
       "      <td>[houston,  tx]</td>\n",
       "      <td>4699066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Colombia</td>\n",
       "      <td>25048</td>\n",
       "      <td>colombia</td>\n",
       "      <td>[colombia]</td>\n",
       "      <td>3686110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>24881</td>\n",
       "      <td>boston, ma</td>\n",
       "      <td>[boston,  ma]</td>\n",
       "      <td>4930956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Indonesia</td>\n",
       "      <td>24684</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>[indonesia]</td>\n",
       "      <td>1643084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Chile</td>\n",
       "      <td>22545</td>\n",
       "      <td>chile</td>\n",
       "      <td>[chile]</td>\n",
       "      <td>3895114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Worldwide</td>\n",
       "      <td>22394</td>\n",
       "      <td>worldwide</td>\n",
       "      <td>[worldwide]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Caracas, Venezuela</td>\n",
       "      <td>22303</td>\n",
       "      <td>caracas, venezuela</td>\n",
       "      <td>[caracas,  venezuela]</td>\n",
       "      <td>3646738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Nairobi, Kenya</td>\n",
       "      <td>22264</td>\n",
       "      <td>nairobi, kenya</td>\n",
       "      <td>[nairobi,  kenya]</td>\n",
       "      <td>184745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>São Paulo, Brasil</td>\n",
       "      <td>21690</td>\n",
       "      <td>são paulo, brasil</td>\n",
       "      <td>[são paulo,  brasil]</td>\n",
       "      <td>3448433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>21279</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>[seattle,  wa]</td>\n",
       "      <td>5809844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tweet_user_location  tweet_id tweet_user_location_copy  \\\n",
       "0                      None   4994911                     none   \n",
       "1             United States    190257            united states   \n",
       "2                     India     97652                    india   \n",
       "3           London, England     77542          london, england   \n",
       "4                       USA     67336                      usa   \n",
       "5                    London     66315                   london   \n",
       "6              New York, NY     64266             new york, ny   \n",
       "7            Washington, DC     62869           washington, dc   \n",
       "8           Los Angeles, CA     61941          los angeles, ca   \n",
       "9           California, USA     54503          california, usa   \n",
       "10                   France     54481                   france   \n",
       "11           Lagos, Nigeria     52122           lagos, nigeria   \n",
       "12           United Kingdom     48965           united kingdom   \n",
       "13                   México     46987                   méxico   \n",
       "14            Paris, France     46026            paris, france   \n",
       "15                   España     44838                   españa   \n",
       "16                  Nigeria     44185                  nigeria   \n",
       "17                Venezuela     42657                venezuela   \n",
       "18                   Canada     40858                   canada   \n",
       "19         New Delhi, India     39714         new delhi, india   \n",
       "20                       \\N     39268                       \\n   \n",
       "21              Chicago, IL     37747              chicago, il   \n",
       "22             Florida, USA     36840             florida, usa   \n",
       "23                       UK     36063                       uk   \n",
       "24  Buenos Aires, Argentina     34826  buenos aires, argentina   \n",
       "25               Texas, USA     33996               texas, usa   \n",
       "26                Argentina     33687                argentina   \n",
       "27                   Brasil     33580                   brasil   \n",
       "28                   Italia     32502                   italia   \n",
       "29            New York, USA     31541            new york, usa   \n",
       "30                Australia     30921                australia   \n",
       "31  England, United Kingdom     30857  england, united kingdom   \n",
       "32                    Paris     29451                    paris   \n",
       "33              Atlanta, GA     29293              atlanta, ga   \n",
       "34                   Madrid     28946                   madrid   \n",
       "35            Mumbai, India     27054            mumbai, india   \n",
       "36         Toronto, Ontario     27010         toronto, ontario   \n",
       "37                    Earth     26727                    earth   \n",
       "38                 New York     26546                 new york   \n",
       "39        San Francisco, CA     26438        san francisco, ca   \n",
       "40              Houston, TX     25425              houston, tx   \n",
       "41                 Colombia     25048                 colombia   \n",
       "42               Boston, MA     24881               boston, ma   \n",
       "43                Indonesia     24684                indonesia   \n",
       "44                    Chile     22545                    chile   \n",
       "45                Worldwide     22394                worldwide   \n",
       "46       Caracas, Venezuela     22303       caracas, venezuela   \n",
       "47           Nairobi, Kenya     22264           nairobi, kenya   \n",
       "48        São Paulo, Brasil     21690        são paulo, brasil   \n",
       "49              Seattle, WA     21279              seattle, wa   \n",
       "\n",
       "                      elements geonameid  \n",
       "0                       [none]       NaN  \n",
       "1              [united states]   6252001  \n",
       "2                      [india]   1269750  \n",
       "3           [london,  england]   2643743  \n",
       "4                        [usa]   6252001  \n",
       "5                     [london]   2643743  \n",
       "6              [new york,  ny]   5128581  \n",
       "7            [washington,  dc]   4140963  \n",
       "8           [los angeles,  ca]   5368361  \n",
       "9           [california,  usa]   5332921  \n",
       "10                    [france]   3017382  \n",
       "11           [lagos,  nigeria]   2332453  \n",
       "12            [united kingdom]   2635167  \n",
       "13                    [méxico]   3523272  \n",
       "14            [paris,  france]   2988507  \n",
       "15                    [españa]   2510769  \n",
       "16                   [nigeria]   2328926  \n",
       "17                 [venezuela]   3625428  \n",
       "18                    [canada]   6251999  \n",
       "19         [new delhi,  india]   1273294  \n",
       "20                        [\\n]       NaN  \n",
       "21              [chicago,  il]   4887398  \n",
       "22             [florida,  usa]   4155751  \n",
       "23                        [uk]   2635167  \n",
       "24  [buenos aires,  argentina]   3435907  \n",
       "25               [texas,  usa]   4736286  \n",
       "26                 [argentina]   3865483  \n",
       "27                    [brasil]   3469034  \n",
       "28                    [italia]   3175395  \n",
       "29            [new york,  usa]   5128638  \n",
       "30                 [australia]   2077456  \n",
       "31  [england,  united kingdom]   6269131  \n",
       "32                     [paris]   2988507  \n",
       "33              [atlanta,  ga]   4180439  \n",
       "34                    [madrid]   3117732  \n",
       "35            [mumbai,  india]   1275339  \n",
       "36         [toronto,  ontario]   6167865  \n",
       "37                     [earth]       NaN  \n",
       "38                  [new york]   5128638  \n",
       "39        [san francisco,  ca]   5391959  \n",
       "40              [houston,  tx]   4699066  \n",
       "41                  [colombia]   3686110  \n",
       "42               [boston,  ma]   4930956  \n",
       "43                 [indonesia]   1643084  \n",
       "44                     [chile]   3895114  \n",
       "45                 [worldwide]       NaN  \n",
       "46       [caracas,  venezuela]   3646738  \n",
       "47           [nairobi,  kenya]    184745  \n",
       "48        [são paulo,  brasil]   3448433  \n",
       "49              [seattle,  wa]   5809844  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_df['geonameid'] = np.nan\n",
    "test_df['geonameid'] = test_df['elements'].map(lambda elements: infer_geonameid(elements))\n",
    "test_df\n",
    "\n",
    "# Testing one by one\n",
    "# for e in test_df['elements']:\n",
    "#     print(e)\n",
    "#     infer_geonameid(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.000%\n"
     ]
    }
   ],
   "source": [
    "print_geonameid_completeness(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_user_location</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_user_location_copy</th>\n",
       "      <th>elements</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet_user_location, tweet_id, tweet_user_location_copy, elements, geonameid]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_nan(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6252001'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_geonameid(['columbus', 'ohio', 'usa'])\n",
    "infer_geonameid(['usa'])\n",
    "#get_admin1(admin1_df, 'florida', country_code='US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>name ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [code, name, name ascii, geonameid]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = 'toronto'\n",
    "admin1_code = 'on'\n",
    "# cities_alt_df[(cities_alt_df['altname'] == element) & \\\n",
    "#               (cities_alt_df['admin1'] == admin1_code)]\n",
    "\n",
    "element = 'england'\n",
    "country_code = 'GB'\n",
    "admin1_df[(admin1_df['code'] == f'{country_code}.{element}') & \\\n",
    "         ((admin1_df['name'] == element) | \\\n",
    "          (admin1_df['name ascii'] == element))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6252001'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#countries_df[countries_df['Country'] == 'united states']\n",
    "infer_geonameid(['united states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#ISO</th>\n",
       "      <th>ISO3</th>\n",
       "      <th>ISO-Numeric</th>\n",
       "      <th>fips</th>\n",
       "      <th>Country</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Area(in sq km)</th>\n",
       "      <th>Population</th>\n",
       "      <th>Continent</th>\n",
       "      <th>tld</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CurrencyName</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Postal Code Format</th>\n",
       "      <th>Postal Code Regex</th>\n",
       "      <th>Languages</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>neighbours</th>\n",
       "      <th>EquivalentFipsCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>US</td>\n",
       "      <td>united states</td>\n",
       "      <td>Washington</td>\n",
       "      <td>9629091.0</td>\n",
       "      <td>327167434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.us</td>\n",
       "      <td>USD</td>\n",
       "      <td>Dollar</td>\n",
       "      <td>1</td>\n",
       "      <td>#####-####</td>\n",
       "      <td>^\\d{5}(-\\d{4})?$</td>\n",
       "      <td>en-US,es-US,haw,fr</td>\n",
       "      <td>6252001</td>\n",
       "      <td>CA,MX,CU</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #ISO ISO3 ISO-Numeric fips        Country     Capital  Area(in sq km)  \\\n",
       "233   US  USA         840   US  united states  Washington       9629091.0   \n",
       "\n",
       "    Population Continent  tld CurrencyCode CurrencyName Phone  \\\n",
       "233  327167434       NaN  .us          USD       Dollar     1   \n",
       "\n",
       "    Postal Code Format Postal Code Regex           Languages geonameid  \\\n",
       "233         #####-####  ^\\d{5}(-\\d{4})?$  en-US,es-US,haw,fr   6252001   \n",
       "\n",
       "    neighbours EquivalentFipsCode  \n",
       "233   CA,MX,CU                NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = ['united states']\n",
    "get_country(countries_df, elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep columns we need\n",
    "output_df = test_df[['tweet_user_location', 'tweet_id', 'geonameid']]\n",
    "output_path = os.path.join(current_dir, \"locations_clean_user_location_geonameid.tsv\")\n",
    "output_df.to_csv(output_path, sep=\"\\t\", index=False)\n",
    "\n",
    "# Special 'with URL' for fast-checking\n",
    "output_df = output_df.assign(url=lambda x: \"https://www.geonames.org/\" + x['geonameid'])\n",
    "output_path = os.path.join(current_dir, \"locations_clean_user_location_geonameid_url.tsv\")\n",
    "output_df.to_csv(output_path, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
